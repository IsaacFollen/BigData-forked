<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Big Data Cleaning and Transformation | Big Data Analytics</title>
  <meta name="description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Big Data Cleaning and Transformation | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://umatter.github.io/BigData/img/cover.jpg" />
  <meta property="og:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Big Data Cleaning and Transformation | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="twitter:image" content="https://umatter.github.io/BigData/img/cover.jpg" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2022-12-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-collection-and-data-storage.html"/>
<link rel="next" href="descriptive-statistics-and-aggregation.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>I Setting the Scene: Analyzing Big Data</b></span></li>
<li class="chapter" data-level="" data-path="s.html"><a href="s.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="what-is-big-in-big-data.html"><a href="what-is-big-in-big-data.html"><i class="fa fa-check"></i><b>1</b> What is <em>big</em> in “Big Data”?</a></li>
<li class="chapter" data-level="2" data-path="approaches-to-analyzing-big-data.html"><a href="approaches-to-analyzing-big-data.html"><i class="fa fa-check"></i><b>2</b> Approaches to analyzing Big Data</a></li>
<li class="chapter" data-level="3" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html"><i class="fa fa-check"></i><b>3</b> Two domains of Big Data Analytics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>3.1</b> A practical <em>big P</em> problem</a></li>
<li class="chapter" data-level="3.2" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>3.2</b> A practical <em>big N</em> problem</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>3.2.1</b> OLS as a point of reference</a></li>
<li class="chapter" data-level="3.2.2" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>3.2.2</b> The <em>Uluru</em> algorithm as an alternative to OLS</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="two-domains-of-big-data-analytics.html"><a href="two-domains-of-big-data-analytics.html#conclusion"><i class="fa fa-check"></i><b>3.3</b> Conclusion</a></li>
</ul></li>
<li class="part"><span><b>II Platform: Software and Computing Resources</b></span></li>
<li class="chapter" data-level="" data-path="p.html"><a href="p.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>4</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>4.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>4.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="4.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>4.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>4.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="4.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>4.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="4.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>4.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="4.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>4.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="4.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>4.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="4.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>4.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>4.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>4.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="4.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>4.4.2</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#wrapping-up"><i class="fa fa-check"></i><b>4.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>5</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>5.1</b> Mass storage</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoid-redundancies"><i class="fa fa-check"></i><b>5.1.1</b> Avoid redundancies</a></li>
<li class="chapter" data-level="5.1.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>5.1.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>5.2</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="5.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>5.3</b> Combining RAM and hard disk: virtual memory</a></li>
<li class="chapter" data-level="5.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>5.4</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>5.4.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="5.4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>5.4.2</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>5.5</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>5.5.1</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The road ahead: Hardware made for machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#wrapping-up-1"><i class="fa fa-check"></i><b>5.7</b> Wrapping up</a></li>
<li class="chapter" data-level="5.8" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#still-insufficient-computing-resources"><i class="fa fa-check"></i><b>5.8</b> Still insufficient computing resources?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>6</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>6.1</b> MapReduce</a></li>
<li class="chapter" data-level="6.2" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-hadoop"><i class="fa fa-check"></i><b>6.2</b> Apache Hadoop</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>6.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-spark"><i class="fa fa-check"></i><b>6.3</b> Apache Spark</a></li>
<li class="chapter" data-level="6.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>6.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>6.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="6.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>6.6</b> Spark with R + SQL</a></li>
<li class="chapter" data-level="6.7" data-path="distributed-systems.html"><a href="distributed-systems.html#wrapping-up-2"><i class="fa fa-check"></i><b>6.7</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>7</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cloud-computing.html"><a href="cloud-computing.html#cloud-computing-basics-and-platforms"><i class="fa fa-check"></i><b>7.1</b> Cloud computing basics and platforms</a></li>
<li class="chapter" data-level="7.2" data-path="cloud-computing.html"><a href="cloud-computing.html#transitioning-to-the-cloud"><i class="fa fa-check"></i><b>7.2</b> Transitioning to the cloud</a></li>
<li class="chapter" data-level="7.3" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-in-the-cloud-virtual-servers"><i class="fa fa-check"></i><b>7.3</b> Scaling up in the cloud: virtual servers</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-aws-ec2-and-rrstudio"><i class="fa fa-check"></i><b>7.3.1</b> Scaling up with AWS EC2 and R/RStudio</a></li>
<li class="chapter" data-level="7.3.2" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>7.3.2</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-gpus"><i class="fa fa-check"></i><b>7.4</b> Scaling up with GPUs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>7.4.1</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="7.4.2" data-path="cloud-computing.html"><a href="cloud-computing.html#rstudio-and-ec2-with-gpus-on-aws"><i class="fa fa-check"></i><b>7.4.2</b> RStudio and EC2 with GPUs on AWS</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-out-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>7.5</b> Scaling out: MapReduce in the cloud</a></li>
<li class="chapter" data-level="7.6" data-path="cloud-computing.html"><a href="cloud-computing.html#wrapping-up-3"><i class="fa fa-check"></i><b>7.6</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>III Components of Big Data Analytics</b></span></li>
<li class="chapter" data-level="" data-path="introduction-to-part-ii.html"><a href="introduction-to-part-ii.html"><i class="fa fa-check"></i>Introduction to Part II</a></li>
<li class="chapter" data-level="8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>8</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>8.1</b> Gathering and compilation of raw data</a></li>
<li class="chapter" data-level="8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#stackcombine-raw-source-files"><i class="fa fa-check"></i><b>8.2</b> Stack/combine raw source files</a></li>
<li class="chapter" data-level="8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>8.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>8.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="8.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>8.3.2</b> Efficient data access: indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-rdbms"><i class="fa fa-check"></i><b>8.4</b> Connecting R to RDBMS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>8.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>8.4.2</b> Importing data</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issue-queries"><i class="fa fa-check"></i><b>8.4.3</b> Issue queries</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>8.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>8.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#column-based-analytics-databases"><i class="fa fa-check"></i><b>8.6</b> Column-based analytics databases</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#installation-and-start-up"><i class="fa fa-check"></i><b>8.6.1</b> Installation and start up</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#first-steps-via-druids-gui"><i class="fa fa-check"></i><b>8.6.2</b> First steps via Druid’s GUI</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#query-druid-from-r"><i class="fa fa-check"></i><b>8.6.3</b> Query Druid from R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouses"><i class="fa fa-check"></i><b>8.7</b> Data warehouses</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example"><i class="fa fa-check"></i><b>8.7.1</b> Data warehouse for analytics: Google BigQuery example</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service"><i class="fa fa-check"></i><b>8.8</b> Data lakes and simple storage service</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps"><i class="fa fa-check"></i><b>8.8.1</b> AWS S3 with R: first steps</a></li>
<li class="chapter" data-level="8.8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#uploading-data-to-s3"><i class="fa fa-check"></i><b>8.8.2</b> Uploading data to S3</a></li>
<li class="chapter" data-level="8.8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-aws-athena"><i class="fa fa-check"></i><b>8.8.3</b> More than just simple storage: S3 + AWS Athena</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#wrapping-up-4"><i class="fa fa-check"></i><b>8.9</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>9</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics"><i class="fa fa-check"></i><b>9.1</b> Out-of-memory strategies and lazy evaluation: practical basics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>9.1.1</b> Chunking data with the <code>ff</code>-package</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>9.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow"><i class="fa fa-check"></i><b>9.1.3</b> Connecting to Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#ff-big-data-preparation-tutorial"><i class="fa fa-check"></i><b>9.2</b> <code>ff</code> Big Data Preparation Tutorial</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-import"><i class="fa fa-check"></i><b>9.2.2</b> Data import</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-imported-files"><i class="fa fa-check"></i><b>9.2.3</b> Inspect imported files</a></li>
<li class="chapter" data-level="9.2.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation"><i class="fa fa-check"></i><b>9.2.4</b> Data cleaning and transformation</a></li>
<li class="chapter" data-level="9.2.5" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#subsetting"><i class="fa fa-check"></i><b>9.2.5</b> Subsetting</a></li>
<li class="chapter" data-level="9.2.6" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#saveloadexport-ff_files-files"><i class="fa fa-check"></i><b>9.2.6</b> Save/load/export ff_files-files</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#arrow-big-data-preparation-tutorial"><i class="fa fa-check"></i><b>9.3</b> <code>arrow</code> Big Data Preparation Tutorial</a></li>
<li class="chapter" data-level="9.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#wrapping-up-5"><i class="fa fa-check"></i><b>9.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>10</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>10.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>10.1.1</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="10.1.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#cross-tabulation-of-ff-vectors"><i class="fa fa-check"></i><b>10.1.2</b> Cross-tabulation of <code>ff</code> vectors</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-arrow"><i class="fa fa-check"></i><b>10.2</b> High-speed in-memory data aggregation with <code>arrow</code></a></li>
<li class="chapter" data-level="10.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>10.3</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
<li class="chapter" data-level="10.4" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#wrapping-up-6"><i class="fa fa-check"></i><b>10.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>11</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#challenges-of-big-data-visualization"><i class="fa fa-check"></i><b>11.1</b> Challenges of big data visualization</a></li>
<li class="chapter" data-level="11.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>11.2</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="11.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualize-time-and-space"><i class="fa fa-check"></i><b>11.3</b> Visualize Time and Space</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>11.3.1</b> Preparations</a></li>
<li class="chapter" data-level="11.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>11.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#wrapping-up-7"><i class="fa fa-check"></i><b>11.4</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>IV Application: Topics in Big Data Econometrics</b></span></li>
<li class="chapter" data-level="" data-path="a.html"><a href="a.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html"><i class="fa fa-check"></i><b>12</b> Bottle Necks in Every-Day Econometrics</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#case-study-data-import-and-memory-allocation"><i class="fa fa-check"></i><b>12.1</b> Case study: Data Import and Memory Allocation</a></li>
<li class="chapter" data-level="12.2" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>12.2</b> Case Study: Loops, Memory, and Vectorization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#preparation"><i class="fa fa-check"></i><b>12.2.1</b> Preparation</a></li>
<li class="chapter" data-level="12.2.2" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>12.2.2</b> Naïve Approach (ignorant of R)</a></li>
<li class="chapter" data-level="12.2.3" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>12.2.3</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="12.2.4" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>12.2.4</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>12.3</b> Case study: Bootstrapping and Parallel Processing</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>12.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="bottle-necks-in-every-day-econometrics.html"><a href="bottle-necks-in-every-day-econometrics.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>12.4</b> Case Study: Efficient Fixed Effects Estimation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html"><i class="fa fa-check"></i><b>13</b> GPUs and Machine Learning</a>
<ul>
<li class="chapter" data-level="13.1" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>13.1</b> Tensorflow/Keras example: predict housing prices</a></li>
<li class="chapter" data-level="13.2" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#data-preparation"><i class="fa fa-check"></i><b>13.2</b> Data preparation</a></li>
<li class="chapter" data-level="13.3" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#model-specification"><i class="fa fa-check"></i><b>13.3</b> Model specification</a></li>
<li class="chapter" data-level="13.4" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#training-and-prediction"><i class="fa fa-check"></i><b>13.4</b> Training and prediction</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#a-word-of-caution"><i class="fa fa-check"></i><b>13.4.1</b> A word of caution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html"><i class="fa fa-check"></i><b>14</b> Regression Analysis and Categorization with Spark and R</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-regression-analysis"><i class="fa fa-check"></i><b>14.1</b> Simple regression analysis</a></li>
<li class="chapter" data-level="14.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification"><i class="fa fa-check"></i><b>14.2</b> Machine learning for classification</a></li>
<li class="chapter" data-level="14.3" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark"><i class="fa fa-check"></i><b>14.3</b> Building machine learning pipelines with R and Spark</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import"><i class="fa fa-check"></i><b>14.3.1</b> Set up and data import</a></li>
<li class="chapter" data-level="14.3.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline"><i class="fa fa-check"></i><b>14.3.2</b> Building the pipeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-8"><i class="fa fa-check"></i><b>14.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html"><i class="fa fa-check"></i><b>15</b> Large-scale Text Analysis with sparklyr</a>
<ul>
<li class="chapter" data-level="15.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count"><i class="fa fa-check"></i><b>15.1</b> Getting started: import, pre-processing, and word count</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i><b>A</b> Appendix A</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendix-a.html"><a href="appendix-a.html#github"><i class="fa fa-check"></i><b>A.1</b> GitHub</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendix-a.html"><a href="appendix-a.html#initiate-a-new-repository"><i class="fa fa-check"></i><b>A.1.1</b> Initiate a new repository</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendix-a.html"><a href="appendix-a.html#clone-this-courses-repository"><i class="fa fa-check"></i><b>A.1.2</b> Clone this course’s repository</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendix-a.html"><a href="appendix-a.html#fork-this-courses-repository"><i class="fa fa-check"></i><b>A.1.3</b> Fork this course’s repository</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendix-b.html"><a href="appendix-b.html"><i class="fa fa-check"></i><b>B</b> Appendix B</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendix-b.html"><a href="appendix-b.html#data-types-and-memorystorage"><i class="fa fa-check"></i><b>B.1</b> Data types and memory/storage</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="appendix-b.html"><a href="appendix-b.html#example-in-r-data-types-and-information-storage"><i class="fa fa-check"></i><b>B.1.1</b> Example in R: Data types and information storage</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="appendix-b.html"><a href="appendix-b.html#data-structures"><i class="fa fa-check"></i><b>B.2</b> Data structures</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="appendix-b.html"><a href="appendix-b.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i><b>B.2.1</b> Vectors vs Factors in R</a></li>
<li class="chapter" data-level="B.2.2" data-path="appendix-b.html"><a href="appendix-b.html#matricesarrays"><i class="fa fa-check"></i><b>B.2.2</b> Matrices/Arrays</a></li>
<li class="chapter" data-level="B.2.3" data-path="appendix-b.html"><a href="appendix-b.html#data-frames-tibbles-and-data-tables"><i class="fa fa-check"></i><b>B.2.3</b> Data frames, tibbles, and data tables</a></li>
<li class="chapter" data-level="B.2.4" data-path="appendix-b.html"><a href="appendix-b.html#lists"><i class="fa fa-check"></i><b>B.2.4</b> Lists</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="appendix-b.html"><a href="appendix-b.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i><b>B.3</b> R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendix-c.html"><a href="appendix-c.html"><i class="fa fa-check"></i><b>C</b> Appendix C</a>
<ul>
<li class="chapter" data-level="C.1" data-path="appendix-c.html"><a href="appendix-c.html#install-hadoop-on-ubuntu-linux"><i class="fa fa-check"></i><b>C.1</b> Install Hadoop (on Ubuntu Linux)</a></li>
<li class="chapter" data-level="C.2" data-path="appendix-c.html"><a href="appendix-c.html#manually-set-up-a-database-server-in-the-cloud"><i class="fa fa-check"></i><b>C.2</b> Manually set up a database server in the cloud</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="big-data-cleaning-and-transformation" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Big Data Cleaning and Transformation<a href="big-data-cleaning-and-transformation.html#big-data-cleaning-and-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Preceding the filtering/selection/aggregation of raw data, data cleaning and transformation typically have to be run on large volumes of raw data, before the observations and variables of interest can be further analyzed. Typical data cleaning tasks involve:</p>
<ul>
<li>Normalization/standartization (across entities, categories, observation periods).</li>
<li>Coding of additional variables (indicators, strings to categorical, etc.).</li>
<li>Removing/adding covariates.</li>
<li>Merging/joining data sets.</li>
<li>Properly defining data types for each variable.</li>
</ul>
<p>All of these steps are very common tasks when working with data for analytics purposes, independent of the size of datasets. However, as most of the techniques and software developed for such tasks is meant to process data in memory, performing these tasks on rather big datasets can be challenging. Data cleaning workflows you are perfectly familiar with might slow down substantially or crash due to a lack of memory (RAM), particularly if the data preparation step involves merging/joining two datasets. Other potential bottle-necks are the parsing of large files (CPU), or the intense reading from and writing to the hard disk (Mass storage).</p>
<p>In practice, the most critical bottleneck of common data preparation tasks is often a lack of RAM. In the following, we thus explore two strategies that broadly build on the idea of <em>virtual memory</em> (using parts of the hard disk as RAM) and/or <em>lazy evaluation</em> (only loading/processing the part of a dataset really required).</p>
<div id="out-of-memory-strategies-and-lazy-evaluation-practical-basics" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Out-of-memory strategies and lazy evaluation: practical basics<a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Virtual memory is in simple words an approach to combining the RAM and mass storage components in order to cope with a lack of RAM. Modern operating systems come with a virtual memory manager that would automatically handle the swapping between RAM and the hard-disk, when running processes that use up too much RAM. However, a virtual memory manager is not specifically developed to perform this task in the context of data analysis. Several strategies have thus been developed to build on the basic idea of <em>virtual memory</em> in the context of data analysis tasks.</p>
<ul>
<li><p><em>Chunked data files on disk</em>: The data analytics software ‘partitions’ the data set, maps, and stores the chunks of raw data on disk. What is actually ‘read’ into RAM when importing the data file with this approach is the mapping to the partitions of the actual data set (the data structure) and some metadata describing the data set. In R, this approach is implemented in the <code>ff</code> package and several packages building on <code>ff</code>. In this approach, the usage of disk space and the linking between RAM and files on disk is very explicit (and well visible to the user).</p></li>
<li><p><em>Memory mapped files and shared memory</em>: The data analytics software uses segments of virtual memory for the data set and allows different programs/processes to access it in the same memory segment. Thus, virtual memory is explicitly allocated for one or several specific data analytics tasks. In R, this approach is prominently implemented in the <code>bigmemory</code> package and several packages building on <code>bigmemory</code>.</p></li>
</ul>
<p>A conceptually related but differently focused approach is the <em>lazy evaluation</em> implemented in Apache Arrow and the corresponding <code>arrow</code> package <span class="citation">(<a href="#ref-richardson_etal2022" role="doc-biblioref">Richardson et al. 2022</a>)</span>. While Apache Arrow is basically a platform for in-memory columnar data, it is optimized for processing large amounts of data and working with datasets that actually do not fit into memory. The way this is done is that instructions on what to do with a dataset are not evaluated step-by-step on the spot bot all together at the point of actually loading the data into R. That is, we can connect to a dataset via <code>arrow</code>, see its variables, etc., give instructions of what observations to filter out and what columns to select, all before we actually start reading the data into RAM. In comparison to the strategies outlined above, this approach is usually much faster but might still lead to a situation with a lack of memory.</p>
<p>The following subsections we briefly look at how to set up an R session for data preparation purposes with either of the approaches (<code>ff</code>, <code>bigmemory</code>, <code>arrow</code>), and look at some of the conceptual basics behind these approaches.</p>
<div id="chunking-data-with-the-ff-package" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Chunking data with the <code>ff</code>-package<a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We first install and load the <code>ff</code> and <code>ffbase</code> packages, as well as the <code>pryr</code> package. We use the already known <code>flights.csv</code>-data set^[Data from the same source is also used in the code examples given in <span class="citation">Kane, Emerson, and Weston (<a href="#ref-kane_etal2013" role="doc-biblioref">2013</a>)</span>. For the sake of the example, we only use a fraction of the original data set.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> On disk, the dataset is about 30MB:</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="big-data-cleaning-and-transformation.html#cb258-1" aria-hidden="true" tabindex="-1"></a>fs<span class="sc">::</span><span class="fu">file_size</span>(<span class="st">&quot;data/flights.csv&quot;</span>)</span></code></pre></div>
<pre><code>## 29.5M</code></pre>
<p>However, loading the entire dataset of several GBs would work just fine, using the <code>ff</code>-approach.</p>
<p>When importing data via the <code>ff</code> package, we first have to set up a directory where <code>ff</code> can store the partitioned data set (recall that this is explicitly/visibly done on disk). We call this new directory <code>ff_files</code>.</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="big-data-cleaning-and-transformation.html#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP --------------</span></span>
<span id="cb260-2"><a href="big-data-cleaning-and-transformation.html#cb260-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb260-3"><a href="big-data-cleaning-and-transformation.html#cb260-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(c(&quot;ff&quot;, &quot;ffbase&quot;))</span></span>
<span id="cb260-4"><a href="big-data-cleaning-and-transformation.html#cb260-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb260-5"><a href="big-data-cleaning-and-transformation.html#cb260-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ff)</span>
<span id="cb260-6"><a href="big-data-cleaning-and-transformation.html#cb260-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ffbase)</span>
<span id="cb260-7"><a href="big-data-cleaning-and-transformation.html#cb260-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table) <span class="co"># for comparison</span></span>
<span id="cb260-8"><a href="big-data-cleaning-and-transformation.html#cb260-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb260-9"><a href="big-data-cleaning-and-transformation.html#cb260-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb260-10"><a href="big-data-cleaning-and-transformation.html#cb260-10" aria-hidden="true" tabindex="-1"></a><span class="co"># create directory for ff chunks, and assign directory to ff </span></span>
<span id="cb260-11"><a href="big-data-cleaning-and-transformation.html#cb260-11" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mkdir ff_files&quot;</span>)</span>
<span id="cb260-12"><a href="big-data-cleaning-and-transformation.html#cb260-12" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">fftempdir =</span> <span class="st">&quot;ff_files&quot;</span>)</span></code></pre></div>
<p>Now we can read in the data with <code>read.table.ffdf</code>. In order to better understand the underlying concept, we also import the data into common <code>data.table</code>- object via <code>fread()</code> and then look at the size of the objects resulting from the two ‘import’ approaches in the R environment with <code>object.size()</code>.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="big-data-cleaning-and-transformation.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="co"># usual in-memory csv import</span></span>
<span id="cb261-2"><a href="big-data-cleaning-and-transformation.html#cb261-2" aria-hidden="true" tabindex="-1"></a>flights_dt <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/flights.csv&quot;</span>)</span>
<span id="cb261-3"><a href="big-data-cleaning-and-transformation.html#cb261-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-4"><a href="big-data-cleaning-and-transformation.html#cb261-4" aria-hidden="true" tabindex="-1"></a><span class="co"># out-of-memory approach</span></span>
<span id="cb261-5"><a href="big-data-cleaning-and-transformation.html#cb261-5" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> </span>
<span id="cb261-6"><a href="big-data-cleaning-and-transformation.html#cb261-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">read.table.ffdf</span>(<span class="at">file=</span><span class="st">&quot;data/flights.csv&quot;</span>,</span>
<span id="cb261-7"><a href="big-data-cleaning-and-transformation.html#cb261-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">sep=</span><span class="st">&quot;,&quot;</span>,</span>
<span id="cb261-8"><a href="big-data-cleaning-and-transformation.html#cb261-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">VERBOSE=</span><span class="cn">TRUE</span>,</span>
<span id="cb261-9"><a href="big-data-cleaning-and-transformation.html#cb261-9" aria-hidden="true" tabindex="-1"></a>                     <span class="at">header=</span><span class="cn">TRUE</span>,</span>
<span id="cb261-10"><a href="big-data-cleaning-and-transformation.html#cb261-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">next.rows=</span><span class="dv">100000</span>,</span>
<span id="cb261-11"><a href="big-data-cleaning-and-transformation.html#cb261-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">colClasses=</span><span class="cn">NA</span>)</span></code></pre></div>
<pre><code>## read.table.ffdf 1..100000 (100000)  csv-read=0.569sec ffdf-write=0.07sec
## read.table.ffdf 100001..200000 (100000)  csv-read=0.436sec ffdf-write=0.053sec
## read.table.ffdf 200001..300000 (100000)  csv-read=0.428sec ffdf-write=0.048sec
## read.table.ffdf 300001..336776 (36776)  csv-read=0.172sec ffdf-write=0.032sec
##  csv-read=1.605sec  ffdf-write=0.203sec  TOTAL=1.808sec</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="big-data-cleaning-and-transformation.html#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compare object sizes</span></span>
<span id="cb263-2"><a href="big-data-cleaning-and-transformation.html#cb263-2" aria-hidden="true" tabindex="-1"></a><span class="fu">object.size</span>(flights) <span class="co"># out-of-memory approach</span></span></code></pre></div>
<pre><code>## 949976 bytes</code></pre>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="big-data-cleaning-and-transformation.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object.size</span>(flights_dt) <span class="co"># common data.table</span></span></code></pre></div>
<pre><code>## 32569024 bytes</code></pre>
<p>Note that there are two substantial differences to what we have previously seen when using <code>fread()</code>. It takes much longer to import a csv into the ff_files structure. However, the RAM allocated to it is much smaller. This is exactly what we would expect, keeping in mind what <code>read.table.ffdf()</code> does in comparison to what <code>fread()</code> does. Now we can actually have a look at the data chunks created by <code>ff</code>.</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="big-data-cleaning-and-transformation.html#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co"># show the files in the directory keeping the chunks</span></span>
<span id="cb267-2"><a href="big-data-cleaning-and-transformation.html#cb267-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">list.files</span>(<span class="st">&quot;ff_files&quot;</span>))</span></code></pre></div>
<pre><code>## [1] &quot;ffdf69c851913fa8f.ff&quot; &quot;ffdf69c851f5bd539.ff&quot;
## [3] &quot;ffdf69c8521447bb0.ff&quot; &quot;ffdf69c852e5ecdf8.ff&quot;
## [5] &quot;ffdf69c853126bd56.ff&quot; &quot;ffdf69c85334e5686.ff&quot;</code></pre>
</div>
<div id="memory-mapping-with-bigmemory" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Memory mapping with <code>bigmemory</code><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <code>bigmemory</code>-package handles data in matrices, and therefore only accepts data values of identical data type. Before importing data via the <code>bigmemory</code>-package, we thus have to ensure that all variables in the raw data can be imported in a common type.</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="big-data-cleaning-and-transformation.html#cb269-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP ----------------</span></span>
<span id="cb269-2"><a href="big-data-cleaning-and-transformation.html#cb269-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-3"><a href="big-data-cleaning-and-transformation.html#cb269-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb269-4"><a href="big-data-cleaning-and-transformation.html#cb269-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bigmemory)</span>
<span id="cb269-5"><a href="big-data-cleaning-and-transformation.html#cb269-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(biganalytics)</span>
<span id="cb269-6"><a href="big-data-cleaning-and-transformation.html#cb269-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-7"><a href="big-data-cleaning-and-transformation.html#cb269-7" aria-hidden="true" tabindex="-1"></a><span class="co"># import the data</span></span>
<span id="cb269-8"><a href="big-data-cleaning-and-transformation.html#cb269-8" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> <span class="fu">read.big.matrix</span>(<span class="st">&quot;data/flights.csv&quot;</span>,</span>
<span id="cb269-9"><a href="big-data-cleaning-and-transformation.html#cb269-9" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type=</span><span class="st">&quot;integer&quot;</span>,</span>
<span id="cb269-10"><a href="big-data-cleaning-and-transformation.html#cb269-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">header=</span><span class="cn">TRUE</span>,</span>
<span id="cb269-11"><a href="big-data-cleaning-and-transformation.html#cb269-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">backingfile=</span><span class="st">&quot;flights.bin&quot;</span>,</span>
<span id="cb269-12"><a href="big-data-cleaning-and-transformation.html#cb269-12" aria-hidden="true" tabindex="-1"></a>                     <span class="at">descriptorfile=</span><span class="st">&quot;flights.desc&quot;</span>)</span></code></pre></div>
<p>Note that, similar to the <code>ff</code>-example, <code>read.big.matrix()</code> initiates a local file-backing <code>flights.bin</code> on disk which is linked to the <code>flights</code>-object in RAM. From looking at the imported file, we see that various variable values have been discarded. This is due to the fact that we have forced all variables to be of type <code>"integer"</code> when importing the data set.</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="big-data-cleaning-and-transformation.html#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(flights)</span></code></pre></div>
<pre><code>##                       min        max       mean
## year             2013.000   2013.000   2013.000
## month               1.000     12.000      6.549
## day                 1.000     31.000     15.711
## dep_time            1.000   2400.000   1349.110
## sched_dep_time    106.000   2359.000   1344.255
## dep_delay         -43.000   1301.000     12.639
## arr_time            1.000   2400.000   1502.055
## sched_arr_time      1.000   2359.000   1536.380
## arr_delay         -86.000   1272.000      6.895
## carrier             9.000      9.000      9.000
## flight              1.000   8500.000   1971.924
## tailnum                                        
## origin                                         
## dest                                           
## air_time           20.000    695.000    150.686
## distance           17.000   4983.000   1039.913
## hour                1.000     23.000     13.180
## minute              0.000     59.000     26.230
## time_hour        2013.000   2014.000   2013.000
##                       NAs
## year                0.000
## month               0.000
## day                 0.000
## dep_time         8255.000
## sched_dep_time      0.000
## dep_delay        8255.000
## arr_time         8713.000
## sched_arr_time      0.000
## arr_delay        9430.000
## carrier        318316.000
## flight              0.000
## tailnum        336776.000
## origin         336776.000
## dest           336776.000
## air_time         9430.000
## distance            0.000
## hour                0.000
## minute              0.000
## time_hour           0.000</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="big-data-cleaning-and-transformation.html#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object.size</span>(flights)</span></code></pre></div>
<pre><code>## 696 bytes</code></pre>
<p>Again, the object representing the dataset in R does not contain the actual data (it does not even take up a KB of memory).</p>
</div>
<div id="connecting-to-apache-arrow" class="section level3 hasAnchor" number="9.1.3">
<h3><span class="header-section-number">9.1.3</span> Connecting to Apache Arrow<a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="big-data-cleaning-and-transformation.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP ----------------</span></span>
<span id="cb274-2"><a href="big-data-cleaning-and-transformation.html#cb274-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb274-3"><a href="big-data-cleaning-and-transformation.html#cb274-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb274-4"><a href="big-data-cleaning-and-transformation.html#cb274-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arrow)</span>
<span id="cb274-5"><a href="big-data-cleaning-and-transformation.html#cb274-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb274-6"><a href="big-data-cleaning-and-transformation.html#cb274-6" aria-hidden="true" tabindex="-1"></a><span class="co"># import the data</span></span>
<span id="cb274-7"><a href="big-data-cleaning-and-transformation.html#cb274-7" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> <span class="fu">read_csv_arrow</span>(<span class="st">&quot;data/flights.csv&quot;</span>,</span>
<span id="cb274-8"><a href="big-data-cleaning-and-transformation.html#cb274-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">as_data_frame =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>Note the <code>as_data_frame=FALSE</code> in the function call. This instructs arrow to only read some of the data (to know what is in the file) and establish a connection to the file, but not actually importing all the csv.</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="big-data-cleaning-and-transformation.html#cb275-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(flights)</span></code></pre></div>
<pre><code>##                Length Class        Mode       
## year           336776 ChunkedArray environment
## month          336776 ChunkedArray environment
## day            336776 ChunkedArray environment
## dep_time       336776 ChunkedArray environment
## sched_dep_time 336776 ChunkedArray environment
## dep_delay      336776 ChunkedArray environment
## arr_time       336776 ChunkedArray environment
## sched_arr_time 336776 ChunkedArray environment
## arr_delay      336776 ChunkedArray environment
## carrier        336776 ChunkedArray environment
## flight         336776 ChunkedArray environment
## tailnum        336776 ChunkedArray environment
## origin         336776 ChunkedArray environment
## dest           336776 ChunkedArray environment
## air_time       336776 ChunkedArray environment
## distance       336776 ChunkedArray environment
## hour           336776 ChunkedArray environment
## minute         336776 ChunkedArray environment
## time_hour      336776 ChunkedArray environment</code></pre>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="big-data-cleaning-and-transformation.html#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object.size</span>(flights)</span></code></pre></div>
<pre><code>## 488 bytes</code></pre>
<p>Again, we notice that the <code>flights</code>-object is much smaller than the actual dataset on disk.</p>
</div>
</div>
<div id="ff-big-data-preparation-tutorial" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> <code>ff</code> Big Data Preparation Tutorial<a href="big-data-cleaning-and-transformation.html#ff-big-data-preparation-tutorial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="set-up" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Set up<a href="big-data-cleaning-and-transformation.html#set-up" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following examples are based on <span class="citation">Walkowiak (<a href="#ref-walkowiak_2016" role="doc-biblioref">2016</a>)</span>, Chapter 3. You can download the original data sets used in these examples from <a href="https://github.com/PacktPublishing/Big-Data-Analytics-with-R/tree/master/Chapter%203">the book’s GitHub repository</a>. The set up for our analysis script involves the loading of the <code>ff</code> and <code>ffbase</code> packages, the intitiation of fix variables to hold the paths to the data sets, as well as the creation and assignment of a new local directory <code>ff_files</code> in which the binary flat files-partitioned chunks of the original data sets will be stored.</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="big-data-cleaning-and-transformation.html#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="do">## SET UP ------------------------</span></span>
<span id="cb279-2"><a href="big-data-cleaning-and-transformation.html#cb279-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-3"><a href="big-data-cleaning-and-transformation.html#cb279-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create and set directory for ff files</span></span>
<span id="cb279-4"><a href="big-data-cleaning-and-transformation.html#cb279-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mkdir ff_files&quot;</span>)</span>
<span id="cb279-5"><a href="big-data-cleaning-and-transformation.html#cb279-5" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">fftempdir =</span> <span class="st">&quot;ff_files&quot;</span>)</span>
<span id="cb279-6"><a href="big-data-cleaning-and-transformation.html#cb279-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-7"><a href="big-data-cleaning-and-transformation.html#cb279-7" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb279-8"><a href="big-data-cleaning-and-transformation.html#cb279-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ff)</span>
<span id="cb279-9"><a href="big-data-cleaning-and-transformation.html#cb279-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ffbase)</span>
<span id="cb279-10"><a href="big-data-cleaning-and-transformation.html#cb279-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pryr)</span>
<span id="cb279-11"><a href="big-data-cleaning-and-transformation.html#cb279-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb279-12"><a href="big-data-cleaning-and-transformation.html#cb279-12" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb279-13"><a href="big-data-cleaning-and-transformation.html#cb279-13" aria-hidden="true" tabindex="-1"></a>FLIGHTS_DATA <span class="ot">&lt;-</span> <span class="st">&quot;data/flights_sep_oct15.txt&quot;</span></span>
<span id="cb279-14"><a href="big-data-cleaning-and-transformation.html#cb279-14" aria-hidden="true" tabindex="-1"></a>AIRLINES_DATA <span class="ot">&lt;-</span> <span class="st">&quot;data/airline_id.csv&quot;</span></span></code></pre></div>
</div>
<div id="data-import" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Data import<a href="big-data-cleaning-and-transformation.html#data-import" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a first step we read (or ‘upload’) the data into R. This step involves the creation of the binary chunked files as well as the mapping of these files and the metadata. In comparison to the traditional <code>read.csv</code> approach, you will notice two things. On the one hand the data import takes longer, on the other hand it uses up much less RAM than than with <code>read.csv</code>.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="big-data-cleaning-and-transformation.html#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DATA IMPORT ------------------</span></span>
<span id="cb280-2"><a href="big-data-cleaning-and-transformation.html#cb280-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb280-3"><a href="big-data-cleaning-and-transformation.html#cb280-3" aria-hidden="true" tabindex="-1"></a><span class="co"># check memory used</span></span>
<span id="cb280-4"><a href="big-data-cleaning-and-transformation.html#cb280-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.78 GB</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="big-data-cleaning-and-transformation.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Upload flights_sep_oct15.txt and airline_id.csv files from flat files. </span></span>
<span id="cb282-2"><a href="big-data-cleaning-and-transformation.html#cb282-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb282-3"><a href="big-data-cleaning-and-transformation.html#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(flights.ff <span class="ot">&lt;-</span> <span class="fu">read.table.ffdf</span>(<span class="at">file=</span>FLIGHTS_DATA,</span>
<span id="cb282-4"><a href="big-data-cleaning-and-transformation.html#cb282-4" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">sep=</span><span class="st">&quot;,&quot;</span>,</span>
<span id="cb282-5"><a href="big-data-cleaning-and-transformation.html#cb282-5" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">VERBOSE=</span><span class="cn">TRUE</span>,</span>
<span id="cb282-6"><a href="big-data-cleaning-and-transformation.html#cb282-6" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">header=</span><span class="cn">TRUE</span>,</span>
<span id="cb282-7"><a href="big-data-cleaning-and-transformation.html#cb282-7" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">next.rows=</span><span class="dv">100000</span>,</span>
<span id="cb282-8"><a href="big-data-cleaning-and-transformation.html#cb282-8" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">colClasses=</span><span class="cn">NA</span>))</span></code></pre></div>
<pre><code>## read.table.ffdf 1..100000 (100000)  csv-read=0.576sec ffdf-write=0.099sec
## read.table.ffdf 100001..200000 (100000)  csv-read=0.632sec ffdf-write=0.075sec
## read.table.ffdf 200001..300000 (100000)  csv-read=0.683sec ffdf-write=0.082sec
## read.table.ffdf 300001..400000 (100000)  csv-read=0.669sec ffdf-write=0.092sec
## read.table.ffdf 400001..500000 (100000)  csv-read=0.743sec ffdf-write=0.076sec
## read.table.ffdf 500001..600000 (100000)  csv-read=0.667sec ffdf-write=0.073sec
## read.table.ffdf 600001..700000 (100000)  csv-read=0.748sec ffdf-write=0.109sec
## read.table.ffdf 700001..800000 (100000)  csv-read=0.824sec ffdf-write=0.081sec
## read.table.ffdf 800001..900000 (100000)  csv-read=0.615sec ffdf-write=0.068sec
## read.table.ffdf 900001..951111 (51111)  csv-read=0.32sec ffdf-write=0.059sec
##  csv-read=6.477sec  ffdf-write=0.814sec  TOTAL=7.291sec</code></pre>
<pre><code>##    user  system elapsed 
##   6.286   0.785   7.298</code></pre>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="big-data-cleaning-and-transformation.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(airlines.ff <span class="ot">&lt;-</span> <span class="fu">read.csv.ffdf</span>(<span class="at">file=</span> AIRLINES_DATA,</span>
<span id="cb285-2"><a href="big-data-cleaning-and-transformation.html#cb285-2" aria-hidden="true" tabindex="-1"></a>                             <span class="at">VERBOSE=</span><span class="cn">TRUE</span>,</span>
<span id="cb285-3"><a href="big-data-cleaning-and-transformation.html#cb285-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">header=</span><span class="cn">TRUE</span>,</span>
<span id="cb285-4"><a href="big-data-cleaning-and-transformation.html#cb285-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">next.rows=</span><span class="dv">100000</span>,</span>
<span id="cb285-5"><a href="big-data-cleaning-and-transformation.html#cb285-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">colClasses=</span><span class="cn">NA</span>))</span></code></pre></div>
<pre><code>## read.table.ffdf 1..1607 (1607)  csv-read=0.008sec ffdf-write=0.006sec
##  csv-read=0.008sec  ffdf-write=0.006sec  TOTAL=0.014sec</code></pre>
<pre><code>##    user  system elapsed 
##   0.005   0.007   0.016</code></pre>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="big-data-cleaning-and-transformation.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check memory used</span></span>
<span id="cb288-2"><a href="big-data-cleaning-and-transformation.html#cb288-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.78 GB</code></pre>
<p>Comparison with <code>read.table</code></p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="big-data-cleaning-and-transformation.html#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Using read.table()</span></span>
<span id="cb290-2"><a href="big-data-cleaning-and-transformation.html#cb290-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(flights.table <span class="ot">&lt;-</span> <span class="fu">read.table</span>(FLIGHTS_DATA, </span>
<span id="cb290-3"><a href="big-data-cleaning-and-transformation.html#cb290-3" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">sep=</span><span class="st">&quot;,&quot;</span>,</span>
<span id="cb290-4"><a href="big-data-cleaning-and-transformation.html#cb290-4" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">header=</span><span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   5.124   0.622   5.829</code></pre>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="big-data-cleaning-and-transformation.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="co">#gc()</span></span>
<span id="cb292-2"><a href="big-data-cleaning-and-transformation.html#cb292-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-3"><a href="big-data-cleaning-and-transformation.html#cb292-3" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(airlines.table <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(AIRLINES_DATA,</span>
<span id="cb292-4"><a href="big-data-cleaning-and-transformation.html#cb292-4" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">header =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.002   0.001   0.003</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="big-data-cleaning-and-transformation.html#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check memory used</span></span>
<span id="cb294-2"><a href="big-data-cleaning-and-transformation.html#cb294-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.93 GB</code></pre>
</div>
<div id="inspect-imported-files" class="section level3 hasAnchor" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Inspect imported files<a href="big-data-cleaning-and-transformation.html#inspect-imported-files" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A particularly useful aspect of working with the ff-package and the packages building on them is that many of the simple R functions that work on usual data.frames in RAM also work on ff_filess. Hence, without actually having loaded the entire raw data of a large data set into RAM, we can quickly get an overview of the key characteristics such as the number of observations and the number of variables.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="big-data-cleaning-and-transformation.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Inspect the ff_files objects.</span></span>
<span id="cb296-2"><a href="big-data-cleaning-and-transformation.html#cb296-2" aria-hidden="true" tabindex="-1"></a><span class="do">## For flights.ff object:</span></span>
<span id="cb296-3"><a href="big-data-cleaning-and-transformation.html#cb296-3" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(flights.ff)</span></code></pre></div>
<pre><code>## [1] &quot;ffdf&quot;</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="big-data-cleaning-and-transformation.html#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(flights.ff)</span></code></pre></div>
<pre><code>## [1] 951111     28</code></pre>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="big-data-cleaning-and-transformation.html#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="do">## For airlines.ff object:</span></span>
<span id="cb300-2"><a href="big-data-cleaning-and-transformation.html#cb300-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(airlines.ff)</span></code></pre></div>
<pre><code>## [1] &quot;ffdf&quot;</code></pre>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="big-data-cleaning-and-transformation.html#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(airlines.ff)</span></code></pre></div>
<pre><code>## [1] 1607    2</code></pre>
</div>
<div id="data-cleaning-and-transformation" class="section level3 hasAnchor" number="9.2.4">
<h3><span class="header-section-number">9.2.4</span> Data cleaning and transformation<a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>After inspecting the data, we go through several steps of cleaning and transformation, with the goal of then merging the two data sets. That is, we want to create a new data set that contains detailed flights information but with additional information on the carriers/airlines. First, we want to rename some of the variables.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="big-data-cleaning-and-transformation.html#cb304-1" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1: </span></span>
<span id="cb304-2"><a href="big-data-cleaning-and-transformation.html#cb304-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Rename &quot;Code&quot; variable from airlines.ff to &quot;AIRLINE_ID&quot; and &quot;Description&quot; into &quot;AIRLINE_NM&quot;.</span></span>
<span id="cb304-3"><a href="big-data-cleaning-and-transformation.html#cb304-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines.ff) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;AIRLINE_ID&quot;</span>, <span class="st">&quot;AIRLINE_NM&quot;</span>)</span>
<span id="cb304-4"><a href="big-data-cleaning-and-transformation.html#cb304-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines.ff)</span></code></pre></div>
<pre><code>## [1] &quot;AIRLINE_ID&quot; &quot;AIRLINE_NM&quot;</code></pre>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="big-data-cleaning-and-transformation.html#cb306-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(airlines.ff[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>,])</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    20 obs. of  2 variables:
##  $ AIRLINE_ID: int  19031 19032 19033 19034 19035 19036 19037 19038 19039 19040 ...
##  $ AIRLINE_NM: Factor w/ 1607 levels &quot;40-Mile Air: Q5&quot;,..: 945 1025 503 721 64 725 1194 99 1395 276 ...</code></pre>
<p>Now we can join the two data sets via the unique airline identifier <code>"AIRLINE_ID"</code>. Note that these kind of operations would usually take up substantially more RAM on the spot, if both original data sets would also be fully loaded into RAM. As illustrated by the <code>mem_change()</code>-function, this is not the case here. All that is needed is a small chunk of RAM to keep the metadata and mapping-information of the new <code>ff_files</code> object, all the actual data is cached on the hard disk.</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="big-data-cleaning-and-transformation.html#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="co"># merge of ff_files objects</span></span>
<span id="cb308-2"><a href="big-data-cleaning-and-transformation.html#cb308-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_change</span>(flights.data.ff <span class="ot">&lt;-</span> <span class="fu">merge.ffdf</span>(flights.ff, airlines.ff, <span class="at">by=</span><span class="st">&quot;AIRLINE_ID&quot;</span>))</span></code></pre></div>
<pre><code>## 774 kB</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="big-data-cleaning-and-transformation.html#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="co">#The new object is only 551.2 Kb in size</span></span>
<span id="cb310-2"><a href="big-data-cleaning-and-transformation.html#cb310-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(flights.data.ff)</span></code></pre></div>
<pre><code>## [1] &quot;ffdf&quot;</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="big-data-cleaning-and-transformation.html#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(flights.data.ff)</span></code></pre></div>
<pre><code>## [1] 951111     29</code></pre>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="big-data-cleaning-and-transformation.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(flights.data.ff)</span></code></pre></div>
<pre><code>##  [1] &quot;YEAR&quot;              &quot;MONTH&quot;            
##  [3] &quot;DAY_OF_MONTH&quot;      &quot;DAY_OF_WEEK&quot;      
##  [5] &quot;FL_DATE&quot;           &quot;UNIQUE_CARRIER&quot;   
##  [7] &quot;AIRLINE_ID&quot;        &quot;TAIL_NUM&quot;         
##  [9] &quot;FL_NUM&quot;            &quot;ORIGIN_AIRPORT_ID&quot;
## [11] &quot;ORIGIN&quot;            &quot;ORIGIN_CITY_NAME&quot; 
## [13] &quot;ORIGIN_STATE_NM&quot;   &quot;ORIGIN_WAC&quot;       
## [15] &quot;DEST_AIRPORT_ID&quot;   &quot;DEST&quot;             
## [17] &quot;DEST_CITY_NAME&quot;    &quot;DEST_STATE_NM&quot;    
## [19] &quot;DEST_WAC&quot;          &quot;DEP_TIME&quot;         
## [21] &quot;DEP_DELAY&quot;         &quot;ARR_TIME&quot;         
## [23] &quot;ARR_DELAY&quot;         &quot;CANCELLED&quot;        
## [25] &quot;CANCELLATION_CODE&quot; &quot;DIVERTED&quot;         
## [27] &quot;AIR_TIME&quot;          &quot;DISTANCE&quot;         
## [29] &quot;AIRLINE_NM&quot;</code></pre>
<p>Inspect difference to in-memory operation</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="big-data-cleaning-and-transformation.html#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="do">##For flights.table:</span></span>
<span id="cb316-2"><a href="big-data-cleaning-and-transformation.html#cb316-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines.table) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;AIRLINE_ID&quot;</span>, <span class="st">&quot;AIRLINE_NM&quot;</span>)</span>
<span id="cb316-3"><a href="big-data-cleaning-and-transformation.html#cb316-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines.table)</span></code></pre></div>
<pre><code>## [1] &quot;AIRLINE_ID&quot; &quot;AIRLINE_NM&quot;</code></pre>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="big-data-cleaning-and-transformation.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(airlines.table[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>,])</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    20 obs. of  2 variables:
##  $ AIRLINE_ID: int  19031 19032 19033 19034 19035 19036 19037 19038 19039 19040 ...
##  $ AIRLINE_NM: chr  &quot;Mackey International Inc.: MAC&quot; &quot;Munz Northern Airlines Inc.: XY&quot; &quot;Cochise Airlines Inc.: COC&quot; &quot;Golden Gate Airlines Inc.: GSA&quot; ...</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="big-data-cleaning-and-transformation.html#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check memory usage of merge in RAM </span></span>
<span id="cb320-2"><a href="big-data-cleaning-and-transformation.html#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_change</span>(flights.data.table <span class="ot">&lt;-</span> <span class="fu">merge</span>(flights.table,</span>
<span id="cb320-3"><a href="big-data-cleaning-and-transformation.html#cb320-3" aria-hidden="true" tabindex="-1"></a>                                       airlines.table,</span>
<span id="cb320-4"><a href="big-data-cleaning-and-transformation.html#cb320-4" aria-hidden="true" tabindex="-1"></a>                                       <span class="at">by=</span><span class="st">&quot;AIRLINE_ID&quot;</span>))</span></code></pre></div>
<pre><code>## 161 MB</code></pre>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="big-data-cleaning-and-transformation.html#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="co">#The new object is already 105.7 Mb in size</span></span>
<span id="cb322-2"><a href="big-data-cleaning-and-transformation.html#cb322-2" aria-hidden="true" tabindex="-1"></a><span class="co">#A rapid spike in RAM use when processing</span></span></code></pre></div>
</div>
<div id="subsetting" class="section level3 hasAnchor" number="9.2.5">
<h3><span class="header-section-number">9.2.5</span> Subsetting<a href="big-data-cleaning-and-transformation.html#subsetting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we want to filter out some observations as well as select only specific variables for a subset of the overall data set.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="big-data-cleaning-and-transformation.html#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 2.09 GB</code></pre>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="big-data-cleaning-and-transformation.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset the ff_files object flights.data.ff:</span></span>
<span id="cb325-2"><a href="big-data-cleaning-and-transformation.html#cb325-2" aria-hidden="true" tabindex="-1"></a>subs1.ff <span class="ot">&lt;-</span> <span class="fu">subset.ffdf</span>(flights.data.ff, CANCELLED <span class="sc">==</span> <span class="dv">1</span>, </span>
<span id="cb325-3"><a href="big-data-cleaning-and-transformation.html#cb325-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">select =</span> <span class="fu">c</span>(FL_DATE, AIRLINE_ID, </span>
<span id="cb325-4"><a href="big-data-cleaning-and-transformation.html#cb325-4" aria-hidden="true" tabindex="-1"></a>                                   ORIGIN_CITY_NAME,</span>
<span id="cb325-5"><a href="big-data-cleaning-and-transformation.html#cb325-5" aria-hidden="true" tabindex="-1"></a>                                   ORIGIN_STATE_NM,</span>
<span id="cb325-6"><a href="big-data-cleaning-and-transformation.html#cb325-6" aria-hidden="true" tabindex="-1"></a>                                   DEST_CITY_NAME,</span>
<span id="cb325-7"><a href="big-data-cleaning-and-transformation.html#cb325-7" aria-hidden="true" tabindex="-1"></a>                                   DEST_STATE_NM,</span>
<span id="cb325-8"><a href="big-data-cleaning-and-transformation.html#cb325-8" aria-hidden="true" tabindex="-1"></a>                                   CANCELLATION_CODE))</span>
<span id="cb325-9"><a href="big-data-cleaning-and-transformation.html#cb325-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-10"><a href="big-data-cleaning-and-transformation.html#cb325-10" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(subs1.ff)</span></code></pre></div>
<pre><code>## [1] 4529    7</code></pre>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="big-data-cleaning-and-transformation.html#cb327-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 2.09 GB</code></pre>
</div>
<div id="saveloadexport-ff_files-files" class="section level3 hasAnchor" number="9.2.6">
<h3><span class="header-section-number">9.2.6</span> Save/load/export ff_files-files<a href="big-data-cleaning-and-transformation.html#saveloadexport-ff_files-files" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In order to better organize and easily reload newly created <code>ff_files</code>s, we can explicitly save them to disk.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="big-data-cleaning-and-transformation.html#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save a newly created ff_files object to a data file:</span></span>
<span id="cb329-2"><a href="big-data-cleaning-and-transformation.html#cb329-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb329-3"><a href="big-data-cleaning-and-transformation.html#cb329-3" aria-hidden="true" tabindex="-1"></a><span class="fu">save.ffdf</span>(subs1.ff, <span class="at">overwrite =</span> <span class="cn">TRUE</span>) <span class="co">#7 files (one for each column) created in the ffdb directory</span></span></code></pre></div>
<p>If we want to reload a previously saved <code>ff_files</code>, we do not have to go through the chunking of a raw data file again, but can very quickly load the data mapping and metadata into RAM in order to further work with the data (stored on disk).</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="big-data-cleaning-and-transformation.html#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading previously saved ff_files files:</span></span>
<span id="cb330-2"><a href="big-data-cleaning-and-transformation.html#cb330-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(subs1.ff)</span>
<span id="cb330-3"><a href="big-data-cleaning-and-transformation.html#cb330-3" aria-hidden="true" tabindex="-1"></a><span class="co">#gc()</span></span>
<span id="cb330-4"><a href="big-data-cleaning-and-transformation.html#cb330-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load.ffdf</span>(<span class="st">&quot;ffdb&quot;</span>)</span>
<span id="cb330-5"><a href="big-data-cleaning-and-transformation.html#cb330-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check the class and structure of the loaded data</span></span>
<span id="cb330-6"><a href="big-data-cleaning-and-transformation.html#cb330-6" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(subs1.ff) </span></code></pre></div>
<pre><code>## [1] &quot;ffdf&quot;</code></pre>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="big-data-cleaning-and-transformation.html#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(subs1.ff)</span></code></pre></div>
<pre><code>## List of 3
##  $ virtual: &#39;data.frame&#39;:    7 obs. of  7 variables:
##  .. $ VirtualVmode     : chr  &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; ...
##  .. $ AsIs             : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  .. $ VirtualIsMatrix  : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  .. $ PhysicalIsMatrix : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  .. $ PhysicalElementNo: int  1 2 3 4 5 6 7
##  .. $ PhysicalFirstCol : int  1 1 1 1 1 1 1
##  .. $ PhysicalLastCol  : int  1 1 1 1 1 1 1
##  .. - attr(*, &quot;Dim&quot;)= int [1:2] 4529 7
##  .. - attr(*, &quot;Dimorder&quot;)= int [1:2] 1 2
##  $ physical: List of 7
##  .. $ FL_DATE          : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$FL_DATE.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:61] &quot;2015-09-01&quot; &quot;2015-09-02&quot; &quot;2015-09-03&quot; &quot;2015-09-04&quot; ...
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ AIRLINE_ID       : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$AIRLINE_ID.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ ORIGIN_CITY_NAME : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$ORIGIN_CITY_NAME.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:305] &quot;Abilene, TX&quot; &quot;Akron, OH&quot; &quot;Albany, GA&quot; &quot;Albany, NY&quot; ...
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ ORIGIN_STATE_NM  : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$ORIGIN_STATE_NM.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:52] &quot;Alabama&quot; &quot;Alaska&quot; &quot;Arizona&quot; &quot;Arkansas&quot; ...
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ DEST_CITY_NAME   : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$DEST_CITY_NAME.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:306] &quot;Abilene, TX&quot; &quot;Akron, OH&quot; &quot;Albany, GA&quot; &quot;Albany, NY&quot; ...
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ DEST_STATE_NM    : list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$DEST_STATE_NM.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:52] &quot;Alabama&quot; &quot;Alaska&quot; &quot;Arizona&quot; &quot;Arkansas&quot; ...
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  .. $ CANCELLATION_CODE: list()
##  ..  ..- attr(*, &quot;physical&quot;)=Class &#39;ff_pointer&#39; &lt;externalptr&gt; 
##  ..  .. ..- attr(*, &quot;vmode&quot;)= chr &quot;integer&quot;
##  ..  .. ..- attr(*, &quot;maxlength&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;pattern&quot;)= chr &quot;ffdf&quot;
##  ..  .. ..- attr(*, &quot;filename&quot;)= chr &quot;/home/umatter/Dropbox/Teaching/HSG/BigData/BigData/ffdb/subs1.ff$CANCELLATION_CODE.ff&quot;
##  ..  .. ..- attr(*, &quot;pagesize&quot;)= int 65536
##  ..  .. ..- attr(*, &quot;finalizer&quot;)= chr &quot;close&quot;
##  ..  .. ..- attr(*, &quot;finonexit&quot;)= logi TRUE
##  ..  .. ..- attr(*, &quot;readonly&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;caching&quot;)= chr &quot;mmnoflush&quot;
##  ..  ..- attr(*, &quot;virtual&quot;)= list()
##  ..  .. ..- attr(*, &quot;Length&quot;)= int 4529
##  ..  .. ..- attr(*, &quot;Symmetric&quot;)= logi FALSE
##  ..  .. ..- attr(*, &quot;Levels&quot;)= chr [1:4] &quot;&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot;
##  ..  .. ..- attr(*, &quot;ramclass&quot;)= chr &quot;factor&quot;
##  .. .. - attr(*, &quot;class&quot;) =  chr [1:2] &quot;ff_vector&quot; &quot;ff&quot;
##  $ row.names:  NULL
## - attributes: List of 2
##  .. $ names: chr [1:2] &quot;virtual&quot; &quot;physical&quot;
##  .. $ class: chr &quot;ffdf&quot;</code></pre>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="big-data-cleaning-and-transformation.html#cb334-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(subs1.ff)</span></code></pre></div>
<pre><code>## [1] 4529    7</code></pre>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="big-data-cleaning-and-transformation.html#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dimnames</span>(subs1.ff)</span></code></pre></div>
<pre><code>## [[1]]
## NULL
## 
## [[2]]
## [1] &quot;FL_DATE&quot;           &quot;AIRLINE_ID&quot;       
## [3] &quot;ORIGIN_CITY_NAME&quot;  &quot;ORIGIN_STATE_NM&quot;  
## [5] &quot;DEST_CITY_NAME&quot;    &quot;DEST_STATE_NM&quot;    
## [7] &quot;CANCELLATION_CODE&quot;</code></pre>
<p>In case we want to store an <code>ff_files</code> data set in a format more accessible for other users (such as csv), we can do so as follows. This last step is also quite common in practice. The initial raw data set is very large, thus we perform all the theoretically very memory-intense tasks of preparing the analytic data set via <code>ff</code> and then store the (often much smaller) analytic data set in a more accessible csv file in order to later read it into RAM and run more computationally intense analyses directly in RAM.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="big-data-cleaning-and-transformation.html#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  Export subs1.ff into CSV and TXT files:</span></span>
<span id="cb338-2"><a href="big-data-cleaning-and-transformation.html#cb338-2" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv.ffdf</span>(subs1.ff, <span class="st">&quot;subset1.csv&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="arrow-big-data-preparation-tutorial" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> <code>arrow</code> Big Data Preparation Tutorial<a href="big-data-cleaning-and-transformation.html#arrow-big-data-preparation-tutorial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We begin by initializing our R session like in the short <code>arrow</code> introduction above.</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="big-data-cleaning-and-transformation.html#cb339-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP ----------------</span></span>
<span id="cb339-2"><a href="big-data-cleaning-and-transformation.html#cb339-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-3"><a href="big-data-cleaning-and-transformation.html#cb339-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb339-4"><a href="big-data-cleaning-and-transformation.html#cb339-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arrow)</span>
<span id="cb339-5"><a href="big-data-cleaning-and-transformation.html#cb339-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb339-6"><a href="big-data-cleaning-and-transformation.html#cb339-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pryr) <span class="co"># for profiling</span></span>
<span id="cb339-7"><a href="big-data-cleaning-and-transformation.html#cb339-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-8"><a href="big-data-cleaning-and-transformation.html#cb339-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb339-9"><a href="big-data-cleaning-and-transformation.html#cb339-9" aria-hidden="true" tabindex="-1"></a>FLIGHTS_DATA <span class="ot">&lt;-</span> <span class="st">&quot;data/flights_sep_oct15.txt&quot;</span></span>
<span id="cb339-10"><a href="big-data-cleaning-and-transformation.html#cb339-10" aria-hidden="true" tabindex="-1"></a>AIRLINES_DATA <span class="ot">&lt;-</span> <span class="st">&quot;data/airline_id.csv&quot;</span></span>
<span id="cb339-11"><a href="big-data-cleaning-and-transformation.html#cb339-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-12"><a href="big-data-cleaning-and-transformation.html#cb339-12" aria-hidden="true" tabindex="-1"></a><span class="co"># import the data</span></span>
<span id="cb339-13"><a href="big-data-cleaning-and-transformation.html#cb339-13" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> <span class="fu">read_csv_arrow</span>(FLIGHTS_DATA,</span>
<span id="cb339-14"><a href="big-data-cleaning-and-transformation.html#cb339-14" aria-hidden="true" tabindex="-1"></a>                     <span class="at">as_data_frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb339-15"><a href="big-data-cleaning-and-transformation.html#cb339-15" aria-hidden="true" tabindex="-1"></a>airlines <span class="ot">&lt;-</span> <span class="fu">read_csv_arrow</span>(AIRLINES_DATA,</span>
<span id="cb339-16"><a href="big-data-cleaning-and-transformation.html#cb339-16" aria-hidden="true" tabindex="-1"></a>                     <span class="at">as_data_frame =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>Note how the data from the csv files is not actually read into RAM yet. The initiated objects <code>flights</code> and <code>airlines</code> are not data frames (yet) and occupy hardly any RAM.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="big-data-cleaning-and-transformation.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(flights)</span></code></pre></div>
<pre><code>## [1] &quot;Table&quot;        &quot;ArrowTabular&quot; &quot;ArrowObject&quot; 
## [4] &quot;R6&quot;</code></pre>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="big-data-cleaning-and-transformation.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(airlines)</span></code></pre></div>
<pre><code>## [1] &quot;Table&quot;        &quot;ArrowTabular&quot; &quot;ArrowObject&quot; 
## [4] &quot;R6&quot;</code></pre>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="big-data-cleaning-and-transformation.html#cb344-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object_size</span>(flights)</span></code></pre></div>
<pre><code>## 283.62 kB</code></pre>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="big-data-cleaning-and-transformation.html#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object_size</span>(airlines)</span></code></pre></div>
<pre><code>## 283.62 kB</code></pre>
<p>In analogy to the <code>ff</code>-tutorial above, we go through the same data preparation steps. First, we rename the variables in <code>airlines</code> in order to ensure that the variable names are consistent with the <code>flights</code> data frame.</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="big-data-cleaning-and-transformation.html#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1: </span></span>
<span id="cb348-2"><a href="big-data-cleaning-and-transformation.html#cb348-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Rename &quot;Code&quot; variable from airlines.ff to &quot;AIRLINE_ID&quot; and &quot;Description&quot; into &quot;AIRLINE_NM&quot;.</span></span>
<span id="cb348-3"><a href="big-data-cleaning-and-transformation.html#cb348-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;AIRLINE_ID&quot;</span>, <span class="st">&quot;AIRLINE_NM&quot;</span>)</span>
<span id="cb348-4"><a href="big-data-cleaning-and-transformation.html#cb348-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(airlines)</span></code></pre></div>
<pre><code>## [1] &quot;AIRLINE_ID&quot; &quot;AIRLINE_NM&quot;</code></pre>
<p>In a second step the two data frames are merged/joined. The <code>arrow</code>-package follows <code>dplyr</code>-syntax regarding data preperation tasks. That is, we can directly build on functions like</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="big-data-cleaning-and-transformation.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="co"># merge the two datasets via arrow</span></span>
<span id="cb350-2"><a href="big-data-cleaning-and-transformation.html#cb350-2" aria-hidden="true" tabindex="-1"></a>flights.data.ar <span class="ot">&lt;-</span> <span class="fu">inner_join</span>(airlines, flights, <span class="at">by=</span><span class="st">&quot;AIRLINE_ID&quot;</span>)</span>
<span id="cb350-3"><a href="big-data-cleaning-and-transformation.html#cb350-3" aria-hidden="true" tabindex="-1"></a><span class="fu">object_size</span>(flights.data.ar)</span></code></pre></div>
<pre><code>## 647.74 kB</code></pre>
<p>In a last step, we filter the resulting dataset for cancelled flights and select only some of the available variables.</p>
<p>Now, we want to filter out some observations as well as select only specific variables for a subset of the overall data set. As arrow works with the <code>dplyr</code> backend, we can directly use the typical <code>dplyr</code>-syntax to combine selection of columns and filtering of rows.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="big-data-cleaning-and-transformation.html#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset the ff_files object flights.data.ff:</span></span>
<span id="cb352-2"><a href="big-data-cleaning-and-transformation.html#cb352-2" aria-hidden="true" tabindex="-1"></a>subs1.ar <span class="ot">&lt;-</span> </span>
<span id="cb352-3"><a href="big-data-cleaning-and-transformation.html#cb352-3" aria-hidden="true" tabindex="-1"></a>        flights.data.ar <span class="sc">%&gt;%</span></span>
<span id="cb352-4"><a href="big-data-cleaning-and-transformation.html#cb352-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(CANCELLED <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb352-5"><a href="big-data-cleaning-and-transformation.html#cb352-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">select</span>(FL_DATE,</span>
<span id="cb352-6"><a href="big-data-cleaning-and-transformation.html#cb352-6" aria-hidden="true" tabindex="-1"></a>               AIRLINE_ID,</span>
<span id="cb352-7"><a href="big-data-cleaning-and-transformation.html#cb352-7" aria-hidden="true" tabindex="-1"></a>               ORIGIN_CITY_NAME,</span>
<span id="cb352-8"><a href="big-data-cleaning-and-transformation.html#cb352-8" aria-hidden="true" tabindex="-1"></a>               ORIGIN_STATE_NM,</span>
<span id="cb352-9"><a href="big-data-cleaning-and-transformation.html#cb352-9" aria-hidden="true" tabindex="-1"></a>               DEST_CITY_NAME,</span>
<span id="cb352-10"><a href="big-data-cleaning-and-transformation.html#cb352-10" aria-hidden="true" tabindex="-1"></a>               DEST_STATE_NM,</span>
<span id="cb352-11"><a href="big-data-cleaning-and-transformation.html#cb352-11" aria-hidden="true" tabindex="-1"></a>               CANCELLATION_CODE)</span>
<span id="cb352-12"><a href="big-data-cleaning-and-transformation.html#cb352-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb352-13"><a href="big-data-cleaning-and-transformation.html#cb352-13" aria-hidden="true" tabindex="-1"></a><span class="fu">object_size</span>(subs1.ar)</span></code></pre></div>
<pre><code>## 591.21 kB</code></pre>
<p>Again, this operation hardly affected RAM usage by R. Note, though, that in contrast to the <code>ff</code>-approach, arrow has actually not yet created the new subset <code>sub1.ar</code>. In fact, it has not even really imported the data nor merged the two datasets. This is the effect of the <code>lazy evaluation</code>-approach implemented in <code>arrow</code>. To further process the data in <code>sub1.ar</code> with other functions (outside of <code>arrow</code>), we need to actually trigger the evaluation of all the data preparation steps we just have R instructed to do. This is done via <code>collect()</code>.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="big-data-cleaning-and-transformation.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_change</span>(subs1.ar.df <span class="ot">&lt;-</span> <span class="fu">collect</span>(subs1.ar))</span></code></pre></div>
<pre><code>## 2.47 MB</code></pre>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="big-data-cleaning-and-transformation.html#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(subs1.ar.df)</span></code></pre></div>
<pre><code>## [1] &quot;tbl_df&quot;     &quot;tbl&quot;        &quot;data.frame&quot;</code></pre>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="big-data-cleaning-and-transformation.html#cb358-1" aria-hidden="true" tabindex="-1"></a><span class="fu">object_size</span>(subs1.ar.df)</span></code></pre></div>
<pre><code>## 57.15 kB</code></pre>
<p>Note how in this tutorial, the final subset is substantially smaller than the initial two datasets. Hence, in this case it does not matter much to actually load the into RAM as a data frame. However, there is not even necessarily the need to load the final subset as data frame into R in your workflow. Instead of calling <code>collect()</code>, you can then trigger the computation of all the data preparation steps via <code>compute()</code> and, for example, store the resulting <code>Arrow Table</code> to a CSV-file.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="big-data-cleaning-and-transformation.html#cb360-1" aria-hidden="true" tabindex="-1"></a>subs1.ar <span class="sc">%&gt;%</span> </span>
<span id="cb360-2"><a href="big-data-cleaning-and-transformation.html#cb360-2" aria-hidden="true" tabindex="-1"></a>        <span class="fu">compute</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-3"><a href="big-data-cleaning-and-transformation.html#cb360-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">write_csv_arrow</span>(<span class="at">file=</span><span class="st">&quot;data/subs1.ar.csv&quot;</span>)</span></code></pre></div>
</div>
<div id="wrapping-up-5" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Wrapping up<a href="big-data-cleaning-and-transformation.html#wrapping-up-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Typically, the raw/uncleaned data is the critical bottleneck in terms of data volume. Particularly as the selection and filtering of the overall dataset in preparation of analytic datasets can only work properly with cleaned data.</li>
<li><em>Out-of-memory</em> strategies are based on the concept of virtual memory and are key to cleaning large amounts of data locally.</li>
<li>The <em><code>ff</code>-package</em> provides a high-level R-interface to an out-of-memory approach. Most functions in <code>ff</code> and the corresponding <code>ffbase</code>-package come with a syntax very similar to the basic R syntax for data cleaning and manipulation.</li>
<li>The basic idea behind <code>ff</code> is to store the data in chunked format in easy-accessible way on the hard disk and only keep the metadata of a dataset (e.g. variable names) in an R object in RAM while working on the dataset.</li>
<li>The <code>arrow</code>-package offers a similar functionality on a slightly different approach called <em>lazy evaluation</em> (only evaluate data manipulation/cleaning tasks once the data is pulled into R). Unlike <code>ff</code>, <code>arrow</code> closly follows the <code>dplyr</code>-syntax rather than basic R syntax for data cleaning tasks.</li>
</ul>
<!-- ```{r echo=FALSE, warning=FALSE, message=FALSE} -->
<!-- try(detach("package:ff", unload=TRUE, force = TRUE)) -->
<!-- try(detach("package:ffbase", unload=TRUE, force = TRUE)) -->
<!-- try(detach("package:doBy", unload=TRUE, force = TRUE)) -->
<!-- try(detach("package:vcd", unload=TRUE, force = TRUE)) -->
<!-- try(detach("package:data.table", unload = TRUE, force = TRUE)) -->
<!-- ``` -->
<!-- ```{r echo=FALSE, message=FALSE, warning=FALSE} -->
<!-- # remove all packages -->
<!-- packages <- names(sessionInfo()$otherPkgs) -->
<!-- packages <- packages[!packages %in% c("bookdown", "knitr", "rmarkdown")] -->
<!-- lapply(packages, function(pkgs) -->
<!--   detach( -->
<!--     paste0('package:', pkgs), -->
<!--     character.only = T, -->
<!--     unload = T, -->
<!--     force = T -->
<!--   )) -->
<!-- # close all connections -->
<!-- # DIZtools::close_all_connections() -->
<!-- # remove objects -->
<!-- #rm(list = ls()) -->
<!-- #gc()  -->
<!-- ``` -->

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-kane_etal2013" class="csl-entry">
Kane, Michael, John W. Emerson, and Stephen Weston. 2013. <span>“Scalable Strategies for Computing with Massive Data.”</span> <em>Journal of Statistical Software</em> 55 (14): 1–19. <a href="https://doi.org/10.18637/jss.v055.i14">https://doi.org/10.18637/jss.v055.i14</a>.
</div>
<div id="ref-richardson_etal2022" class="csl-entry">
Richardson, Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane, Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2022. <em>Arrow: Integration to ’Apache’ ’Arrow’</em>.
</div>
<div id="ref-walkowiak_2016" class="csl-entry">
Walkowiak, Simkon. 2016. <em>Big Data Analytics with r</em>. Birmingham, UK: PACKT Publishing.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="46">
<li id="fn46"><p>The full raw data used there can be downloaded <a href="http://stat-computing.org/dataexpo/2009/the-data.html">here</a>.<a href="big-data-cleaning-and-transformation.html#fnref46" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-collection-and-data-storage.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="descriptive-statistics-and-aggregation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
