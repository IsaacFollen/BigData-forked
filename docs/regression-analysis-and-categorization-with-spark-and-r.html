<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Regression Analysis and Categorization with Spark and R | Big Data Analytics</title>
  <meta name="description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Regression Analysis and Categorization with Spark and R | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://umatter.github.io/BigData/img/cover.jpg" />
  <meta property="og:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Regression Analysis and Categorization with Spark and R | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="twitter:image" content="https://umatter.github.io/BigData/img/cover.jpg" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2023-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="econometrics-with-gpus.html"/>
<link rel="next" href="large-scale-text-analysis-with-sparklyr.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#background-and-goals-of-this-book"><i class="fa fa-check"></i>Background and goals of this book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#a-moving-target"><i class="fa fa-check"></i>A moving target</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#content-and-organization-of-the-book"><i class="fa fa-check"></i>Content and organization of the book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#prerequisits-and-requirements"><i class="fa fa-check"></i>Prerequisits and requirements</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#thanks"><i class="fa fa-check"></i>Thanks</a></li>
</ul></li>
<li class="part"><span><b>I Setting the Scene: Analyzing Big Data</b></span></li>
<li class="chapter" data-level="" data-path="s.html"><a href="s.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="what-is-big-in-big-data.html"><a href="what-is-big-in-big-data.html"><i class="fa fa-check"></i><b>1</b> What is <em>Big</em> in “Big Data”?</a></li>
<li class="chapter" data-level="2" data-path="approaches-to-analyzing-big-data.html"><a href="approaches-to-analyzing-big-data.html"><i class="fa fa-check"></i><b>2</b> Approaches to Analyzing Big Data</a></li>
<li class="chapter" data-level="3" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html"><i class="fa fa-check"></i><b>3</b> The Two Domains of Big Data Analytics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>3.1</b> A practical <em>big P</em> problem </a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#simple-logistig-regression-naive-approach"><i class="fa fa-check"></i><b>3.1.1</b> Simple logistig regression (naive approach)</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#regularization-the-lasso-estimator"><i class="fa fa-check"></i><b>3.1.2</b> Regularization: the lasso estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>3.2</b> A practical <em>big N</em> problem </a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>3.2.1</b> OLS as a point of reference </a></li>
<li class="chapter" data-level="3.2.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>3.2.2</b> The <em>Uluru</em> algorithm as an alternative to OLS </a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Platform: Software and Computing Resources</b></span></li>
<li class="chapter" data-level="" data-path="p.html"><a href="p.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>4</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>4.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>4.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="4.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>4.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>4.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="4.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>4.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="4.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>4.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="4.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>4.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="4.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>4.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="4.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>4.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>4.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>4.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="4.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>4.4.2</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#with-a-little-help-from-my-friends-gpt-and-rsql-coding"><i class="fa fa-check"></i><b>4.5</b> With a little help from my friends: GPT and R/SQL coding</a></li>
<li class="chapter" data-level="4.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#wrapping-up"><i class="fa fa-check"></i><b>4.6</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>5</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>5.1</b> Mass storage</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoid-redundancies"><i class="fa fa-check"></i><b>5.1.1</b> Avoid redundancies</a></li>
<li class="chapter" data-level="5.1.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>5.1.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>5.2</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="5.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>5.3</b> Combining RAM and hard disk: Virtual memory</a></li>
<li class="chapter" data-level="5.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>5.4</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>5.4.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="5.4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-session-approach-with-futures"><i class="fa fa-check"></i><b>5.4.2</b> Multi-session approach with futures</a></li>
<li class="chapter" data-level="5.4.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>5.4.3</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>5.5</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>5.5.1</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The road ahead: Hardware made for machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#wrapping-up-1"><i class="fa fa-check"></i><b>5.7</b> Wrapping up</a></li>
<li class="chapter" data-level="5.8" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#still-have-insufficient-computing-resources"><i class="fa fa-check"></i><b>5.8</b> Still have insufficient computing resources?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>6</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>6.1</b> MapReduce</a></li>
<li class="chapter" data-level="6.2" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-hadoop"><i class="fa fa-check"></i><b>6.2</b> Apache Hadoop</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>6.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-spark"><i class="fa fa-check"></i><b>6.3</b> Apache Spark</a></li>
<li class="chapter" data-level="6.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>6.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>6.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="6.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>6.6</b> Spark with R + SQL</a></li>
<li class="chapter" data-level="6.7" data-path="distributed-systems.html"><a href="distributed-systems.html#wrapping-up-2"><i class="fa fa-check"></i><b>6.7</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>7</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cloud-computing.html"><a href="cloud-computing.html#cloud-computing-basics-and-platforms"><i class="fa fa-check"></i><b>7.1</b> Cloud computing basics and platforms</a></li>
<li class="chapter" data-level="7.2" data-path="cloud-computing.html"><a href="cloud-computing.html#transitioning-to-the-cloud"><i class="fa fa-check"></i><b>7.2</b> Transitioning to the cloud</a></li>
<li class="chapter" data-level="7.3" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-in-the-cloud-virtual-servers"><i class="fa fa-check"></i><b>7.3</b> Scaling up in the cloud: Virtual servers</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>7.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-gpus"><i class="fa fa-check"></i><b>7.4</b> Scaling up with GPUs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>7.4.1</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="7.4.2" data-path="cloud-computing.html"><a href="cloud-computing.html#rstudio-and-ec2-with-gpus-on-aws"><i class="fa fa-check"></i><b>7.4.2</b> RStudio and EC2 with GPUs on AWS</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-out-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>7.5</b> Scaling out: MapReduce in the cloud</a></li>
<li class="chapter" data-level="7.6" data-path="cloud-computing.html"><a href="cloud-computing.html#wrapping-up-3"><i class="fa fa-check"></i><b>7.6</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>III Components of Big Data Analytics</b></span></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>8</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>8.1</b> Gathering and compilation of raw data</a></li>
<li class="chapter" data-level="8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#stackcombine-raw-source-files"><i class="fa fa-check"></i><b>8.2</b> Stack/combine raw source files</a></li>
<li class="chapter" data-level="8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>8.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>8.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="8.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>8.3.2</b> Efficient data access: Indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-an-rdbms"><i class="fa fa-check"></i><b>8.4</b> Connecting R to an RDBMS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>8.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>8.4.2</b> Importing data</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issue-queries"><i class="fa fa-check"></i><b>8.4.3</b> Issue queries</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>8.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>8.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#column-based-analytics-databases"><i class="fa fa-check"></i><b>8.6</b> Column-based analytics databases</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#installation-and-start-up"><i class="fa fa-check"></i><b>8.6.1</b> Installation and start up</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#first-steps-via-druids-gui"><i class="fa fa-check"></i><b>8.6.2</b> First steps via Druid’s GUI</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#query-druid-from-r"><i class="fa fa-check"></i><b>8.6.3</b> Query Druid from R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouses"><i class="fa fa-check"></i><b>8.7</b> Data warehouses</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example"><i class="fa fa-check"></i><b>8.7.1</b> Data warehouse for analytics: Google BigQuery example</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service"><i class="fa fa-check"></i><b>8.8</b> Data lakes and simple storage service</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps"><i class="fa fa-check"></i><b>8.8.1</b> AWS S3 with R: First steps</a></li>
<li class="chapter" data-level="8.8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#uploading-data-to-s3"><i class="fa fa-check"></i><b>8.8.2</b> Uploading data to S3</a></li>
<li class="chapter" data-level="8.8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-amazon-athena"><i class="fa fa-check"></i><b>8.8.3</b> More than just simple storage: S3 + Amazon Athena</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#wrapping-up-4"><i class="fa fa-check"></i><b>8.9</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>9</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics"><i class="fa fa-check"></i><b>9.1</b> Out-of-memory strategies and lazy evaluation: Practical basics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>9.1.1</b> Chunking data with the <code>ff</code> package</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>9.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow"><i class="fa fa-check"></i><b>9.1.3</b> Connecting to Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-ff"><i class="fa fa-check"></i><b>9.2</b> Big Data preparation tutorial with <code>ff</code></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-import"><i class="fa fa-check"></i><b>9.2.2</b> Data import</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-imported-files"><i class="fa fa-check"></i><b>9.2.3</b> Inspect imported files</a></li>
<li class="chapter" data-level="9.2.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation"><i class="fa fa-check"></i><b>9.2.4</b> Data cleaning and transformation</a></li>
<li class="chapter" data-level="9.2.5" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-difference-to-in-memory-operation"><i class="fa fa-check"></i><b>9.2.5</b> Inspect difference to in-memory operation</a></li>
<li class="chapter" data-level="9.2.6" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#subsetting"><i class="fa fa-check"></i><b>9.2.6</b> Subsetting</a></li>
<li class="chapter" data-level="9.2.7" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#saveloadexport-ff-files"><i class="fa fa-check"></i><b>9.2.7</b> Save/load/export <code>ff</code> files</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-arrow"><i class="fa fa-check"></i><b>9.3</b> Big Data preparation tutorial with <code>arrow</code></a></li>
<li class="chapter" data-level="9.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#wrapping-up-5"><i class="fa fa-check"></i><b>9.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>10</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>10.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a></li>
<li class="chapter" data-level="10.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>10.2</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="10.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-arrow"><i class="fa fa-check"></i><b>10.3</b> High-speed in-memory data aggregation with <code>arrow</code></a></li>
<li class="chapter" data-level="10.4" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>10.4</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
<li class="chapter" data-level="10.5" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#wrapping-up-6"><i class="fa fa-check"></i><b>10.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>11</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#challenges-of-big-data-visualization"><i class="fa fa-check"></i><b>11.1</b> Challenges of Big Data visualization</a></li>
<li class="chapter" data-level="11.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>11.2</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="11.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualizing-time-and-space"><i class="fa fa-check"></i><b>11.3</b> Visualizing time and space</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>11.3.1</b> Preparations</a></li>
<li class="chapter" data-level="11.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>11.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#wrapping-up-7"><i class="fa fa-check"></i><b>11.4</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>IV Application: Topics in Big Data Econometrics</b></span></li>
<li class="chapter" data-level="" data-path="a.html"><a href="a.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html"><i class="fa fa-check"></i><b>12</b> Bottlenecks in Everyday Data Analytics Tasks</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>12.1</b> Case study: Efficient fixed effects estimation</a></li>
<li class="chapter" data-level="12.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>12.2</b> Case study: Loops, memory, and vectorization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>12.2.1</b> Naïve approach (ignorant of R)</a></li>
<li class="chapter" data-level="12.2.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>12.2.2</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="12.2.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>12.2.3</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>12.3</b> Case study: Bootstrapping and parallel processing</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>12.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html"><i class="fa fa-check"></i><b>13</b> Econometrics with GPUs</a>
<ul>
<li class="chapter" data-level="13.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#ols-on-gpus"><i class="fa fa-check"></i><b>13.1</b> OLS on GPUs</a></li>
<li class="chapter" data-level="13.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#a-word-of-caution"><i class="fa fa-check"></i><b>13.2</b> A word of caution</a></li>
<li class="chapter" data-level="13.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#higher-level-interfaces-for-basic-econometrics-with-gpus"><i class="fa fa-check"></i><b>13.3</b> Higher-level interfaces for basic econometrics with GPUs</a></li>
<li class="chapter" data-level="13.4" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>13.4</b> TensorFlow/Keras example: predict housing prices</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#data-preparation"><i class="fa fa-check"></i><b>13.4.1</b> Data preparation</a></li>
<li class="chapter" data-level="13.4.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#model-specification"><i class="fa fa-check"></i><b>13.4.2</b> Model specification</a></li>
<li class="chapter" data-level="13.4.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#training-and-prediction"><i class="fa fa-check"></i><b>13.4.3</b> Training and prediction</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#wrapping-up-8"><i class="fa fa-check"></i><b>13.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html"><i class="fa fa-check"></i><b>14</b> Regression Analysis and Categorization with Spark and R</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-linear-regression-analysis"><i class="fa fa-check"></i><b>14.1</b> Simple linear regression analysis</a></li>
<li class="chapter" data-level="14.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification"><i class="fa fa-check"></i><b>14.2</b> Machine learning for classification</a></li>
<li class="chapter" data-level="14.3" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark"><i class="fa fa-check"></i><b>14.3</b> Building machine learning pipelines with R and Spark</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import"><i class="fa fa-check"></i><b>14.3.1</b> Set up and data import</a></li>
<li class="chapter" data-level="14.3.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline"><i class="fa fa-check"></i><b>14.3.2</b> Building the pipeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-9"><i class="fa fa-check"></i><b>14.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html"><i class="fa fa-check"></i><b>15</b> Large-scale Text Analysis with sparklyr</a>
<ul>
<li class="chapter" data-level="15.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count"><i class="fa fa-check"></i><b>15.1</b> Getting started: Import, pre-processing, and word count</a></li>
<li class="chapter" data-level="15.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#tutorial-political-slant"><i class="fa fa-check"></i><b>15.2</b> Tutorial: political slant</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#data-download-and-import"><i class="fa fa-check"></i><b>15.2.1</b> Data download and import</a></li>
<li class="chapter" data-level="15.2.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#cleaning-speeches-data"><i class="fa fa-check"></i><b>15.2.2</b> Cleaning speeches data</a></li>
<li class="chapter" data-level="15.2.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#create-a-bigrams-count-per-party"><i class="fa fa-check"></i><b>15.2.3</b> Create a bigrams count per party</a></li>
<li class="chapter" data-level="15.2.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#find-partisan-phrases"><i class="fa fa-check"></i><b>15.2.4</b> Find “partisan” phrases</a></li>
<li class="chapter" data-level="15.2.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#results-most-partisan-phrases-by-congress"><i class="fa fa-check"></i><b>15.2.5</b> Results: most partisan phrases by congress</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#natural-language-processing-at-scale"><i class="fa fa-check"></i><b>15.3</b> Natural Language Processing at Scale</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#preparatory-steps"><i class="fa fa-check"></i><b>15.3.1</b> Preparatory steps</a></li>
<li class="chapter" data-level="15.3.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sentiment-annotation"><i class="fa fa-check"></i><b>15.3.2</b> Sentiment annotation</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#aggregation-and-visualization"><i class="fa fa-check"></i><b>15.4</b> Aggregation and visualization</a></li>
<li class="chapter" data-level="15.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sparklyr-and-lazy-evaluation"><i class="fa fa-check"></i><b>15.5</b> <code>sparklyr</code> and lazy evaluation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html"><i class="fa fa-check"></i>Appendix A: GitHub</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#initiate-a-new-repository"><i class="fa fa-check"></i>Initiate a new repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#clone-this-books-repository"><i class="fa fa-check"></i>Clone this book’s repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#fork-this-books-repository"><i class="fa fa-check"></i>Fork this book’s repository</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html"><i class="fa fa-check"></i>Appendix B: R Basics</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-types-and-memorystorage"><i class="fa fa-check"></i>Data types and memory/storage</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#example-data-types-and-information-storage"><i class="fa fa-check"></i>Example: Data types and information storage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-structures"><i class="fa fa-check"></i>Data structures</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i>Vectors vs Factors in R</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#matricesarrays"><i class="fa fa-check"></i>Matrices/Arrays</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-frames-tibbles-and-data-tables"><i class="fa fa-check"></i>Data frames, tibbles, and data tables</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i>R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-c-install-hadoop.html"><a href="appendix-c-install-hadoop.html"><i class="fa fa-check"></i>Appendix C: Install Hadoop</a></li>
<li class="part"><span><b>VI References and Index</b></span></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-analysis-and-categorization-with-spark-and-r" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">Chapter 14</span> Regression Analysis and Categorization with Spark and R<a href="regression-analysis-and-categorization-with-spark-and-r.html#regression-analysis-and-categorization-with-spark-and-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p></p>
<p>Regression analysis, particularly simple linear regression (OLS), is the backbone of applied econometrics. As discussed in previous chapters, regression analysis can be computationally very intensive with a dataset of many observations and variables, as it involves matrix operations on a very large model matrix. Chapter 12 discusses in one case study the special case of a large model matrix due to fixed-effects dummy variables. In this chapter, we first look at a generally applicable approach for estimating linear regression models with large datasets (when the model matrix cannot be held in RAM). Building on the same <code>sparklyr</code> framework <span class="citation">(<a href="#ref-sparklyr" role="doc-biblioref">Luraschi et al. 2022</a>)</span> as for the simple linear regression case, we then look at classification models, such as logit and random forest. Finally, we look at how regression analysis and machine learning tasks can be organized in machine learning pipelines to be run, stored/reloaded, and updated flexibly.</p>
<div id="simple-linear-regression-analysis" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Simple linear regression analysis<a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-linear-regression-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
Suppose we want to conduct a correlation study of what factors are associated with longer or shorter arrival delays in air travel. Via its built-in ‘MLib’ library, Spark provides several high-level functions to conduct regression analyses. When calling these functions via <code>sparklyr</code> (or <code>SparkR</code>), their usage is actually very similar to the usual R packages/functions commonly used to run regressions in R.</p>
<p>As a simple point of reference, we first estimate a linear model with the usual R approach (all computed in the R environment). First, we load the data as a common <code>data.table</code>. We could also convert a copy of the entire <code>SparkDataFrame</code> object to a <code>data.frame</code> or <code>data.table</code> and get essentially the same outcome. However, collecting the data from the RDD structure would take much longer than parsing the CSV with <code>fread</code>. In addition, we only import the first 300 rows. Running regression analysis with relatively large datasets in Spark on a small local machine might fail or be rather slow.<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a></p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb539-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flights_r &lt;- collect(flights) # very slow!</span></span>
<span id="cb539-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb539-2" aria-hidden="true" tabindex="-1"></a>flights_r <span class="ot">&lt;-</span> data.table<span class="sc">::</span><span class="fu">fread</span>(<span class="st">&quot;data/flights.csv&quot;</span>, <span class="at">nrows =</span> <span class="dv">300</span>) </span></code></pre></div>
<p>Now we run a simple linear regression (OLS) and show the summary output.</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify the linear model</span></span>
<span id="cb540-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-2" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> arr_delay <span class="sc">~</span> dep_delay <span class="sc">+</span> distance</span>
<span id="cb540-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model with OLS</span></span>
<span id="cb540-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-4" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(model1, flights_r)</span>
<span id="cb540-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compute t-tests etc.</span></span>
<span id="cb540-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb540-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = model1, data = flights_r)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -42.39  -9.96  -1.91   9.87  48.02 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.182662   1.676560   -0.11     0.91    
## dep_delay    0.989553   0.017282   57.26   &lt;2e-16 ***
## distance     0.000114   0.001239    0.09     0.93    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.5 on 297 degrees of freedom
## Multiple R-squared:  0.917,  Adjusted R-squared:  0.917 
## F-statistic: 1.65e+03 on 2 and 297 DF,  p-value: &lt;2e-16</code></pre>
<p>Now we aim to compute essentially the same model estimate in <code>sparklyr</code>.<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> In order to use Spark via the <code>sparklyr</code> package, we need to first load the package and establish a connection with Spark (similar to <code>SparkR::sparkR.session()</code>).</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb542-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb542-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb542-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb542-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb542-3" aria-hidden="true" tabindex="-1"></a><span class="co"># connect with default configuration</span></span>
<span id="cb542-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb542-4" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master=</span><span class="st">&quot;local&quot;</span>)</span></code></pre></div>
<p>We then copy the data.table <code>flights_r</code> (previously loaded into our R session) to Spark. Again, working on a normal laptop this seems trivial, but the exact same command would allow us (when connected with Spark on a cluster computer in the cloud) to properly load and distribute the data.table on the cluster. Finally, we then fit the model with <code>ml_linear_regression()</code> and compute.</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load data to spark</span></span>
<span id="cb543-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-2" aria-hidden="true" tabindex="-1"></a>flights_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, flights_r, <span class="st">&quot;flights_spark&quot;</span>)</span>
<span id="cb543-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model</span></span>
<span id="cb543-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-4" aria-hidden="true" tabindex="-1"></a>fit1_spark <span class="ot">&lt;-</span> <span class="fu">ml_linear_regression</span>(flights_spark, <span class="at">formula =</span> model1)</span>
<span id="cb543-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compute summary stats</span></span>
<span id="cb543-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb543-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1_spark)</span></code></pre></div>
<pre><code>Deviance Residuals:
    Min      1Q  Median      3Q     Max 
-42.386  -9.965  -1.911   9.866  48.024 

Coefficients:
  (Intercept)     dep_delay      distance 
-0.1826622687  0.9895529018  0.0001139616 

R-Squared: 0.9172
Root Mean Squared Error: 15.42</code></pre>
<p>Alternatively, we can use the <code>spark_apply()</code> function to run the regression analysis in R via the original R <code>lm()</code> function.<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a></p>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model</span></span>
<span id="cb545-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_apply</span>(flights_spark, </span>
<span id="cb545-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-3" aria-hidden="true" tabindex="-1"></a>            <span class="cf">function</span>(df){</span>
<span id="cb545-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-4" aria-hidden="true" tabindex="-1"></a>              broom<span class="sc">::</span><span class="fu">tidy</span>(<span class="fu">lm</span>(arr_delay <span class="sc">~</span> dep_delay <span class="sc">+</span> distance, df))},</span>
<span id="cb545-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">names =</span> <span class="fu">c</span>(<span class="st">&quot;term&quot;</span>, </span>
<span id="cb545-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-6" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;estimate&quot;</span>, </span>
<span id="cb545-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-7" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;std.error&quot;</span>, </span>
<span id="cb545-8"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-8" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;statistic&quot;</span>, </span>
<span id="cb545-9"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-9" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;p.value&quot;</span>)</span>
<span id="cb545-10"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb545-10" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
<pre><code># Source: spark&lt;?&gt; [?? x 5]
  term         estimate std.error statistic   p.value
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept) -0.183      1.68      -0.109  9.13e-  1
2 dep_delay    0.990      0.0173    57.3    1.63e-162
3 distance     0.000114   0.00124    0.0920 9.27e-  1</code></pre>
<p>Finally, the <code>parsnip</code> package <span class="citation">(<a href="#ref-parsnip" role="doc-biblioref">Kuhn and Vaughan 2022</a>)</span> (together with the <code>tidymodels</code> package; <span class="citation">Kuhn and Wickham (<a href="#ref-tidymodels" role="doc-biblioref">2020</a>)</span>) provides a simple interface to run the same model (or similar specifications) on different “engines” (estimators/fitting algorithms), and several of the <code>parsnip</code> models are also supported in <code>sparklyr</code>. This significantly facilitates the transition from local testing (with a small subset of the data) to running the estimation on the entire dataset on spark.</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb547-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parsnip)</span>
<span id="cb547-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb547-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-4" aria-hidden="true" tabindex="-1"></a><span class="co"># simple local linear regression example from above</span></span>
<span id="cb547-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-5" aria-hidden="true" tabindex="-1"></a><span class="co"># via tidymodels/parsnip</span></span>
<span id="cb547-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-6" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">fit</span>(<span class="fu">linear_reg</span>(<span class="at">engine=</span><span class="st">&quot;lm&quot;</span>), model1, <span class="at">data=</span>flights_r)</span>
<span id="cb547-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb547-7" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(fit1)</span></code></pre></div>
<pre><code># A tibble: 3 × 5
  term         estimate std.error statistic   p.value
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept) -0.183      1.68      -0.109  9.13e-  1
2 dep_delay    0.990      0.0173    57.3    1.63e-162
3 distance     0.000114   0.00124    0.0920 9.27e-  1</code></pre>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the same on Spark </span></span>
<span id="cb549-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb549-2" aria-hidden="true" tabindex="-1"></a>fit1_spark <span class="ot">&lt;-</span> <span class="fu">fit</span>(<span class="fu">linear_reg</span>(<span class="at">engine=</span><span class="st">&quot;spark&quot;</span>), model1, <span class="at">data=</span>flights_spark)</span>
<span id="cb549-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb549-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(fit1_spark)</span></code></pre></div>
<pre><code># A tibble: 3 × 5
  term         estimate std.error statistic   p.value
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept) -0.183      1.68      -0.109  9.13e-  1
2 dep_delay    0.990      0.0173    57.3    1.63e-162
3 distance     0.000114   0.00124    0.0920 9.27e-  1</code></pre>
<p>We will further build on this interface in the next section where we look at different machine learning procedures for a classification problem.</p>
</div>
<div id="machine-learning-for-classification" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Machine learning for classification<a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Building on <code>sparklyr</code>, <code>tidymodels</code>, and <code>parsnip</code>, we test a set of machine learning models on the classification problem discussed in <span class="citation">Varian (<a href="#ref-varian_2014" role="doc-biblioref">2014</a>)</span>: predicting Titanic survivors. The data for this exercise can be downloaded from here: <a href="http://doi.org/10.3886/E113925V1">http://doi.org/10.3886/E113925V1</a>.</p>
<p>We import and prepare the data in R.</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load into R, select variables of interest, remove missing</span></span>
<span id="cb551-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-2" aria-hidden="true" tabindex="-1"></a>titanic_r <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/titanic3.csv&quot;</span>)</span>
<span id="cb551-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-3" aria-hidden="true" tabindex="-1"></a>titanic_r <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(titanic_r[, <span class="fu">c</span>(<span class="st">&quot;survived&quot;</span>,</span>
<span id="cb551-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-4" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;pclass&quot;</span>,</span>
<span id="cb551-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-5" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;sex&quot;</span>,</span>
<span id="cb551-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-6" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;age&quot;</span>,</span>
<span id="cb551-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-7" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;sibsp&quot;</span>,</span>
<span id="cb551-8"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-8" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;parch&quot;</span>)])</span>
<span id="cb551-9"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb551-9" aria-hidden="true" tabindex="-1"></a>titanic_r<span class="sc">$</span>survived <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(titanic_r<span class="sc">$</span>survived<span class="sc">==</span><span class="dv">1</span>, <span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>)</span></code></pre></div>
<p>In order to assess the performance of the classifiers later on, we split the sample into training and test datasets. We do so with the help of the <code>rsample</code> package <span class="citation">(<a href="#ref-rsample" role="doc-biblioref">Frick et al. 2022</a>)</span>, which provides a number of high-level functions to facilitate this kind of pre-processing.</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb552-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb552-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-3" aria-hidden="true" tabindex="-1"></a><span class="co"># split into training and test set</span></span>
<span id="cb552-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-4" aria-hidden="true" tabindex="-1"></a>titanic_r <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(titanic_r)</span>
<span id="cb552-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-5" aria-hidden="true" tabindex="-1"></a>ti_training <span class="ot">&lt;-</span> <span class="fu">training</span>(titanic_r)</span>
<span id="cb552-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb552-6" aria-hidden="true" tabindex="-1"></a>ti_testing <span class="ot">&lt;-</span> <span class="fu">testing</span>(titanic_r)</span></code></pre></div>
<p>For the training and assessment of the classifiers, we transfer the two datasets to the spark cluster.</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb553-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load data to spark</span></span>
<span id="cb553-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb553-2" aria-hidden="true" tabindex="-1"></a>ti_training_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, ti_training, <span class="st">&quot;ti_training_spark&quot;</span>)</span>
<span id="cb553-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb553-3" aria-hidden="true" tabindex="-1"></a>ti_testing_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, ti_testing, <span class="st">&quot;ti_testing_spark&quot;</span>)</span></code></pre></div>
<p>Now we can set up a ‘horse race’ between different ML approaches to find the best performing model. Overall, we will consider the following models/algorithms:</p>
<ul>
<li>Logistic regression</li>
<li>Boosted trees</li>
<li>Random forest</li>
</ul>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-1" aria-hidden="true" tabindex="-1"></a><span class="co"># models to be used</span></span>
<span id="cb554-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-2" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">logit=</span><span class="fu">logistic_reg</span>(<span class="at">engine=</span><span class="st">&quot;spark&quot;</span>, <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>),</span>
<span id="cb554-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">btree=</span><span class="fu">boost_tree</span>(<span class="at">engine =</span> <span class="st">&quot;spark&quot;</span>, <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>),</span>
<span id="cb554-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">rforest=</span><span class="fu">rand_forest</span>(<span class="at">engine =</span> <span class="st">&quot;spark&quot;</span>, <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>))</span>
<span id="cb554-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-5" aria-hidden="true" tabindex="-1"></a><span class="co"># train/fit the models</span></span>
<span id="cb554-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb554-6" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">lapply</span>(models, fit, <span class="at">formula=</span>survived<span class="sc">~</span>., <span class="at">data=</span>ti_training_spark)</span></code></pre></div>
<p>The fitted models (trained algorithms) can now be assessed with the help of the test dataset. To this end, we use the high-level <code>accuracy</code> function provided in the <code>yardstick</code> package <span class="citation">(<a href="#ref-yardstick" role="doc-biblioref">Kuhn, Vaughan, and Hvitfeldt 2022</a>)</span> to compute the accuracy of the fitted models. We proceed in three steps. First, we use the fitted models to predict the outcomes (we classify cases into survived/did not survive) of the <em>test set</em>. Then we fetch the predictions from the Spark cluster, format the variables, and add the actual outcomes as an additional column.</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run predictions</span></span>
<span id="cb555-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">lapply</span>(fits, predict, <span class="at">new_data=</span>ti_testing_spark)</span>
<span id="cb555-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fetch predictions from Spark, format, add actual outcomes</span></span>
<span id="cb555-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-4" aria-hidden="true" tabindex="-1"></a>pred_outcomes <span class="ot">&lt;-</span> </span>
<span id="cb555-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-5" aria-hidden="true" tabindex="-1"></a>     <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(predictions), <span class="cf">function</span>(i){</span>
<span id="cb555-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-6" aria-hidden="true" tabindex="-1"></a>          x_r <span class="ot">&lt;-</span> <span class="fu">collect</span>(predictions[[i]]) <span class="co"># load into local R environment</span></span>
<span id="cb555-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-7" aria-hidden="true" tabindex="-1"></a>          x_r<span class="sc">$</span>pred_class <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(x_r<span class="sc">$</span>pred_class) <span class="co"># format for predictions</span></span>
<span id="cb555-8"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-8" aria-hidden="true" tabindex="-1"></a>          x_r<span class="sc">$</span>survived <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(ti_testing<span class="sc">$</span>survived) <span class="co"># add true outcomes</span></span>
<span id="cb555-9"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-9" aria-hidden="true" tabindex="-1"></a>          <span class="fu">return</span>(x_r)</span>
<span id="cb555-10"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-10" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb555-11"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb555-11" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<p>Finally, we compute the accuracy of the models, stack the results, and display them (ordered from best-performing to worst-performing.)</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb556-1" aria-hidden="true" tabindex="-1"></a>acc <span class="ot">&lt;-</span> <span class="fu">lapply</span>(pred_outcomes, accuracy, <span class="at">truth=</span><span class="st">&quot;survived&quot;</span>, <span class="at">estimate=</span><span class="st">&quot;pred_class&quot;</span>)</span>
<span id="cb556-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb556-2" aria-hidden="true" tabindex="-1"></a>acc <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(acc)</span>
<span id="cb556-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb556-3" aria-hidden="true" tabindex="-1"></a>acc<span class="sc">$</span>model <span class="ot">&lt;-</span> <span class="fu">names</span>(fits)</span>
<span id="cb556-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb556-4" aria-hidden="true" tabindex="-1"></a>acc[<span class="fu">order</span>(acc<span class="sc">$</span>.estimate, <span class="at">decreasing =</span> <span class="cn">TRUE</span>),]</span></code></pre></div>
<pre><code># A tibble: 3 × 4
  .metric  .estimator .estimate model  
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;  
1 accuracy binary         0.817 rforest
2 accuracy binary         0.790 btree  
3 accuracy binary         0.779 logit  </code></pre>
<p>In this simple example, all models perform similarly well. However, none of them really performs outstandingly. In a next step, we might want to learn about which variables are considered more or less important for the predictions. Here, the <code>tidy()</code> function is very useful. As long as the model types are comparable (here <code>btree</code> and <code>rforest</code>), <code>tidy()</code> delivers essentially the same type of summary for different models.</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb558-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(fits[[<span class="st">&quot;btree&quot;</span>]])</span></code></pre></div>
<pre><code># A tibble: 5 × 2
  feature  importance
  &lt;chr&gt;         &lt;dbl&gt;
1 age          0.415 
2 sex_male     0.223 
3 pclass       0.143 
4 sibsp        0.120 
5 parch        0.0987</code></pre>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb560-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(fits[[<span class="st">&quot;rforest&quot;</span>]])</span></code></pre></div>
<pre><code># A tibble: 5 × 2
  feature  importance
  &lt;chr&gt;         &lt;dbl&gt;
1 sex_male     0.604 
2 pclass       0.188 
3 age          0.120 
4 sibsp        0.0595
5 parch        0.0290</code></pre>
<p>Finally, we clean up and disconnect from the Spark cluster.</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb562-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span></code></pre></div>
</div>
<div id="building-machine-learning-pipelines-with-r-and-spark" class="section level2 hasAnchor" number="14.3">
<h2><span class="header-section-number">14.3</span> Building machine learning pipelines with R and Spark<a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>Spark provides a framework to implement machine learning pipelines called <a href="https://spark.apache.org/docs/latest/ml-pipeline.html">ML Pipelines</a>, with the aim of facilitating the combination of various preparatory steps and ML algorithms into a pipeline/workflow. <code>sparklyr</code> provides a straightforward interface to ML Pipelines that allows implementing and testing the entire ML workflow in R and then easily deploying the final pipeline to a Spark cluster or more generally to the production environment. In the following example, we will revisit the e-commerce purchase prediction model (Google Analytics data from the Google Merchandise Shop) introduced in Chapter 1. That is, we want to prepare the Google Analytics data and then use lasso to find a set of important predictors for purchase decisions, all built into a machine learning pipeline\index{Machine learning pipeline.</p>
<div id="set-up-and-data-import" class="section level3 hasAnchor" number="14.3.1">
<h3><span class="header-section-number">14.3.1</span> Set up and data import<a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>All of the key ingredients are provided in <code>sparklyr</code>. However, I recommend using the ‘piping’ syntax provided in <code>dplyr</code> <span class="citation">(<a href="#ref-dplyr" role="doc-biblioref">Wickham et al. 2023</a>)</span> to implement the machine learning pipeline. In this context, using this syntax is particularly helpful to make the code easy to read and understand.</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb563-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb563-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb563-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb563-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb563-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb563-6" aria-hidden="true" tabindex="-1"></a>INPUT_DATA <span class="ot">&lt;-</span> <span class="st">&quot;data/ga.csv&quot;</span></span></code></pre></div>
<p>Recall that the Google Analytics dataset is a small subset of the overall data generated by Google Analytics on a moderately sized e-commerce site. Hence, it makes perfect sense to first implement and test the pipeline locally (on a local Spark installation) before deploying it on an actual Spark cluster in the cloud. In a first step, we thus copy the imported data to the local Spark instance.</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import to local R session, prepare raw data</span></span>
<span id="cb564-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-2" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(<span class="fu">read.csv</span>(INPUT_DATA))</span>
<span id="cb564-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-3" aria-hidden="true" tabindex="-1"></a><span class="co">#ga$purchase &lt;- as.factor(ifelse(ga$purchase==1, &quot;yes&quot;, &quot;no&quot;))</span></span>
<span id="cb564-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-4" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to, and copy the data to the local cluster</span></span>
<span id="cb564-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-5" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">&quot;local&quot;</span>)</span>
<span id="cb564-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb564-6" aria-hidden="true" tabindex="-1"></a>ga_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, ga, <span class="st">&quot;ga_spark&quot;</span>, <span class="at">overwrite =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="building-the-pipeline" class="section level3 hasAnchor" number="14.3.2">
<h3><span class="header-section-number">14.3.2</span> Building the pipeline<a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The pipeline object is initialized via <code>ml_pipeline()</code>, in which we refer to the connection to the local Spark cluster. We then add the model specification (the formula) to the pipeline with <code>ft_r_formula()</code>. <code>ft_r_formula</code> essentially transforms the data in accordance with the common specification syntax in R (here: <code>purchase ~ .</code>). Among other things, this takes care of properly setting up the model matrix. Finally, we add the model via <code>ml_logistic_regression()</code>. We can set the penalization parameters via <code>elastic_net_param</code> (with <code>alpha=1</code>, we get the lasso).</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ml pipeline</span></span>
<span id="cb565-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-2" aria-hidden="true" tabindex="-1"></a>ga_pipeline <span class="ot">&lt;-</span> </span>
<span id="cb565-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ml_pipeline</span>(sc) <span class="sc">%&gt;%</span></span>
<span id="cb565-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_string_indexer</span>(<span class="at">input_col=</span><span class="st">&quot;city&quot;</span>, </span>
<span id="cb565-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output_col=</span><span class="st">&quot;city_output&quot;</span>,</span>
<span id="cb565-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">handle_invalid =</span> <span class="st">&quot;skip&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_string_indexer</span>(<span class="at">input_col=</span><span class="st">&quot;country&quot;</span>, </span>
<span id="cb565-8"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output_col=</span><span class="st">&quot;country_output&quot;</span>,</span>
<span id="cb565-9"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">handle_invalid =</span> <span class="st">&quot;skip&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-10"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-10" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_string_indexer</span>(<span class="at">input_col=</span><span class="st">&quot;source&quot;</span>, </span>
<span id="cb565-11"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-11" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output_col=</span><span class="st">&quot;source_output&quot;</span>,</span>
<span id="cb565-12"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-12" aria-hidden="true" tabindex="-1"></a>                       <span class="at">handle_invalid =</span> <span class="st">&quot;skip&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-13"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-13" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_string_indexer</span>(<span class="at">input_col=</span><span class="st">&quot;browser&quot;</span>, </span>
<span id="cb565-14"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-14" aria-hidden="true" tabindex="-1"></a>                       <span class="at">output_col=</span><span class="st">&quot;browser_output&quot;</span>,</span>
<span id="cb565-15"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-15" aria-hidden="true" tabindex="-1"></a>                       <span class="at">handle_invalid =</span> <span class="st">&quot;skip&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-16"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_r_formula</span>(purchase <span class="sc">~</span> .) <span class="sc">%&gt;%</span> </span>
<span id="cb565-17"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb565-17" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ml_logistic_regression</span>(<span class="at">elastic_net_param =</span> <span class="fu">list</span>(<span class="at">alpha=</span><span class="dv">1</span>))</span></code></pre></div>
<p>Finally, we create a cross-validator object to train the model with a k-fold cross-validation and fit the model.
For the sake of the example, we use only a 30-fold cross validation (to be run in parallel on 8 cores).</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify the hyperparameter grid</span></span>
<span id="cb566-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (parameter values to be considered in optimization)</span></span>
<span id="cb566-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-3" aria-hidden="true" tabindex="-1"></a>ga_params <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">logistic_regression=</span><span class="fu">list</span>(<span class="at">max_iter=</span><span class="dv">80</span>))</span>
<span id="cb566-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb566-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-5" aria-hidden="true" tabindex="-1"></a><span class="co"># create the cross-validator object</span></span>
<span id="cb566-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb566-7"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-7" aria-hidden="true" tabindex="-1"></a>cv_lasso <span class="ot">&lt;-</span> <span class="fu">ml_cross_validator</span>(sc,</span>
<span id="cb566-8"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">estimator=</span>ga_pipeline,</span>
<span id="cb566-9"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">estimator_param_maps =</span> ga_params,</span>
<span id="cb566-10"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-10" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">ml_binary_classification_evaluator</span>(sc),</span>
<span id="cb566-11"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-11" aria-hidden="true" tabindex="-1"></a>                         <span class="at">num_folds =</span> <span class="dv">30</span>, </span>
<span id="cb566-12"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-12" aria-hidden="true" tabindex="-1"></a>                         <span class="at">parallelism =</span> <span class="dv">8</span>)</span>
<span id="cb566-13"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb566-14"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-14" aria-hidden="true" tabindex="-1"></a><span class="co"># train/fit the model</span></span>
<span id="cb566-15"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-15" aria-hidden="true" tabindex="-1"></a>cv_lasso_fit <span class="ot">&lt;-</span> <span class="fu">ml_fit</span>(cv_lasso, ga_spark) </span>
<span id="cb566-16"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb566-16" aria-hidden="true" tabindex="-1"></a><span class="co"># note: this takes several minutes to run on a local machine (1 node, 8 cores)</span></span></code></pre></div>
<p>Finally, we can inspect and further process the results – in particular the model’s performance.</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pipeline summary </span></span>
<span id="cb567-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb567-2" aria-hidden="true" tabindex="-1"></a><span class="co"># cv_lasso_fit</span></span>
<span id="cb567-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb567-3" aria-hidden="true" tabindex="-1"></a><span class="co"># average performance</span></span>
<span id="cb567-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb567-4" aria-hidden="true" tabindex="-1"></a>cv_lasso_fit<span class="sc">$</span>avg_metrics_df</span></code></pre></div>
<pre><code>  areaUnderROC max_iter_1
1    0.8666304         80</code></pre>
<p>Before closing the connection to the Spark cluster, we can save the entire pipeline to work further with it later on.</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save the entire pipeline/fit</span></span>
<span id="cb569-2"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ml_save</span>(</span>
<span id="cb569-3"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-3" aria-hidden="true" tabindex="-1"></a>  cv_lasso_fit,</span>
<span id="cb569-4"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;ga_cv_lasso_fit&quot;</span>,</span>
<span id="cb569-5"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">overwrite =</span> <span class="cn">TRUE</span></span>
<span id="cb569-6"><a href="regression-analysis-and-categorization-with-spark-and-r.html#cb569-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>To reload the pipeline later on, run <code>ml_load(sc, "ga_cv_lasso_fit")</code>.</p>
</div>
</div>
<div id="wrapping-up-9" class="section level2 hasAnchor" number="14.4">
<h2><span class="header-section-number">14.4</span> Wrapping up<a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The key take-aways from this chapter are:</p>
<ul>
<li>When running econometric analysis such as linear or logistic regressions with massive amounts of data, <code>sparklyr</code> provides all the basic functions you need.</li>
<li>You can test your code on your local spark installation by connecting to the local ‘cluster’: <code>spark_connect(master="local")</code>. This allows you to test your entire regression analysis script locally (on a sub-sample) before running the exact same script via a connection to a large spark cluster on AWS EMR. To do so, simply connect to the cluster via <code>spark_connect(master = "yarn")</code> from RStudio server, following the setup introduced in Section 8.4.</li>
<li>The <code>rsample</code> package provides easy-to-use high-level functions to split your dataset into training and test datasets: See <code>?initial_split</code>, <code>?training</code>, and <code>?testing</code>.</li>
<li>The <code>parsnip</code> and <code>broom</code> packages <span class="citation">(<a href="#ref-broom" role="doc-biblioref">Robinson, Hayes, and Couch 2022</a>)</span> provide a way to easily standardize regression output. This is very helpful if you want to verify your regression analysis implementation for Spark with the more familiar R regression frameworks such as <code>lm()</code>. For example, compare the standard R OLS output with the linear regression output computed on a Spark cluster: <code>fit(linear_reg(engine="lm"), model1, data=flights_r)</code> for R’s standard OLS; <code>fit(linear_reg(engine="spark"), model1, data=flights_r)</code> for Spark.</li>
<li>For more advanced users, <code>sparklyr</code> provides a straightforward way to efficiently implement entire Spark machine learning pipelines in an R script via <code>ml_pipeline(sc)</code> and the <code>dplyr</code>-style pipe operators <code>%&gt;%</code>, including model specification, data preparation, and selection and specification of the estimator.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-rsample" class="csl-entry">
Frick, Hannah, Fanny Chow, Max Kuhn, Michael Mahoney, Julia Silge, and Hadley Wickham. 2022. <em>Rsample: General Resampling Infrastructure</em>. <a href="https://CRAN.R-project.org/package=rsample">https://CRAN.R-project.org/package=rsample</a>.
</div>
<div id="ref-parsnip" class="csl-entry">
Kuhn, Max, and Davis Vaughan. 2022. <em>Parsnip: A Common API to Modeling and Analysis Functions</em>. <a href="https://CRAN.R-project.org/package=parsnip">https://CRAN.R-project.org/package=parsnip</a>.
</div>
<div id="ref-yardstick" class="csl-entry">
Kuhn, Max, Davis Vaughan, and Emil Hvitfeldt. 2022. <em>Yardstick: Tidy Characterizations of Model Performance</em>. <a href="https://CRAN.R-project.org/package=yardstick">https://CRAN.R-project.org/package=yardstick</a>.
</div>
<div id="ref-tidymodels" class="csl-entry">
Kuhn, Max, and Hadley Wickham. 2020. <em>Tidymodels: A Collection of Packages for Modeling and Machine Learning Using Tidyverse Principles.</em> <a href="https://www.tidymodels.org">https://www.tidymodels.org</a>.
</div>
<div id="ref-sparklyr" class="csl-entry">
Luraschi, Javier, Kevin Kuo, Kevin Ushey, JJ Allaire, Hossein Falaki, Lu Wang, Andy Zhang, Yitao Li, Edgar Ruiz, and The Apache Software Foundation. 2022. <em><span class="nocase">sparklyr: R Interface to Apache Spark</span></em>. <a href="https://spark.rstudio.com/">https://spark.rstudio.com/</a>.
</div>
<div id="ref-broom" class="csl-entry">
Robinson, David, Alex Hayes, and Simon Couch. 2022. <em>Broom: Convert Statistical Objects into Tidy Tibbles</em>. <a href="https://CRAN.R-project.org/package=broom">https://CRAN.R-project.org/package=broom</a>.
</div>
<div id="ref-varian_2014" class="csl-entry">
Varian, Hal R. 2014. <span>“Big Data: New Tricks for Econometrics.”</span> <em>Journal of Economic Perspectives</em> 28 (2): 3–28. <a href="https://doi.org/10.1257/jep.28.2.3">https://doi.org/10.1257/jep.28.2.3</a>.
</div>
<div id="ref-dplyr" class="csl-entry">
Wickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="73">
<li id="fn73"><p>Again, it is important to keep in mind that running Spark on a small local machine is only optimal for learning and testing code (based on relatively small samples). The whole framework is optimized to be run on cluster computers.<a href="regression-analysis-and-categorization-with-spark-and-r.html#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p>Most regression models commonly used in traditional applied econometrics are provided in some form in <code>sparklyr</code> or <code>SparkR</code>. See the package documentation for more details.<a href="regression-analysis-and-categorization-with-spark-and-r.html#fnref74" class="footnote-back">↩︎</a></p></li>
<li id="fn75"><p>Note, though, that this approach might take longer.<a href="regression-analysis-and-categorization-with-spark-and-r.html#fnref75" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="econometrics-with-gpus.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="large-scale-text-analysis-with-sparklyr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
