<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 Large-scale Text Analysis with sparklyr | Big Data Analytics</title>
  <meta name="description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 Large-scale Text Analysis with sparklyr | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://umatter.github.io/BigData/img/cover.jpg" />
  <meta property="og:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 Large-scale Text Analysis with sparklyr | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="twitter:image" content="https://umatter.github.io/BigData/img/cover.jpg" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2023-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-analysis-and-categorization-with-spark-and-r.html"/>
<link rel="next" href="appendix-a-github.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#background-and-goals-of-this-book"><i class="fa fa-check"></i>Background and goals of this book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#a-moving-target"><i class="fa fa-check"></i>A moving target</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#content-and-organization-of-the-book"><i class="fa fa-check"></i>Content and organization of the book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#prerequisits-and-requirements"><i class="fa fa-check"></i>Prerequisits and requirements</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#thanks"><i class="fa fa-check"></i>Thanks</a></li>
</ul></li>
<li class="part"><span><b>I Setting the Scene: Analyzing Big Data</b></span></li>
<li class="chapter" data-level="" data-path="s.html"><a href="s.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="what-is-big-in-big-data.html"><a href="what-is-big-in-big-data.html"><i class="fa fa-check"></i><b>1</b> What is <em>Big</em> in “Big Data”?</a></li>
<li class="chapter" data-level="2" data-path="approaches-to-analyzing-big-data.html"><a href="approaches-to-analyzing-big-data.html"><i class="fa fa-check"></i><b>2</b> Approaches to Analyzing Big Data</a></li>
<li class="chapter" data-level="3" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html"><i class="fa fa-check"></i><b>3</b> The Two Domains of Big Data Analytics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>3.1</b> A practical <em>big P</em> problem </a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#simple-logistig-regression-naive-approach"><i class="fa fa-check"></i><b>3.1.1</b> Simple logistig regression (naive approach)</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#regularization-the-lasso-estimator"><i class="fa fa-check"></i><b>3.1.2</b> Regularization: the lasso estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>3.2</b> A practical <em>big N</em> problem </a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>3.2.1</b> OLS as a point of reference </a></li>
<li class="chapter" data-level="3.2.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>3.2.2</b> The <em>Uluru</em> algorithm as an alternative to OLS </a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Platform: Software and Computing Resources</b></span></li>
<li class="chapter" data-level="" data-path="p.html"><a href="p.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>4</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>4.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>4.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="4.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>4.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>4.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="4.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>4.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="4.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>4.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="4.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>4.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="4.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>4.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="4.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>4.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>4.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>4.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="4.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>4.4.2</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#with-a-little-help-from-my-friends-gpt-and-rsql-coding"><i class="fa fa-check"></i><b>4.5</b> With a little help from my friends: GPT and R/SQL coding</a></li>
<li class="chapter" data-level="4.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#wrapping-up"><i class="fa fa-check"></i><b>4.6</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>5</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>5.1</b> Mass storage</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoid-redundancies"><i class="fa fa-check"></i><b>5.1.1</b> Avoid redundancies</a></li>
<li class="chapter" data-level="5.1.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>5.1.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>5.2</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="5.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>5.3</b> Combining RAM and hard disk: Virtual memory</a></li>
<li class="chapter" data-level="5.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>5.4</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>5.4.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="5.4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-session-approach-with-futures"><i class="fa fa-check"></i><b>5.4.2</b> Multi-session approach with futures</a></li>
<li class="chapter" data-level="5.4.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>5.4.3</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>5.5</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>5.5.1</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The road ahead: Hardware made for machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#wrapping-up-1"><i class="fa fa-check"></i><b>5.7</b> Wrapping up</a></li>
<li class="chapter" data-level="5.8" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#still-have-insufficient-computing-resources"><i class="fa fa-check"></i><b>5.8</b> Still have insufficient computing resources?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>6</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>6.1</b> MapReduce</a></li>
<li class="chapter" data-level="6.2" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-hadoop"><i class="fa fa-check"></i><b>6.2</b> Apache Hadoop</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>6.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-spark"><i class="fa fa-check"></i><b>6.3</b> Apache Spark</a></li>
<li class="chapter" data-level="6.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>6.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>6.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="6.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>6.6</b> Spark with R + SQL</a></li>
<li class="chapter" data-level="6.7" data-path="distributed-systems.html"><a href="distributed-systems.html#wrapping-up-2"><i class="fa fa-check"></i><b>6.7</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>7</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cloud-computing.html"><a href="cloud-computing.html#cloud-computing-basics-and-platforms"><i class="fa fa-check"></i><b>7.1</b> Cloud computing basics and platforms</a></li>
<li class="chapter" data-level="7.2" data-path="cloud-computing.html"><a href="cloud-computing.html#transitioning-to-the-cloud"><i class="fa fa-check"></i><b>7.2</b> Transitioning to the cloud</a></li>
<li class="chapter" data-level="7.3" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-in-the-cloud-virtual-servers"><i class="fa fa-check"></i><b>7.3</b> Scaling up in the cloud: Virtual servers</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>7.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-gpus"><i class="fa fa-check"></i><b>7.4</b> Scaling up with GPUs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>7.4.1</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="7.4.2" data-path="cloud-computing.html"><a href="cloud-computing.html#rstudio-and-ec2-with-gpus-on-aws"><i class="fa fa-check"></i><b>7.4.2</b> RStudio and EC2 with GPUs on AWS</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-out-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>7.5</b> Scaling out: MapReduce in the cloud</a></li>
<li class="chapter" data-level="7.6" data-path="cloud-computing.html"><a href="cloud-computing.html#wrapping-up-3"><i class="fa fa-check"></i><b>7.6</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>III Components of Big Data Analytics</b></span></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>8</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>8.1</b> Gathering and compilation of raw data</a></li>
<li class="chapter" data-level="8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#stackcombine-raw-source-files"><i class="fa fa-check"></i><b>8.2</b> Stack/combine raw source files</a></li>
<li class="chapter" data-level="8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>8.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>8.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="8.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>8.3.2</b> Efficient data access: Indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-an-rdbms"><i class="fa fa-check"></i><b>8.4</b> Connecting R to an RDBMS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>8.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>8.4.2</b> Importing data</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issue-queries"><i class="fa fa-check"></i><b>8.4.3</b> Issue queries</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>8.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>8.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#column-based-analytics-databases"><i class="fa fa-check"></i><b>8.6</b> Column-based analytics databases</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#installation-and-start-up"><i class="fa fa-check"></i><b>8.6.1</b> Installation and start up</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#first-steps-via-druids-gui"><i class="fa fa-check"></i><b>8.6.2</b> First steps via Druid’s GUI</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#query-druid-from-r"><i class="fa fa-check"></i><b>8.6.3</b> Query Druid from R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouses"><i class="fa fa-check"></i><b>8.7</b> Data warehouses</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example"><i class="fa fa-check"></i><b>8.7.1</b> Data warehouse for analytics: Google BigQuery example</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service"><i class="fa fa-check"></i><b>8.8</b> Data lakes and simple storage service</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps"><i class="fa fa-check"></i><b>8.8.1</b> AWS S3 with R: First steps</a></li>
<li class="chapter" data-level="8.8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#uploading-data-to-s3"><i class="fa fa-check"></i><b>8.8.2</b> Uploading data to S3</a></li>
<li class="chapter" data-level="8.8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-amazon-athena"><i class="fa fa-check"></i><b>8.8.3</b> More than just simple storage: S3 + Amazon Athena</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#wrapping-up-4"><i class="fa fa-check"></i><b>8.9</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>9</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics"><i class="fa fa-check"></i><b>9.1</b> Out-of-memory strategies and lazy evaluation: Practical basics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>9.1.1</b> Chunking data with the <code>ff</code> package</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>9.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow"><i class="fa fa-check"></i><b>9.1.3</b> Connecting to Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-ff"><i class="fa fa-check"></i><b>9.2</b> Big Data preparation tutorial with <code>ff</code></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-import"><i class="fa fa-check"></i><b>9.2.2</b> Data import</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-imported-files"><i class="fa fa-check"></i><b>9.2.3</b> Inspect imported files</a></li>
<li class="chapter" data-level="9.2.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation"><i class="fa fa-check"></i><b>9.2.4</b> Data cleaning and transformation</a></li>
<li class="chapter" data-level="9.2.5" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-difference-to-in-memory-operation"><i class="fa fa-check"></i><b>9.2.5</b> Inspect difference to in-memory operation</a></li>
<li class="chapter" data-level="9.2.6" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#subsetting"><i class="fa fa-check"></i><b>9.2.6</b> Subsetting</a></li>
<li class="chapter" data-level="9.2.7" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#saveloadexport-ff-files"><i class="fa fa-check"></i><b>9.2.7</b> Save/load/export <code>ff</code> files</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-arrow"><i class="fa fa-check"></i><b>9.3</b> Big Data preparation tutorial with <code>arrow</code></a></li>
<li class="chapter" data-level="9.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#wrapping-up-5"><i class="fa fa-check"></i><b>9.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>10</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>10.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a></li>
<li class="chapter" data-level="10.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>10.2</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="10.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-arrow"><i class="fa fa-check"></i><b>10.3</b> High-speed in-memory data aggregation with <code>arrow</code></a></li>
<li class="chapter" data-level="10.4" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>10.4</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
<li class="chapter" data-level="10.5" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#wrapping-up-6"><i class="fa fa-check"></i><b>10.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>11</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#challenges-of-big-data-visualization"><i class="fa fa-check"></i><b>11.1</b> Challenges of Big Data visualization</a></li>
<li class="chapter" data-level="11.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>11.2</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="11.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualizing-time-and-space"><i class="fa fa-check"></i><b>11.3</b> Visualizing time and space</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>11.3.1</b> Preparations</a></li>
<li class="chapter" data-level="11.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>11.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#wrapping-up-7"><i class="fa fa-check"></i><b>11.4</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>IV Application: Topics in Big Data Econometrics</b></span></li>
<li class="chapter" data-level="" data-path="a.html"><a href="a.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html"><i class="fa fa-check"></i><b>12</b> Bottlenecks in Everyday Data Analytics Tasks</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>12.1</b> Case study: Efficient fixed effects estimation</a></li>
<li class="chapter" data-level="12.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>12.2</b> Case study: Loops, memory, and vectorization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>12.2.1</b> Naïve approach (ignorant of R)</a></li>
<li class="chapter" data-level="12.2.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>12.2.2</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="12.2.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>12.2.3</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>12.3</b> Case study: Bootstrapping and parallel processing</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>12.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html"><i class="fa fa-check"></i><b>13</b> Econometrics with GPUs</a>
<ul>
<li class="chapter" data-level="13.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#ols-on-gpus"><i class="fa fa-check"></i><b>13.1</b> OLS on GPUs</a></li>
<li class="chapter" data-level="13.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#a-word-of-caution"><i class="fa fa-check"></i><b>13.2</b> A word of caution</a></li>
<li class="chapter" data-level="13.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#higher-level-interfaces-for-basic-econometrics-with-gpus"><i class="fa fa-check"></i><b>13.3</b> Higher-level interfaces for basic econometrics with GPUs</a></li>
<li class="chapter" data-level="13.4" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>13.4</b> TensorFlow/Keras example: predict housing prices</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#data-preparation"><i class="fa fa-check"></i><b>13.4.1</b> Data preparation</a></li>
<li class="chapter" data-level="13.4.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#model-specification"><i class="fa fa-check"></i><b>13.4.2</b> Model specification</a></li>
<li class="chapter" data-level="13.4.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#training-and-prediction"><i class="fa fa-check"></i><b>13.4.3</b> Training and prediction</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#wrapping-up-8"><i class="fa fa-check"></i><b>13.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html"><i class="fa fa-check"></i><b>14</b> Regression Analysis and Categorization with Spark and R</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-linear-regression-analysis"><i class="fa fa-check"></i><b>14.1</b> Simple linear regression analysis</a></li>
<li class="chapter" data-level="14.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification"><i class="fa fa-check"></i><b>14.2</b> Machine learning for classification</a></li>
<li class="chapter" data-level="14.3" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark"><i class="fa fa-check"></i><b>14.3</b> Building machine learning pipelines with R and Spark</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import"><i class="fa fa-check"></i><b>14.3.1</b> Set up and data import</a></li>
<li class="chapter" data-level="14.3.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline"><i class="fa fa-check"></i><b>14.3.2</b> Building the pipeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-9"><i class="fa fa-check"></i><b>14.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html"><i class="fa fa-check"></i><b>15</b> Large-scale Text Analysis with sparklyr</a>
<ul>
<li class="chapter" data-level="15.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count"><i class="fa fa-check"></i><b>15.1</b> Getting started: Import, pre-processing, and word count</a></li>
<li class="chapter" data-level="15.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#tutorial-political-slant"><i class="fa fa-check"></i><b>15.2</b> Tutorial: political slant</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#data-download-and-import"><i class="fa fa-check"></i><b>15.2.1</b> Data download and import</a></li>
<li class="chapter" data-level="15.2.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#cleaning-speeches-data"><i class="fa fa-check"></i><b>15.2.2</b> Cleaning speeches data</a></li>
<li class="chapter" data-level="15.2.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#create-a-bigrams-count-per-party"><i class="fa fa-check"></i><b>15.2.3</b> Create a bigrams count per party</a></li>
<li class="chapter" data-level="15.2.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#find-partisan-phrases"><i class="fa fa-check"></i><b>15.2.4</b> Find “partisan” phrases</a></li>
<li class="chapter" data-level="15.2.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#results-most-partisan-phrases-by-congress"><i class="fa fa-check"></i><b>15.2.5</b> Results: most partisan phrases by congress</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#natural-language-processing-at-scale"><i class="fa fa-check"></i><b>15.3</b> Natural Language Processing at Scale</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#preparatory-steps"><i class="fa fa-check"></i><b>15.3.1</b> Preparatory steps</a></li>
<li class="chapter" data-level="15.3.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sentiment-annotation"><i class="fa fa-check"></i><b>15.3.2</b> Sentiment annotation</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#aggregation-and-visualization"><i class="fa fa-check"></i><b>15.4</b> Aggregation and visualization</a></li>
<li class="chapter" data-level="15.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sparklyr-and-lazy-evaluation"><i class="fa fa-check"></i><b>15.5</b> <code>sparklyr</code> and lazy evaluation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html"><i class="fa fa-check"></i>Appendix A: GitHub</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#initiate-a-new-repository"><i class="fa fa-check"></i>Initiate a new repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#clone-this-books-repository"><i class="fa fa-check"></i>Clone this book’s repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#fork-this-books-repository"><i class="fa fa-check"></i>Fork this book’s repository</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html"><i class="fa fa-check"></i>Appendix B: R Basics</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-types-and-memorystorage"><i class="fa fa-check"></i>Data types and memory/storage</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#example-data-types-and-information-storage"><i class="fa fa-check"></i>Example: Data types and information storage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-structures"><i class="fa fa-check"></i>Data structures</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i>Vectors vs Factors in R</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#matricesarrays"><i class="fa fa-check"></i>Matrices/Arrays</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-frames-tibbles-and-data-tables"><i class="fa fa-check"></i>Data frames, tibbles, and data tables</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i>R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-c-install-hadoop.html"><a href="appendix-c-install-hadoop.html"><i class="fa fa-check"></i>Appendix C: Install Hadoop</a></li>
<li class="part"><span><b>VI References and Index</b></span></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="large-scale-text-analysis-with-sparklyr" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Chapter 15</span> Large-scale Text Analysis with sparklyr<a href="large-scale-text-analysis-with-sparklyr.html#large-scale-text-analysis-with-sparklyr" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p></p>
<p>Text analysis/natural language processing (NLP) often involves rather large amounts of data and is particularly challenging for in-memory processing. <code>sparklyr</code> provides several easy-to-use functions to run some of the computationally most demanding text data handling on a Spark cluster. In this chapter we explore these functions and the corresponding workflows to do text analysis on an AWS EMR cluster running Spark. Thereby we focus on the first few key components of a modern NLP pipeline. Figure <a href="large-scale-text-analysis-with-sparklyr.html#fig:nlppipeline">15.1</a> presents an overview of the main components of such a pipeline.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nlppipeline"></span>
<img src="img/05_nlp_pipeline.jpg" alt="Illustration of a NLP (Natural Language Processing) pipeline." width="99%" />
<p class="caption">
Figure 15.1: Illustration of a NLP (Natural Language Processing) pipeline.
</p>
</div>

<p>Up until the deployment of an NLP model, all the steps involved constitute the typical workflow of economic research projects based on text data. Conveniently, all these first crucial steps of analyzing text data are covered in a few high-level functions provided in the <code>sparklyr</code> package. Implementing these steps and running them based on massive amounts of text data on an AWS EMR cluster is thus straightforward.</p>
<p>To get familiar with the basic syntax, the following subsection covers the first steps in such a pipeline based on a very simple text example.</p>
<div id="getting-started-import-pre-processing-and-word-count" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Getting started: Import, pre-processing, and word count<a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
The following example briefly guides the reader through some of the most common first steps when processing text data for NLP. In the code example, we process Friedrich Schiller’s “Wilhelm Tell” (English edition; Project Gutenberg Book ID 2782), which we download from <a href="https://www.gutenberg.org/">Project Gutenberg</a> by means of the <code>gutenbergr</code> package <span class="citation">(<a href="#ref-gutenbergr" role="doc-biblioref">Johnston and Robinson 2022</a>)</span>. The example can easily be extended to process many more books.</p>
<p>The example is set up to work straightforwardly on an AWS EMR cluster. However, given the relatively small amount of data processed here, you can also run it locally. If you want to run it on EMR, simply follow the steps in Chapter 6.4 to set up the cluster and log in to RStudio on the master node. The <code>sparklyr</code> package is already installed on EMR (if you use the bootstrap-script introduced in Chapter 6.4 for the setup of the cluster), but other packages might still have to be installed.</p>
<p>We first load the packages and connect the RStudio session to the cluster (if you run this locally, use <code>spark_connect(master="local")</code>).</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install additional packages</span></span>
<span id="cb570-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;gutenbergr&quot;) # download book from Project Gutenberg</span></span>
<span id="cb570-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;dplyr&quot;) # for the data preparatory steps</span></span>
<span id="cb570-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb570-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-5" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb570-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb570-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gutenbergr)</span>
<span id="cb570-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb570-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb570-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-10" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb570-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-11" aria-hidden="true" tabindex="-1"></a>TELL <span class="ot">&lt;-</span> <span class="st">&quot;https://www.gutenberg.org/cache/epub/6788/pg6788.txt&quot;</span></span>
<span id="cb570-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb570-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb570-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-14" aria-hidden="true" tabindex="-1"></a><span class="co"># connect rstudio session to cluster</span></span>
<span id="cb570-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb570-15" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">&quot;yarn&quot;</span>)</span></code></pre></div>
<p>We fetch the raw text of the book and copy it to the Spark cluster. Note that you can do this sequentially for many books without exhausting the master node’s RAM and then further process the data on the cluster.</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data gathering and preparation</span></span>
<span id="cb571-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fetch Schiller&#39;s Tell, load to cluster</span></span>
<span id="cb571-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-3" aria-hidden="true" tabindex="-1"></a>tmp_file <span class="ot">&lt;-</span> <span class="fu">tempfile</span>()</span>
<span id="cb571-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-4" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(TELL, tmp_file)</span>
<span id="cb571-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-5" aria-hidden="true" tabindex="-1"></a>raw_text <span class="ot">&lt;-</span> <span class="fu">readLines</span>(tmp_file)</span>
<span id="cb571-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-6" aria-hidden="true" tabindex="-1"></a>tell <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">raw_text=</span>raw_text)</span>
<span id="cb571-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-7" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, tell,</span>
<span id="cb571-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-8" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;tell_spark&quot;</span>,</span>
<span id="cb571-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb571-9" aria-hidden="true" tabindex="-1"></a>                      <span class="at">overwrite =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>The text data will be processed in a <code>SparkDataFrame</code> column behind the <code>tbl_spakr</code> object. First, we remove empty lines of text, select the column containing all the text, and then remove all non-numeric and non-alphabetical characters. The last step is an important text cleaning step as we want to avoid special characters being considered words or parts of words later on.</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb572-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data cleaning</span></span>
<span id="cb572-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb572-2" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">filter</span>(tell_spark, raw_text<span class="sc">!=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb572-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb572-3" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">select</span>(tell_spark, raw_text)</span>
<span id="cb572-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb572-4" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">mutate</span>(tell_spark, </span>
<span id="cb572-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb572-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">raw_text =</span> <span class="fu">regexp_replace</span>(raw_text, <span class="st">&quot;[^0-9a-zA-Z]+&quot;</span>, <span class="st">&quot; &quot;</span>))</span></code></pre></div>
<p>Now we can split the lines of text in the column <code>raw_text</code> into individual words (sequences of characters separated by white space). To this end we can call a Spark feature transformation routine called tokenization, which essentially breaks text into individual terms. Specifically, each line of raw text in the column <code>raw_text</code> will be split into words. The overall result (stored in a new column specified with <code>output_col</code>), is then a nested list in which each word is an element of the corresponding line element.</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb573-1" aria-hidden="true" tabindex="-1"></a><span class="co"># split into words</span></span>
<span id="cb573-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb573-2" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">ft_tokenizer</span>(tell_spark, </span>
<span id="cb573-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb573-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">input_col =</span> <span class="st">&quot;raw_text&quot;</span>,</span>
<span id="cb573-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb573-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">output_col =</span> <span class="st">&quot;words&quot;</span>)</span></code></pre></div>
<p>Now we can call another feature transformer called “stop words remover”, which excludes all the stop words (words often occurring in a text but not carrying much information) from the nested word list.</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb574-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove stop-words</span></span>
<span id="cb574-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb574-2" aria-hidden="true" tabindex="-1"></a>tell_spark <span class="ot">&lt;-</span> <span class="fu">ft_stop_words_remover</span>(tell_spark,</span>
<span id="cb574-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb574-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">input_col =</span> <span class="st">&quot;words&quot;</span>,</span>
<span id="cb574-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb574-4" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">output_col =</span> <span class="st">&quot;words_wo_stop&quot;</span>)</span></code></pre></div>
<p>Finally, we combine all of the words in one vector and store the result in a new SparkDataFrame called “all_tell_words” (by calling <code>compute()</code>) and add some final cleaning steps.</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="co"># unnest words, combine in one row</span></span>
<span id="cb575-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-2" aria-hidden="true" tabindex="-1"></a>all_tell_words <span class="ot">&lt;-</span> <span class="fu">mutate</span>(tell_spark, </span>
<span id="cb575-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">word =</span> <span class="fu">explode</span>(words_wo_stop))</span>
<span id="cb575-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb575-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-5" aria-hidden="true" tabindex="-1"></a><span class="co"># final cleaning</span></span>
<span id="cb575-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-6" aria-hidden="true" tabindex="-1"></a>all_tell_words <span class="ot">&lt;-</span> <span class="fu">select</span>(all_tell_words, word)</span>
<span id="cb575-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb575-7" aria-hidden="true" tabindex="-1"></a>all_tell_words <span class="ot">&lt;-</span> <span class="fu">filter</span>(all_tell_words, <span class="dv">2</span><span class="sc">&lt;</span><span class="fu">nchar</span>(word))</span></code></pre></div>
<p>Based on this cleaned set of words, we can compute the word count for the entire book.</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb576-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get word count and store result in Spark memory</span></span>
<span id="cb576-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb576-2" aria-hidden="true" tabindex="-1"></a><span class="fu">compute</span>(<span class="fu">count</span>(all_tell_words, word), <span class="st">&quot;wordcount_tell&quot;</span>)</span></code></pre></div>
<pre><code>## # Source: spark&lt;wordcount_tell&gt; [?? x 2]
##    word           n
##    &lt;chr&gt;      &lt;int&gt;
##  1 language       2
##  2 martin         1
##  3 baron          8
##  4 nephew         3
##  5 hofe           3
##  6 reding        16
##  7 fisherman     39
##  8 baumgarten    32
##  9 hildegard      3
## 10 soldiers       4
## # … with more rows</code></pre>
<p>Finally, we can disconnect the R session from the Spark cluster</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span></code></pre></div>
</div>
<div id="tutorial-political-slant" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Tutorial: political slant<a href="large-scale-text-analysis-with-sparklyr.html#tutorial-political-slant" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The tutorial below shows how to use <code>sparklyr</code> (in conjunction with AWS EMR) to run the entire raw text processing of academic research projects in economics. We will replicate the data preparation and computation of the <em>slant measure</em> for congressional speeches suggested by <span class="citation">Gentzkow and Shapiro (<a href="#ref-gentzkow_shapiro2010" role="doc-biblioref">2010</a>)</span> in the tutorial. To keep things simple, we’ll use the data compiled by <span class="citation">Gentzkow, Shapiro, and Taddy (<a href="#ref-gentzkow_etal2019" role="doc-biblioref">2019</a>)</span> and made available at <a href="https://data.stanford.edu/congress_text" class="uri">https://data.stanford.edu/congress_text</a>.</p>
<div id="data-download-and-import" class="section level3 hasAnchor" number="15.2.1">
<h3><span class="header-section-number">15.2.1</span> Data download and import<a href="large-scale-text-analysis-with-sparklyr.html#data-download-and-import" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To begin, we download the corresponding zip-file to the EMR master node (if using EMR) or to your local RStudio working directory if using a local Spark installation. The unzipped folder contains text data from all speeches delivered from the 97th to the 114th US Congress, among other things. We will primarily work with the raw speeches text data, which is stored in files with the naming pattern <code>"speeches CONGRESS.txt,"</code> where <code>CONGRESS</code> is the number of the corresponding US Congress. To make things easier, we put all of the <code>speeches</code>-files in a subdirectory called <code>'speeches</code>. The following section simply illustrates one method for downloading and rearranging the data files. The following code chunks require that all files containing the text of speeches be stored in <code>data/text/speeches</code> and all speaker information be stored in <code>data/text/speakers</code>.</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download and unzip the raw text data</span></span>
<span id="cb579-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-2" aria-hidden="true" tabindex="-1"></a>URL <span class="ot">&lt;-</span> <span class="st">&quot;https://stacks.stanford.edu/file/druid:md374tz9962/hein-daily.zip&quot;</span></span>
<span id="cb579-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-3" aria-hidden="true" tabindex="-1"></a>PATH <span class="ot">&lt;-</span> <span class="st">&quot;data/hein-daily.zip&quot;</span></span>
<span id="cb579-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="fu">paste0</span>(<span class="st">&quot;curl &quot;</span>,</span>
<span id="cb579-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-5" aria-hidden="true" tabindex="-1"></a>              URL, </span>
<span id="cb579-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-6" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot; &gt; &quot;</span>, </span>
<span id="cb579-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-7" aria-hidden="true" tabindex="-1"></a>              PATH,</span>
<span id="cb579-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot; &amp;&amp; unzip &quot;</span>, </span>
<span id="cb579-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-9" aria-hidden="true" tabindex="-1"></a>              PATH))</span>
<span id="cb579-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-10" aria-hidden="true" tabindex="-1"></a><span class="co"># move the speeches files</span></span>
<span id="cb579-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-11" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mkdir data/text/ &amp;&amp; mkdir data/text/speeches&quot;</span>)</span>
<span id="cb579-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-12" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mv hein-daily/speeches* data/text/speeches/&quot;</span>)</span>
<span id="cb579-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-13" aria-hidden="true" tabindex="-1"></a><span class="co"># move the speaker files</span></span>
<span id="cb579-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-14" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mkdir data/text/speakers&quot;</span>)</span>
<span id="cb579-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb579-15" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mv hein-daily/*SpeakerMap.txt data/text/speakers/&quot;</span>)</span></code></pre></div>
<p>In addition, we download an extra file in which the authors kept only valid phrases (after removing procedural phrases that often occur in congressional speeches but that do not contribute to finding partisan phrases). Thus we can later use this additional file to filter out invalid bigrams.<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a></p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download and unzip procedural phrases data</span></span>
<span id="cb580-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-2" aria-hidden="true" tabindex="-1"></a>URL_P <span class="ot">&lt;-</span> <span class="st">&quot;https://stacks.stanford.edu/file/druid:md374tz9962/vocabulary.zip&quot;</span></span>
<span id="cb580-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-3" aria-hidden="true" tabindex="-1"></a>PATH_P <span class="ot">&lt;-</span> <span class="st">&quot;data/vocabulary.zip&quot;</span></span>
<span id="cb580-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="fu">paste0</span>(<span class="st">&quot;curl &quot;</span>,</span>
<span id="cb580-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-5" aria-hidden="true" tabindex="-1"></a>              URL_P, </span>
<span id="cb580-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-6" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot; &gt; &quot;</span>, </span>
<span id="cb580-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-7" aria-hidden="true" tabindex="-1"></a>              PATH_P,</span>
<span id="cb580-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot; &amp;&amp; unzip &quot;</span>,</span>
<span id="cb580-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-9" aria-hidden="true" tabindex="-1"></a>              PATH_P))</span>
<span id="cb580-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-10" aria-hidden="true" tabindex="-1"></a><span class="co"># move the procedural vocab file</span></span>
<span id="cb580-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb580-11" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;mv vocabulary/vocab.txt data/text/&quot;</span>)</span></code></pre></div>
<p>We begin by loading the corresponding packages, defining some fix variables, and connecting the R session to the Spark cluster, using the same basic pipeline structure as in the previous section’s introductory example. Typically, you would first test these steps on a local Spark installation before feeding in more data to process on a Spark cluster in the cloud. In the following example, we only process the congressional speeches from the 97th to the 114th US Congress. The original source provides data for almost the entire history of Congress (see <a href="https://data.stanford.edu/congress_text" class="uri">https://data.stanford.edu/congress_text</a> for details). Recall that for local tests/working with the local Spark installation, you can connect your R session with <code>sc &lt;- spark_connect(master = "local")</code>. Since even the limited speeches set we work with locally is several GBs in size, we set the memory available to our local Spark node to 16GB. This can be done by fetching the config file via <code>spark_config()</code> and then setting the <code>driver-memory</code> accordingly before initializing the Spark connection with the adapted configuration object (see <code>config = conf</code> in the <code>spark_connect()</code> command).</p>
<p>Unlike in the simple introductory example above, the raw data is distributed in multiple files. By default, Spark expects to load data from multiple files in the same directory. Thus, we can use the <code>spark_read_csv()</code> function to specify where all of the raw data is located in order to read in all of the raw text data at once. The data in this example is essentially stored in CSV format, but the pipe symbol <code>|</code> is used to separate columns instead of the more common commas. By specifying <code>delimiter="|"</code>, we ensure that the data structure is correctly captured.</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LOAD TEXT DATA  --------------------</span></span>
<span id="cb581-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb581-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb581-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-4" aria-hidden="true" tabindex="-1"></a>speeches <span class="ot">&lt;-</span> <span class="fu">spark_read_csv</span>(sc,</span>
<span id="cb581-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">name =</span> <span class="st">&quot;speeches&quot;</span>,</span>
<span id="cb581-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-6" aria-hidden="true" tabindex="-1"></a>                           <span class="at">path =</span>  INPUT_PATH_SPEECHES,</span>
<span id="cb581-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-7" aria-hidden="true" tabindex="-1"></a>                           <span class="at">delimiter =</span> <span class="st">&quot;|&quot;</span>)</span>
<span id="cb581-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-8" aria-hidden="true" tabindex="-1"></a>speakers <span class="ot">&lt;-</span> <span class="fu">spark_read_csv</span>(sc,</span>
<span id="cb581-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-9" aria-hidden="true" tabindex="-1"></a>                           <span class="at">name =</span> <span class="st">&quot;speakers&quot;</span>,</span>
<span id="cb581-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-10" aria-hidden="true" tabindex="-1"></a>                           <span class="at">path =</span>  INPUT_PATH_SPEAKERS,</span>
<span id="cb581-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb581-11" aria-hidden="true" tabindex="-1"></a>                           <span class="at">delimiter =</span> <span class="st">&quot;|&quot;</span>)</span></code></pre></div>
</div>
<div id="cleaning-speeches-data" class="section level3 hasAnchor" number="15.2.2">
<h3><span class="header-section-number">15.2.2</span> Cleaning speeches data<a href="large-scale-text-analysis-with-sparklyr.html#cleaning-speeches-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The intermediate goal of the data preparation steps is to determine the number of bigrams per party. That is, we want to know how frequently members of a particular political party have used a two-word phrase.As a first step, we must combine the speeches and speaker data to obtain the party label per speech, and then clean the raw text to extract words, and create and count bigrams. Congressional speeches frequently include references to dates, bill numbers, years, and so on. This introduces a slew of tokens made up entirely of digits, single characters, and special characters.The cleaning steps that follow are intended to remove the majority of those.</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-1" aria-hidden="true" tabindex="-1"></a><span class="co"># JOIN --------------------</span></span>
<span id="cb582-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-2" aria-hidden="true" tabindex="-1"></a>speeches <span class="ot">&lt;-</span> </span>
<span id="cb582-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">inner_join</span>(speeches,</span>
<span id="cb582-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-4" aria-hidden="true" tabindex="-1"></a>                speakers,</span>
<span id="cb582-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">by=</span><span class="st">&quot;speech_id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb582-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(party <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;R&quot;</span>, <span class="st">&quot;D&quot;</span>), chamber<span class="sc">==</span><span class="st">&quot;H&quot;</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb582-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">congress=</span><span class="fu">substr</span>(speech_id, <span class="dv">1</span>,<span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(speech_id, speech, party, congress)</span>
<span id="cb582-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-9" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb582-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb582-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-11" aria-hidden="true" tabindex="-1"></a><span class="co"># CLEANING ----------------</span></span>
<span id="cb582-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-12" aria-hidden="true" tabindex="-1"></a><span class="co"># clean text: numbers, letters (bill IDs, etc.</span></span>
<span id="cb582-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-13" aria-hidden="true" tabindex="-1"></a>speeches <span class="ot">&lt;-</span> </span>
<span id="cb582-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-14" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(speeches, <span class="at">speech =</span> <span class="fu">tolower</span>(speech)) <span class="sc">%&gt;%</span></span>
<span id="cb582-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech,</span>
<span id="cb582-16"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-16" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;[_</span><span class="sc">\&quot;\&#39;</span><span class="st">():;,.!?</span><span class="sc">\\</span><span class="st">-]&quot;</span>,</span>
<span id="cb582-17"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-17" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-18"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-18" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech, <span class="st">&quot;</span><span class="sc">\\\\</span><span class="st">(.+</span><span class="sc">\\\\</span><span class="st">)&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-19"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-19" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech, <span class="st">&quot;[0-9]+&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-20"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-20" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech, <span class="st">&quot;&lt;[a-z]+&gt;&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-21"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-21" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech, <span class="st">&quot;&lt;</span><span class="sc">\\</span><span class="st">w+&gt;&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-22"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-22" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">regexp_replace</span>(speech, <span class="st">&quot;_&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb582-23"><a href="large-scale-text-analysis-with-sparklyr.html#cb582-23" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">speech =</span> <span class="fu">trimws</span>(speech))</span></code></pre></div>
</div>
<div id="create-a-bigrams-count-per-party" class="section level3 hasAnchor" number="15.2.3">
<h3><span class="header-section-number">15.2.3</span> Create a bigrams count per party<a href="large-scale-text-analysis-with-sparklyr.html#create-a-bigrams-count-per-party" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Based on the cleaned text, we now split the text into words (tokenization), remove stopwords, and create a list of bigrams (2-word phrases). Finally, we unnest the bigram list and keep the party and bigram column. The resulting spark table contains a row for each bigram mentioned in any of the speeches along the information of whether the speech in which the bigram was mentioned was given by a Democrat or a Republican.</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TOKENIZATION, STOPWORDS REMOVAL, NGRAMS ----------------</span></span>
<span id="cb583-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb583-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-3" aria-hidden="true" tabindex="-1"></a><span class="co"># stopwords list </span></span>
<span id="cb583-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-4" aria-hidden="true" tabindex="-1"></a>stop <span class="ot">&lt;-</span> <span class="fu">readLines</span>(<span class="st">&quot;http://snowball.tartarus.org/algorithms/english/stop.txt&quot;</span>)</span>
<span id="cb583-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-5" aria-hidden="true" tabindex="-1"></a>stop <span class="ot">&lt;-</span> <span class="fu">trimws</span>(<span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">|.*&quot;</span>, <span class="st">&quot;&quot;</span>, stop))</span>
<span id="cb583-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-6" aria-hidden="true" tabindex="-1"></a>stop <span class="ot">&lt;-</span> stop[stop<span class="sc">!=</span><span class="st">&quot;&quot;</span>]</span>
<span id="cb583-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb583-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-8" aria-hidden="true" tabindex="-1"></a><span class="co"># clean text: numbers, letters (bill IDs, etc.</span></span>
<span id="cb583-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-9" aria-hidden="true" tabindex="-1"></a>bigrams <span class="ot">&lt;-</span> </span>
<span id="cb583-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-10" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_tokenizer</span>(speeches, <span class="st">&quot;speech&quot;</span>, <span class="st">&quot;words&quot;</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb583-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-11" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_stop_words_remover</span>(<span class="st">&quot;words&quot;</span>, <span class="st">&quot;words_wo_stop&quot;</span>,</span>
<span id="cb583-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-12" aria-hidden="true" tabindex="-1"></a>                           <span class="at">stop_words =</span> stop )  <span class="sc">%&gt;%</span></span>
<span id="cb583-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-13" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ft_ngram</span>(<span class="st">&quot;words_wo_stop&quot;</span>, <span class="st">&quot;bigram_list&quot;</span>, <span class="at">n=</span><span class="dv">2</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb583-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-14" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">bigram=</span><span class="fu">explode</span>(bigram_list)) <span class="sc">%&gt;%</span></span>
<span id="cb583-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">bigram=</span><span class="fu">trim</span>(bigram)) <span class="sc">%&gt;%</span></span>
<span id="cb583-16"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">n_words=</span><span class="fu">as.numeric</span>(<span class="fu">length</span>(bigram) <span class="sc">-</span> </span>
<span id="cb583-17"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-17" aria-hidden="true" tabindex="-1"></a>                                    <span class="fu">length</span>(<span class="fu">replace</span>(bigram, <span class="st">&#39; &#39;</span>, <span class="st">&#39;&#39;</span>)) <span class="sc">+</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb583-18"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-18" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(<span class="dv">3</span><span class="sc">&lt;</span><span class="fu">nchar</span>(bigram), <span class="dv">1</span><span class="sc">&lt;</span>n_words) <span class="sc">%&gt;%</span></span>
<span id="cb583-19"><a href="large-scale-text-analysis-with-sparklyr.html#cb583-19" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(party, congress, bigram)</span></code></pre></div>
<p>Before counting the bigrams by party, we need an additional context-specific cleaning step in which we remove procedural phrases from the speech bigrams.</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the procedural phrases list</span></span>
<span id="cb584-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-2" aria-hidden="true" tabindex="-1"></a>valid_vocab <span class="ot">&lt;-</span> <span class="fu">spark_read_csv</span>(sc,</span>
<span id="cb584-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">path=</span><span class="st">&quot;data/text/vocab.txt&quot;</span>,</span>
<span id="cb584-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">name =</span> <span class="st">&quot;valid_vocab&quot;</span>,</span>
<span id="cb584-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">delimiter =</span> <span class="st">&quot;|&quot;</span>,</span>
<span id="cb584-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">header =</span> <span class="cn">FALSE</span>)</span>
<span id="cb584-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-7" aria-hidden="true" tabindex="-1"></a><span class="co"># remove corresponding bigrams via anti-join</span></span>
<span id="cb584-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb584-8" aria-hidden="true" tabindex="-1"></a>bigrams <span class="ot">&lt;-</span> <span class="fu">inner_join</span>(bigrams, valid_vocab, <span class="at">by=</span> <span class="fu">c</span>(<span class="st">&quot;bigram&quot;</span><span class="ot">=</span><span class="st">&quot;V1&quot;</span>))</span></code></pre></div>
</div>
<div id="find-partisan-phrases" class="section level3 hasAnchor" number="15.2.4">
<h3><span class="header-section-number">15.2.4</span> Find “partisan” phrases<a href="large-scale-text-analysis-with-sparklyr.html#find-partisan-phrases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point, we have all pieces in place in order to compute the bigram count (how often a certain bigram was mentioned by a member of either party). As this is an important intermediate result, we evaluate the entire operation for all the data and cache it in spark memory through <code>compute()</code>. Note that if you run this code on your local machine, it can take a while to process.</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="co"># BIGRAM COUNT PER PARTY ---------------</span></span>
<span id="cb585-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb585-2" aria-hidden="true" tabindex="-1"></a>bigram_count <span class="ot">&lt;-</span> </span>
<span id="cb585-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb585-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">count</span>(bigrams, party, bigram, congress)  <span class="sc">%&gt;%</span></span>
<span id="cb585-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb585-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">compute</span>(<span class="st">&quot;bigram_count&quot;</span>)</span></code></pre></div>
<p>Finally, we can turn to the actual method/analysis suggested by <span class="citation">Gentzkow and Shapiro (<a href="#ref-gentzkow_shapiro2010" role="doc-biblioref">2010</a>)</span>. They suggest a simple chi-squared test to find the most partisan bigrams. For each bigram, we compute the corresponding chi-squared value.</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-1" aria-hidden="true" tabindex="-1"></a><span class="co"># FIND MOST PARTISAN BIGRAMS ------------</span></span>
<span id="cb586-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb586-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-3" aria-hidden="true" tabindex="-1"></a><span class="co"># compute frequencies and chi-squared values</span></span>
<span id="cb586-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-4" aria-hidden="true" tabindex="-1"></a>freqs <span class="ot">&lt;-</span> </span>
<span id="cb586-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-5" aria-hidden="true" tabindex="-1"></a>     bigram_count  <span class="sc">%&gt;%</span></span>
<span id="cb586-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">group_by</span>(party, congress)  <span class="sc">%&gt;%</span></span>
<span id="cb586-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">total=</span><span class="fu">sum</span>(n), <span class="at">f_npl=</span>total<span class="sc">-</span>n)</span>
<span id="cb586-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-8" aria-hidden="true" tabindex="-1"></a>freqs_d <span class="ot">&lt;-</span></span>
<span id="cb586-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-9" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(freqs, party<span class="sc">==</span><span class="st">&quot;D&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb586-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-10" aria-hidden="true" tabindex="-1"></a>     <span class="fu">rename</span>(<span class="at">f_pld=</span>n, <span class="at">f_npld=</span>f_npl) <span class="sc">%&gt;%</span></span>
<span id="cb586-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb586-11" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(bigram, congress, f_pld, f_npld)</span></code></pre></div>
<pre><code>## Adding missing grouping variables: `party`</code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb588-1" aria-hidden="true" tabindex="-1"></a>freqs_r <span class="ot">&lt;-</span></span>
<span id="cb588-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb588-2" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(freqs, party<span class="sc">==</span><span class="st">&quot;R&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb588-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb588-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">rename</span>(<span class="at">f_plr=</span>n, <span class="at">f_nplr=</span>f_npl) <span class="sc">%&gt;%</span></span>
<span id="cb588-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb588-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(bigram, congress, f_plr, f_nplr)</span></code></pre></div>
<pre><code>## Adding missing grouping variables: `party`</code></pre>
<p>Based on the computed bigram frequencies, we can compute the chi-squared test as follows.</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-1" aria-hidden="true" tabindex="-1"></a>pol_bigrams <span class="ot">&lt;-</span></span>
<span id="cb590-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-2" aria-hidden="true" tabindex="-1"></a>     <span class="fu">inner_join</span>(freqs_d, freqs_r, <span class="at">by=</span><span class="fu">c</span>(<span class="st">&quot;bigram&quot;</span>, <span class="st">&quot;congress&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb590-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">group_by</span>(bigram, congress) <span class="sc">%&gt;%</span></span>
<span id="cb590-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">x2=</span>((f_plr<span class="sc">*</span>f_npld<span class="sc">-</span>f_pld<span class="sc">*</span>f_nplr)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span></span>
<span id="cb590-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-5" aria-hidden="true" tabindex="-1"></a>                 ((f_plr <span class="sc">+</span> f_pld)<span class="sc">*</span>(f_plr <span class="sc">+</span> f_nplr)<span class="sc">*</span></span>
<span id="cb590-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-6" aria-hidden="true" tabindex="-1"></a>                       (f_pld <span class="sc">+</span> f_npld)<span class="sc">*</span>(f_nplr <span class="sc">+</span> f_npld))) <span class="sc">%&gt;%</span></span>
<span id="cb590-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(bigram, congress, x2, f_pld, f_plr) <span class="sc">%&gt;%</span></span>
<span id="cb590-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb590-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">compute</span>(<span class="st">&quot;pol_bigrams&quot;</span>)</span></code></pre></div>
</div>
<div id="results-most-partisan-phrases-by-congress" class="section level3 hasAnchor" number="15.2.5">
<h3><span class="header-section-number">15.2.5</span> Results: most partisan phrases by congress<a href="large-scale-text-analysis-with-sparklyr.html#results-most-partisan-phrases-by-congress" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In order to present a first glimpse at the results we first select the 2,000 most partisan phrases per Congress according to the procedure above. To do so, we need to first create an index column in the corresponding spark table.<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a> We then collect the 2,000 most partisan bigrams.<a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a></p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create output data frame</span></span>
<span id="cb591-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-2" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> pol_bigrams  <span class="sc">%&gt;%</span></span>
<span id="cb591-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">group_by</span>(congress) <span class="sc">%&gt;%</span></span>
<span id="cb591-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">arrange</span>(<span class="fu">desc</span>(x2)) <span class="sc">%&gt;%</span></span>
<span id="cb591-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-5" aria-hidden="true" tabindex="-1"></a>     <span class="fu">sdf_with_sequential_id</span>(<span class="at">id=</span><span class="st">&quot;index&quot;</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb591-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(index<span class="sc">&lt;=</span><span class="dv">2000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb591-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">Party=</span><span class="fu">ifelse</span>(f_pld<span class="sc">&lt;</span>f_plr, <span class="st">&quot;R&quot;</span>, <span class="st">&quot;D&quot;</span>))<span class="sc">%&gt;%</span></span>
<span id="cb591-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(bigram, congress, Party, x2) <span class="sc">%&gt;%</span></span>
<span id="cb591-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-9" aria-hidden="true" tabindex="-1"></a>     <span class="fu">collect</span>()</span>
<span id="cb591-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb591-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-11" aria-hidden="true" tabindex="-1"></a><span class="co"># disconnect from cluster</span></span>
<span id="cb591-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb591-12" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span></code></pre></div>
<p>From the subset of the 2,000 most partisan bigrams, we then generate a table of the top 5 most partisan bigrams per congress.</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-1" aria-hidden="true" tabindex="-1"></a><span class="co"># packages to prepare and plot</span></span>
<span id="cb592-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb592-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb592-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-4" aria-hidden="true" tabindex="-1"></a><span class="co"># select top ten per congress, clean</span></span>
<span id="cb592-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-5" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">as.data.table</span>(output)</span>
<span id="cb592-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-6" aria-hidden="true" tabindex="-1"></a>topten <span class="ot">&lt;-</span> output[<span class="fu">order</span>(congress, x2, <span class="at">decreasing =</span> <span class="cn">TRUE</span>),</span>
<span id="cb592-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-7" aria-hidden="true" tabindex="-1"></a>                 rank<span class="sc">:</span><span class="er">=</span><span class="dv">1</span><span class="sc">:</span>.N, by<span class="ot">=</span><span class="fu">list</span>(congress)][rank <span class="sc">%in%</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)]</span>
<span id="cb592-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-8" aria-hidden="true" tabindex="-1"></a>topten[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;990&quot;</span>, <span class="st">&quot;99&quot;</span>, congress)]</span>
<span id="cb592-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-9" aria-hidden="true" tabindex="-1"></a>topten[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;980&quot;</span>, <span class="st">&quot;98&quot;</span>, congress)]</span>
<span id="cb592-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-10" aria-hidden="true" tabindex="-1"></a>topten[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;970&quot;</span>, <span class="st">&quot;97&quot;</span>, congress)]</span>
<span id="cb592-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb592-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-12" aria-hidden="true" tabindex="-1"></a><span class="co"># plot a visualization of the most partisan terms</span></span>
<span id="cb592-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(topten, <span class="at">mapping=</span><span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.integer</span>(congress), <span class="at">y=</span><span class="fu">log</span>(x2), <span class="at">color=</span>Party)) <span class="sc">+</span></span>
<span id="cb592-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-14" aria-hidden="true" tabindex="-1"></a>     <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span>bigram), <span class="at">nudge_y =</span> <span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb592-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ylab</span>(<span class="st">&quot;Partisanship score (Ln of Chisq. value)&quot;</span>) <span class="sc">+</span></span>
<span id="cb592-16"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">xlab</span>(<span class="st">&quot;Congress&quot;</span>) <span class="sc">+</span></span>
<span id="cb592-17"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-17" aria-hidden="true" tabindex="-1"></a>     <span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;D&quot;</span><span class="ot">=</span><span class="st">&quot;blue&quot;</span>, <span class="st">&quot;R&quot;</span><span class="ot">=</span><span class="st">&quot;red&quot;</span>), <span class="at">name=</span><span class="st">&quot;Party&quot;</span>) <span class="sc">+</span></span>
<span id="cb592-18"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-18" aria-hidden="true" tabindex="-1"></a>     <span class="fu">guides</span>(<span class="at">color=</span><span class="fu">guide_legend</span>(<span class="at">title.position=</span><span class="st">&quot;top&quot;</span>)) <span class="sc">+</span></span>
<span id="cb592-19"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-19" aria-hidden="true" tabindex="-1"></a>     <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span><span class="fu">as.integer</span>(<span class="fu">unique</span>(topten<span class="sc">$</span>congress))) <span class="sc">+</span></span>
<span id="cb592-20"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-20" aria-hidden="true" tabindex="-1"></a>     <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb592-21"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-21" aria-hidden="true" tabindex="-1"></a>     <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">90</span>, <span class="at">hjust =</span> <span class="dv">1</span>),</span>
<span id="cb592-22"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-22" aria-hidden="true" tabindex="-1"></a>           <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="dv">1</span>),</span>
<span id="cb592-23"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-23" aria-hidden="true" tabindex="-1"></a>           <span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb592-24"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-24" aria-hidden="true" tabindex="-1"></a>           <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb592-25"><a href="large-scale-text-analysis-with-sparklyr.html#cb592-25" aria-hidden="true" tabindex="-1"></a>           <span class="at">panel.background =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="bigdata_files/figure-html/unnamed-chunk-319-1.png" /><!-- --></p>
</div>
</div>
<div id="natural-language-processing-at-scale" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Natural Language Processing at Scale<a href="large-scale-text-analysis-with-sparklyr.html#natural-language-processing-at-scale" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The examples above merely scratch the surface of what is possible these days in the realm of text analysis. With increasing availability of big data and the recent boost in deep learning, Natural Language Processing (NLP) put forward several very powerful (and very large) language models for various text prediction tasks. Due to the improvement of these models when trained on massive amounts of text data and the rather generic application of many of these large models, it has become common practice to directly work with a pre-trained model. That is, we do not actually train the algorithm based on our own training dataset, but rather build on a model that has been trained on a large text corpus and then has been made available to the public. In this section, we look at one straightforward way to build on such models with <code>sparklyr</code>.</p>
<div id="preparatory-steps" class="section level3 hasAnchor" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> Preparatory steps<a href="large-scale-text-analysis-with-sparklyr.html#preparatory-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Specifically, we look at a few brief example based on the <code>sparknlp</code> package <span class="citation">(<a href="#ref-sparknlp" role="doc-biblioref">Kincaid and Kuo 2023</a>)</span> providing a <code>sparklyr</code> extension for using the <a href="https://www.johnsnowlabs.com/spark-nlp">John Snow Labs Spark NLP</a> library. The package can be directly installed from GitHub: <code>devtools::install_github("r-spark/sparknlp")</code> To begin, we load the corresponding packages and initialize a pre-trained NLP pipeline for entity recognition, which we will then apply to the congressional speeches data. Note that the <code>sparknlp</code> package needs to be loaded before we connect the R session to the Spark cluster. In the following code chunk we thus first load the package and initiate the session by connecting again to the local spark node. In addition to loading the <code>sparklyr</code> and <code>dplyr</code> packages, we also load the <code>sparklyr.nested</code> package <span class="citation">(<a href="#ref-sparklyr.nested" role="doc-biblioref">Pollock 2023</a>)</span>. The latter is useful when working with <code>sparknlp</code>’s pipelines because the results are often returned as nested lists (in Spark table columns).</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb593-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb593-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb593-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparknlp)</span>
<span id="cb593-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sparklyr.nested)</span>
<span id="cb593-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb593-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-7" aria-hidden="true" tabindex="-1"></a><span class="co"># configuration of local spark cluster</span></span>
<span id="cb593-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-8" aria-hidden="true" tabindex="-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb593-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-9" aria-hidden="true" tabindex="-1"></a>conf<span class="sc">$</span><span class="st">`</span><span class="at">sparklyr.shell.driver-memory</span><span class="st">`</span> <span class="ot">&lt;-</span> <span class="st">&quot;16g&quot;</span></span>
<span id="cb593-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-10" aria-hidden="true" tabindex="-1"></a><span class="co"># connect rstudio session to cluster</span></span>
<span id="cb593-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-11" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">&quot;local&quot;</span>, </span>
<span id="cb593-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb593-12" aria-hidden="true" tabindex="-1"></a>                    <span class="at">config =</span> conf)</span></code></pre></div>
<p>The goal of this brief example of <code>sparknlp</code> is to demonstrate how we can easily tap into very powerful pre-trained models to categorize text.To keep things simple, we return to the previous context (congressional speeches) and reload the speeches dataset. To make the following chunks of code run smoothly and relativel fast on a local Spark installation (for test purposes), we use <code>sample_n()</code> for a random draw of 10,000 speeches.</p>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LOAD --------------------</span></span>
<span id="cb594-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb594-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load speeches</span></span>
<span id="cb594-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-4" aria-hidden="true" tabindex="-1"></a>INPUT_PATH_SPEECHES <span class="ot">&lt;-</span> <span class="st">&quot;data/text/speeches/&quot;</span> </span>
<span id="cb594-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-5" aria-hidden="true" tabindex="-1"></a>speeches <span class="ot">&lt;-</span> </span>
<span id="cb594-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">spark_read_csv</span>(sc,</span>
<span id="cb594-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-7" aria-hidden="true" tabindex="-1"></a>                    <span class="at">name =</span> <span class="st">&quot;speeches&quot;</span>,</span>
<span id="cb594-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-8" aria-hidden="true" tabindex="-1"></a>                    <span class="at">path =</span>  INPUT_PATH_SPEECHES,</span>
<span id="cb594-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-9" aria-hidden="true" tabindex="-1"></a>                    <span class="at">delimiter =</span> <span class="st">&quot;|&quot;</span>,</span>
<span id="cb594-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-10" aria-hidden="true" tabindex="-1"></a>                    <span class="at">overwrite =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb594-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-11" aria-hidden="true" tabindex="-1"></a>     <span class="fu">sample_n</span>(<span class="dv">10000</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)  <span class="sc">%&gt;%</span> </span>
<span id="cb594-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb594-12" aria-hidden="true" tabindex="-1"></a>     <span class="fu">compute</span>(<span class="st">&quot;speeches&quot;</span>)</span></code></pre></div>
</div>
<div id="sentiment-annotation" class="section level3 hasAnchor" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> Sentiment annotation<a href="large-scale-text-analysis-with-sparklyr.html#sentiment-annotation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this short tutorial, we’ll examine the tone (sentiment) of the congressional speeches. Sentiment analysis is a fairly common task in NLP, but it is frequently a computationally demanding task with numerous preparatory steps. <code>sparknlp</code> provides a straightforward interface for creating the necessary NLP pipeline in R and massively scaling the analysis on Spark. Let’s begin by loading the pretrained NLP pipeline for sentiment analysis provided in <code>sparknlp</code>.</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the nlp pipeline for sentiment analysis</span></span>
<span id="cb595-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb595-2" aria-hidden="true" tabindex="-1"></a>pipeline <span class="ot">&lt;-</span> <span class="fu">nlp_pretrained_pipeline</span>(sc, <span class="st">&quot;analyze_sentiment&quot;</span>, <span class="st">&quot;en&quot;</span>)</span></code></pre></div>
<p>We can easily feed in the entire speech corpus via the <code>target</code> argument and point to the column containing the raw text (here <code>"speech"</code>). The code below divides the text into sentences and tokens (words) and returns the sentiment annotation for each sentence.</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb596-1" aria-hidden="true" tabindex="-1"></a>speeches_a <span class="ot">&lt;-</span> </span>
<span id="cb596-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb596-2" aria-hidden="true" tabindex="-1"></a>     <span class="fu">nlp_annotate</span>(pipeline,</span>
<span id="cb596-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb596-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">target =</span> speeches,</span>
<span id="cb596-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb596-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">column =</span> <span class="st">&quot;speech&quot;</span>)</span></code></pre></div>
<p>The sentiment of the sentences is then extracted for each corresponding speech ID and coded with two additional indicator variables, indicating whether a sentence was classified as positive or negative.</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract sentiment coding per speech</span></span>
<span id="cb597-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-2" aria-hidden="true" tabindex="-1"></a>sentiments <span class="ot">&lt;-</span> </span>
<span id="cb597-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-3" aria-hidden="true" tabindex="-1"></a>     speeches_a <span class="sc">%&gt;%</span></span>
<span id="cb597-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">sdf_select</span>(speech_id, <span class="at">sentiments=</span>sentiment.result) <span class="sc">%&gt;%</span> </span>
<span id="cb597-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-5" aria-hidden="true" tabindex="-1"></a>     <span class="fu">sdf_explode</span>(sentiments)  <span class="sc">%&gt;%</span> </span>
<span id="cb597-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">pos =</span> <span class="fu">as.integer</span>(sentiments<span class="sc">==</span><span class="st">&quot;positive&quot;</span>),</span>
<span id="cb597-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">neg =</span> <span class="fu">as.integer</span>(sentiments<span class="sc">==</span><span class="st">&quot;negative&quot;</span>))  <span class="sc">%&gt;%</span> </span>
<span id="cb597-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb597-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(speech_id, pos, neg) </span></code></pre></div>
</div>
</div>
<div id="aggregation-and-visualization" class="section level2 hasAnchor" number="15.4">
<h2><span class="header-section-number">15.4</span> Aggregation and visualization<a href="large-scale-text-analysis-with-sparklyr.html#aggregation-and-visualization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Finally, we compute the proportion of sentences with a positive sentiment per speech and export the aggregate sentiment analysis result to the R environment for further processing.<a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a></p>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-1" aria-hidden="true" tabindex="-1"></a><span class="co"># aggregate and download to R environment -----</span></span>
<span id="cb598-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-2" aria-hidden="true" tabindex="-1"></a>sentiments_aggr <span class="ot">&lt;-</span> </span>
<span id="cb598-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-3" aria-hidden="true" tabindex="-1"></a>     sentiments  <span class="sc">%&gt;%</span></span>
<span id="cb598-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-4" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(speech_id, pos, neg) <span class="sc">%&gt;%</span></span>
<span id="cb598-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-5" aria-hidden="true" tabindex="-1"></a>     <span class="fu">group_by</span>(speech_id) <span class="sc">%&gt;%</span></span>
<span id="cb598-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">rel_pos =</span> <span class="fu">sum</span>(pos)<span class="sc">/</span>(<span class="fu">sum</span>(pos) <span class="sc">+</span> <span class="fu">sum</span>(neg))) <span class="sc">%&gt;%</span></span>
<span id="cb598-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-7" aria-hidden="true" tabindex="-1"></a>     <span class="fu">filter</span>(<span class="dv">0</span><span class="sc">&lt;</span>rel_pos) <span class="sc">%&gt;%</span></span>
<span id="cb598-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">select</span>(speech_id, rel_pos) <span class="sc">%&gt;%</span></span>
<span id="cb598-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-9" aria-hidden="true" tabindex="-1"></a>     <span class="fu">sdf_distinct</span>(<span class="at">name =</span> <span class="st">&quot;sentiments_aggr&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb598-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb598-10" aria-hidden="true" tabindex="-1"></a>     <span class="fu">collect</span>()</span></code></pre></div>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb599-1" aria-hidden="true" tabindex="-1"></a><span class="co"># disconnect from cluster</span></span>
<span id="cb599-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb599-2" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_disconnect</span>(sc)</span></code></pre></div>
<p>We can easily plot the aggregate speech sentiment over time because the speech ID is based on the Congress number and the sequential number of speeches in this Congress. This allows us to compare (in the simple setup of this tutorial) the sentiment of congressional speeches over time.</p>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clean</span></span>
<span id="cb600-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb600-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-3" aria-hidden="true" tabindex="-1"></a>sa <span class="ot">&lt;-</span> <span class="fu">as.data.table</span>(sentiments_aggr)</span>
<span id="cb600-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-4" aria-hidden="true" tabindex="-1"></a>sa[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">substr</span>(speech_id, <span class="dv">1</span>,<span class="dv">3</span>)]</span>
<span id="cb600-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-5" aria-hidden="true" tabindex="-1"></a>sa[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;990&quot;</span>, <span class="st">&quot;99&quot;</span>, congress)]</span>
<span id="cb600-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-6" aria-hidden="true" tabindex="-1"></a>sa[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;980&quot;</span>, <span class="st">&quot;98&quot;</span>, congress)]</span>
<span id="cb600-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-7" aria-hidden="true" tabindex="-1"></a>sa[, congress<span class="sc">:</span><span class="er">=</span><span class="fu">gsub</span>(<span class="st">&quot;970&quot;</span>, <span class="st">&quot;97&quot;</span>, congress)]</span>
<span id="cb600-8"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb600-9"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-9" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize results</span></span>
<span id="cb600-10"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb600-11"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sa, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">as.integer</span>(congress),</span>
<span id="cb600-12"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">y=</span>rel_pos,</span>
<span id="cb600-13"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">group=</span>congress)) <span class="sc">+</span></span>
<span id="cb600-14"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-14" aria-hidden="true" tabindex="-1"></a>     <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb600-15"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">ylab</span>(<span class="st">&quot;Share of sentences with positive tone&quot;</span>) <span class="sc">+</span></span>
<span id="cb600-16"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">xlab</span>(<span class="st">&quot;Congress&quot;</span>) <span class="sc">+</span></span>
<span id="cb600-17"><a href="large-scale-text-analysis-with-sparklyr.html#cb600-17" aria-hidden="true" tabindex="-1"></a>     <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="bigdata_files/figure-html/unnamed-chunk-327-1.png" /><!-- --></p>
</div>
<div id="sparklyr-and-lazy-evaluation" class="section level2 hasAnchor" number="15.5">
<h2><span class="header-section-number">15.5</span> <code>sparklyr</code> and lazy evaluation<a href="large-scale-text-analysis-with-sparklyr.html#sparklyr-and-lazy-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
When running the code examples above, you may have noticed that the execution times vary significantly between the different code chunks, and maybe not always in the expected way. When using Apache Spark via the <code>sparklyr</code>/<code>dplyr</code>-interface as we did above, the evaluation of the code is intentionally (very) lazy. That is, unless a line of code really requires data to be processed (for example, due to printing the results to the console or explicitly due to calling <code>collect()</code>), Spark will not be triggered to run the actual processing of the entire data involved.When working with extremely large datasets, it makes sense to modify one’s workflow to accommodate this behavior. A reasonable workflow would then be to write down the pipeline so that the heavy load processing happens at the very end (which can then take several minutes, but you will have time for other things to do.)</p>
<p>The following short example taken from the script developed above illustrates this point. The arguably computationally most intensive part of the previous section was the sentiment annotation via <code>nlp_annotate()</code>:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-1" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(</span>
<span id="cb601-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-2" aria-hidden="true" tabindex="-1"></a>speeches_a <span class="ot">&lt;-</span> </span>
<span id="cb601-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">nlp_annotate</span>(pipeline,</span>
<span id="cb601-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">target =</span> speeches,</span>
<span id="cb601-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">column =</span> <span class="st">&quot;speech&quot;</span>)</span>
<span id="cb601-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb601-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.068   0.017   0.221</code></pre>
<p>Remember that the pre-trained pipeline used in this example includes many steps, such as breaking down speeches into sentences and words, cleaning the text, and predicting the sentiment of each sentence. When you run the code above, you’ll notice that this was not the most time-consuming part to compute. That chunk of code runs in less than a second on my machine (with a local Spark node). Because we do not request the sentiment analysis results at this point, the pipeline is not actually run. It is only executed when we request it. For example, by adding the <code>compute()</code> call at the end.</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-1" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(</span>
<span id="cb603-2"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-2" aria-hidden="true" tabindex="-1"></a>speeches_a <span class="ot">&lt;-</span> </span>
<span id="cb603-3"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">nlp_annotate</span>(pipeline,</span>
<span id="cb603-4"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">target =</span> speeches,</span>
<span id="cb603-5"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">column =</span> <span class="st">&quot;speech&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb603-6"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-6" aria-hidden="true" tabindex="-1"></a>     <span class="fu">compute</span>(<span class="at">name=</span> <span class="st">&quot;speeches_a&quot;</span>)</span>
<span id="cb603-7"><a href="large-scale-text-analysis-with-sparklyr.html#cb603-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.402   0.133  32.918</code></pre>
<p>As you can see, this takes an order of magnitude longer, which makes perfect sense given that the pipeline is now running for the entire dataset fed into it. Unless you require the intermediate results (for example, for inspection), it makes thus sense to only process the big workload at the end of your <code>sparklyr</code>-analytics script.</p>

</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gentzkow_shapiro2010" class="csl-entry">
Gentzkow, Matthew, and Jesse M. Shapiro. 2010. <span>“<span>What Drives Media Slant? Evidence From U.S. Daily Newspapers</span>.”</span> <em>Econometrica</em> 78 (1): 35–71. https://doi.org/<a href="https://doi.org/10.3982/ECTA7195">https://doi.org/10.3982/ECTA7195</a>.
</div>
<div id="ref-gentzkow_etal2019" class="csl-entry">
Gentzkow, Matthew, Jesse M. Shapiro, and Matt Taddy. 2019. <span>“<span class="nocase">Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech</span>.”</span> <em>Econometrica</em> 87 (4): 1307–40. https://doi.org/<a href="https://doi.org/10.3982/ECTA16566">https://doi.org/10.3982/ECTA16566</a>.
</div>
<div id="ref-gutenbergr" class="csl-entry">
Johnston, Myfanwy, and David Robinson. 2022. <em>Gutenbergr: Download and Process Public Domain Works from Project Gutenberg</em>. <a href="https://CRAN.R-project.org/package=gutenbergr">https://CRAN.R-project.org/package=gutenbergr</a>.
</div>
<div id="ref-sparknlp" class="csl-entry">
Kincaid, Dave, and Kevin Kuo. 2023. <em>Sparknlp: R Interface to John Snow Labs Spark NLP</em>.
</div>
<div id="ref-sparklyr.nested" class="csl-entry">
Pollock, Matt. 2023. <em>Sparklyr.nested: A ’Sparklyr’ Extension for Nested Data</em>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="76">
<li id="fn76"><p>Invalid for the context of this study.<a href="large-scale-text-analysis-with-sparklyr.html#fnref76" class="footnote-back">↩︎</a></p></li>
<li id="fn77"><p>Recall that Spark is made to operate on distributed systems. Since the entire dataset is distributed (as subsets) across the cluster, it is not as straightforward to fetch the first N entries of a dataset as compared to a situation in which the entire dataset is stored in one data frame residing in RAM.<a href="large-scale-text-analysis-with-sparklyr.html#fnref77" class="footnote-back">↩︎</a></p></li>
<li id="fn78"><p>The output of the entire pipeline is not at all large anymore at this stage, thus we can confidently call <code>collect()</code> to download the results (output data) from the Spark cluster into our local R memory (or the master node’s R memory when working in the cloud).<a href="large-scale-text-analysis-with-sparklyr.html#fnref78" class="footnote-back">↩︎</a></p></li>
<li id="fn79"><p>Note that even if we run this NLP pipeline for the entire text dataset of congressional speeches, the final aggregate output will easily fit into the RAM of a standard PC.<a href="large-scale-text-analysis-with-sparklyr.html#fnref79" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-analysis-and-categorization-with-spark-and-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix-a-github.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
