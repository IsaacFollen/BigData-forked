<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Hardware: Computing Resources | Big Data Analytics</title>
  <meta name="description" content="A guide to practical big data analytics in R." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Hardware: Computing Resources | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://umatter.github.io/BigData" />
  <meta property="og:image" content="https://umatter.github.io/BigDataimg/cover.png" />
  <meta property="og:description" content="A guide to practical big data analytics in R." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Hardware: Computing Resources | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to practical big data analytics in R." />
  <meta name="twitter:image" content="https://umatter.github.io/BigDataimg/cover.png" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2022-05-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="software-programming-with-big-data.html"/>
<link rel="next" href="distributed-systems.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/d3/d3.min.js"></script>
<link href="libs/profvis/profvis.css" rel="stylesheet" />
<script src="libs/profvis/profvis.js"></script>
<script src="libs/profvis/scroll.js"></script>
<link href="libs/highlight/textmate.css" rel="stylesheet" />
<script src="libs/highlight/highlight.js"></script>
<script src="libs/profvis-binding/profvis.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-big-in-big-data"><i class="fa fa-check"></i><b>1.1</b> What is <em>big</em> in “Big Data?”</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#approaches-to-analyzing-big-data"><i class="fa fa-check"></i><b>1.2</b> Approaches to analyzing Big Data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#content-overview"><i class="fa fa-check"></i><b>1.3</b> Content overview</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#prerequisits"><i class="fa fa-check"></i><b>1.4</b> Prerequisits</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="big-data-econometrics.html"><a href="big-data-econometrics.html"><i class="fa fa-check"></i><b>2</b> Big Data Econometrics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="big-data-econometrics.html"><a href="big-data-econometrics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>2.1</b> A practical <em>big P</em> problem</a></li>
<li class="chapter" data-level="2.2" data-path="big-data-econometrics.html"><a href="big-data-econometrics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>2.2</b> A practical <em>big N</em> problem</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="big-data-econometrics.html"><a href="big-data-econometrics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>2.2.1</b> OLS as a point of reference</a></li>
<li class="chapter" data-level="2.2.2" data-path="big-data-econometrics.html"><a href="big-data-econometrics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>2.2.2</b> The Uluru algorithm as an alternative to OLS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>3</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>3.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>3.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>3.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>3.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="3.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>3.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="3.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>3.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="3.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>3.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="3.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>3.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="3.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>3.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>3.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>3.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="3.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>3.4.2</b> Joins</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>4</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#components-of-a-standard-computing-environment"><i class="fa fa-check"></i><b>4.1</b> Components of a standard computing environment</a></li>
<li class="chapter" data-level="4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>4.2</b> Mass storage</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoid-redundancies"><i class="fa fa-check"></i><b>4.2.1</b> Avoid redundancies</a></li>
<li class="chapter" data-level="4.2.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>4.2.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>4.3</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="4.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>4.4</b> Combining RAM and hard-disk: virtual memory</a></li>
<li class="chapter" data-level="4.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>4.5</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>4.5.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="4.5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>4.5.2</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>4.6</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>4.6.1</b> GPUs in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>5</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="5.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>5.1</b> MapReduce</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce-concept-illustrated-in-r"><i class="fa fa-check"></i><b>5.1.1</b> Map/Reduce Concept Illustrated in R</a></li>
<li class="chapter" data-level="5.1.2" data-path="distributed-systems.html"><a href="distributed-systems.html#mapper"><i class="fa fa-check"></i><b>5.1.2</b> Mapper</a></li>
<li class="chapter" data-level="5.1.3" data-path="distributed-systems.html"><a href="distributed-systems.html#reducer"><i class="fa fa-check"></i><b>5.1.3</b> Reducer</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop"><i class="fa fa-check"></i><b>5.2</b> Hadoop</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>5.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="distributed-systems.html"><a href="distributed-systems.html#spark"><i class="fa fa-check"></i><b>5.3</b> Spark</a></li>
<li class="chapter" data-level="5.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>5.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>5.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>5.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="5.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>5.6</b> Spark with R + SQL</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>6</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-aws-ec2-and-rrstudio"><i class="fa fa-check"></i><b>6.1</b> Scaling up with AWS EC2 and R/RStudio</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>6.1.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="cloud-computing.html"><a href="cloud-computing.html#ec2-with-rstudio-and-gpus"><i class="fa fa-check"></i><b>6.2</b> EC2 with RStudio and GPUs</a></li>
<li class="chapter" data-level="6.3" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>6.3</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="6.4" data-path="cloud-computing.html"><a href="cloud-computing.html#aws-emr-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>6.4</b> AWS EMR: MapReduce in the cloud</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#set-up-an-emr-cluster-to-run-with-r"><i class="fa fa-check"></i><b>6.4.1</b> Set up an EMR cluster to run with R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>7</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>7.1</b> Gathering and compilation of raw data</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#nyc-taxi-data"><i class="fa fa-check"></i><b>7.1.1</b> NYC taxi data</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-import-and-memory-allocation"><i class="fa fa-check"></i><b>7.2</b> Data import and memory allocation</a></li>
<li class="chapter" data-level="7.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>7.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>7.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="7.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>7.3.2</b> Efficient data access: indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-rdbms"><i class="fa fa-check"></i><b>7.4</b> Connecting R to RDBMS</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>7.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>7.4.2</b> Importing data</a></li>
<li class="chapter" data-level="7.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issue-queries"><i class="fa fa-check"></i><b>7.4.3</b> Issue queries</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>7.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>7.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
<li class="chapter" data-level="7.5.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#database-server-in-the-cloud-mariadb-on-an-ec2-instance"><i class="fa fa-check"></i><b>7.5.2</b> Database server in the cloud: MariaDB on an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>8</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="8.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies"><i class="fa fa-check"></i><b>8.1</b> ‘Out-of-memory’ strategies</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>8.1.1</b> Chunking data with the <code>ff</code>-package</a></li>
<li class="chapter" data-level="8.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>8.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#typical-cleaning-tasks"><i class="fa fa-check"></i><b>8.2</b> Typical cleaning tasks</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-preparation-with-ff"><i class="fa fa-check"></i><b>8.2.1</b> Data Preparation with <code>ff</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>9</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>9.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>9.1.1</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="9.1.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#cross-tabulation-of-ff-vectors"><i class="fa fa-check"></i><b>9.1.2</b> Cross-tabulation of <code>ff</code> vectors</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>9.2</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>10</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="10.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>10.1</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="10.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#excursus-modify-and-create-themes"><i class="fa fa-check"></i><b>10.2</b> Excursus: modify and create themes</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#create-your-own-theme-simple-approach"><i class="fa fa-check"></i><b>10.2.1</b> Create your own theme: simple approach</a></li>
<li class="chapter" data-level="10.2.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#implementing-actual-themes-as-functions."><i class="fa fa-check"></i><b>10.2.2</b> Implementing actual themes as functions.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualize-time-and-space"><i class="fa fa-check"></i><b>10.3</b> Visualize Time and Space</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>10.3.1</b> Preparations</a></li>
<li class="chapter" data-level="10.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>10.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#excursus-change-color-schemes"><i class="fa fa-check"></i><b>10.4</b> Excursus: change color schemes</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html"><i class="fa fa-check"></i><b>11</b> Bottle Necks in Local Big Data Analytics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-data-import-and-memory-allocation"><i class="fa fa-check"></i><b>11.1</b> Case study: Data Import and Memory Allocation</a></li>
<li class="chapter" data-level="11.2" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>11.2</b> Case Study: Loops, Memory, and Vectorization</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#preparation"><i class="fa fa-check"></i><b>11.2.1</b> Preparation</a></li>
<li class="chapter" data-level="11.2.2" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>11.2.2</b> Naïve Approach (ignorant of R)</a></li>
<li class="chapter" data-level="11.2.3" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>11.2.3</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="11.2.4" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>11.2.4</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>11.3</b> Case study: Bootstrapping and Parallel Processing</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>11.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>11.4</b> Case Study: Efficient Fixed Effects Estimation</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html"><i class="fa fa-check"></i><b>12</b> GPUs and Machine Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>12.1</b> Tensorflow/Keras example: predict housing prices</a></li>
<li class="chapter" data-level="12.2" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#data-preparation-1"><i class="fa fa-check"></i><b>12.2</b> Data preparation</a></li>
<li class="chapter" data-level="12.3" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#model-specification"><i class="fa fa-check"></i><b>12.3</b> Model specification</a></li>
<li class="chapter" data-level="12.4" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#training-and-prediction"><i class="fa fa-check"></i><b>12.4</b> Training and prediction</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="gpus-and-machine-learning.html"><a href="gpus-and-machine-learning.html#a-word-of-caution"><i class="fa fa-check"></i><b>12.4.1</b> A word of caution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="applied-econometrics-with-spark.html"><a href="applied-econometrics-with-spark.html"><i class="fa fa-check"></i><b>13</b> Applied Econometrics with Spark</a>
<ul>
<li class="chapter" data-level="13.1" data-path="applied-econometrics-with-spark.html"><a href="applied-econometrics-with-spark.html#regression-analysis-with-sparklyr"><i class="fa fa-check"></i><b>13.1</b> Regression analysis with <code>sparklyr</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i><b>A</b> Appendix A</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendix-a.html"><a href="appendix-a.html#github"><i class="fa fa-check"></i><b>A.1</b> GitHub</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendix-a.html"><a href="appendix-a.html#initiate-a-new-repository"><i class="fa fa-check"></i><b>A.1.1</b> Initiate a new repository</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendix-a.html"><a href="appendix-a.html#clone-this-courses-repository"><i class="fa fa-check"></i><b>A.1.2</b> Clone this course’s repository</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendix-a.html"><a href="appendix-a.html#fork-this-courses-repository"><i class="fa fa-check"></i><b>A.1.3</b> Fork this course’s repository</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendix-b.html"><a href="appendix-b.html"><i class="fa fa-check"></i><b>B</b> Appendix B</a>
<ul>
<li class="chapter" data-level="B.0.1" data-path="appendix-b.html"><a href="appendix-b.html#data-types-and-memorystorage"><i class="fa fa-check"></i><b>B.0.1</b> Data types and memory/storage</a></li>
<li class="chapter" data-level="B.0.2" data-path="appendix-b.html"><a href="appendix-b.html#data-structures"><i class="fa fa-check"></i><b>B.0.2</b> Data structures</a></li>
<li class="chapter" data-level="B.0.3" data-path="appendix-b.html"><a href="appendix-b.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i><b>B.0.3</b> Vectors vs Factors in R</a></li>
<li class="chapter" data-level="B.0.4" data-path="appendix-b.html"><a href="appendix-b.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i><b>B.0.4</b> R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="appendix-c.html"><a href="appendix-c.html"><i class="fa fa-check"></i><b>C</b> Appendix C</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hardware-computing-resources" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Hardware: Computing Resources</h1>
<p>In order to better understand how we can use the available computing resources most efficiently in an analytics task, this chapter first provides a basic conceptual introduction to the most important hardware components and how they matter for computation.</p>
<div id="components-of-a-standard-computing-environment" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Components of a standard computing environment</h2>
<p>Figure <a href="hardware-computing-resources.html#fig:components">4.1</a> illustrates the key components of a standard computing environment to process digital data. In our case, these components serve the purpose of computing a statistic, given a large data set as input.</p>
<div class="figure" style="text-align: center"><span id="fig:components"></span>
<img src="img/03_script-hardware_w.jpg" alt="Basic components of a standard computing environment." width="60%" />
<p class="caption">
Figure 4.1: Basic components of a standard computing environment.
</p>
</div>

<ul>
<li><p><em>Mass Storage</em> refers to the type of computer memory we use to store data in the long run. This is what we call the <em>hard drive</em> or <em>hard disk</em>.</p></li>
<li><p>In order to work with data (e.g., in R), it first has to be loaded into the <em>memory</em> of our computer. More specifically, into the Random Access Memory (<em>RAM</em>). Typically, data is only loaded in the RAM as long as we work with it.</p></li>
<li><p>The component actually <em>processing</em> data is the Central Processing Unit (CPU). When using R to process data, R commands are translated into complex combinations of a small set of basic operations which the <em>CPU</em> then executes.</p></li>
</ul>
<p>For what follows, consider the main difference between ‘data analytics’ and ‘Big Data analytics’ that in the latter case, the standard usage of one or several of these components fails or works very inefficiently because the amount of data overwhelms its normal capacity.</p>
<p>From the hardware-perspective, there are two basic strategies to cope with the situation that one of these components is overwhelmed by the amount of data:</p>
<ul>
<li><em>Scale up (‘horizontal scaling’)</em>: Extend the physical capacity of the affected component by building a system with large RAM shared between applications. This sounds like a trivial solution (‘if RAM is too small, buy more RAM…’), but in practice it can be very expensive.</li>
<li><em>Scale out (‘vertical scaling’)</em>: Distribute the workload over several computers (or separate components of a system).</li>
</ul>
<p>From a software-perspective, there are many (context-specific) strategies that can help us to use the resources available more efficiently in order to process large amounts of data. In the following sub-sections, we first get an idea of what we mean by capacity and <em>big</em> regarding the most important hardware components. First we focus on mass storage and memory, then on</p>
</div>
<div id="mass-storage" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Mass storage</h2>
<p>In a simple computing environment, the mass storage device (hard disk) is where the data is stored to be analyzed. So, in what units to we measure the size of data sets and consequently the mass storage capacity of a computer? The smallest unit of information in computing/digital data is called a <em>bit</em> (from <em>bi</em>nary dig<em>it</em>; abbrev. ‘b’) and can take one of two (symbolic) values, either a <code>0</code> or a <code>1</code> (“off” or “on”). Consider, for example, the decimal number <code>139</code>. Written in the binary system, <code>139</code> corresponds to the binary number <code>10001011</code>. In order to store this number on a hard disk, we require a capacity of 8 bits, or one <em>byte</em> (1 byte = 8 bits; abbrev. ‘B’). Historically, one byte encoded a single character of text (i.e., in the ASCII character encoding system). 4 bytes (or 32 bits) are called a <em>word</em>. When thinking of a given data set in its raw/binary representation, we can simply think of it as a row of <code>0</code>s and <code>1</code>s.</p>
<p>Bigger units for storage capacity usually build on bytes:</p>
<ul>
<li><span class="math inline">\(1 \text{ kilobyte (KB)} = 1000^{1} \approx 2^{10} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ megabyte (MB)} = 1000^{2} \approx 2^{20} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ gigabyte (GB)} = 1000^{3} \approx 2^{30} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ terabyte (TB)} = 1000^{4} \approx 2^{40} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ petabyte (PB)} = 1000^{5} \approx 2^{50} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ exabyte (EB)} = 1000^{6} \approx 2^{60} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ zettabyte (ZB)} = 1000^{7} \approx 2^{70} \text{ bytes}\)</span></li>
</ul>
<p><span class="math display">\[1 ZB = 1000000000000000000000\text{ bytes} = 1 \text{ billion terabytes} = 1 \text{ trillion gigabytes}.\]</span>
Currently, a common laptop or desktop computer has several hundred GBs or 1-2 TBs of mass storage capacity. The problems related to a lack of mass storage capacity in Big Data Analytics are likely the easiest to understand. Suppose you collect large amounts of data from an online source such as the Twitter API. At some point, R will throw an error and stop the data collection procedure as the operating system will not allow R to use up more disk space. The simplest solution to this problem is to clean up your hard disk: empty the trash, archive files in the cloud or on an external drive and delete them on the main disk, etc. In addition, there are some easy-to-learn tricks to use from within R to safe some disk space.</p>
<div id="avoid-redundancies" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Avoid redundancies</h3>
<p>Different formats to structure data stored on disk use up more or less space. A simple example is the comparison of <a href="https://en.wikipedia.org/wiki/JSON">JSON (JavaScript Object Notaion)</a> to <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV (Comma Separated Values)</a>, both data structures that are widely used to store data for analytics purposes. JSON is much more flexible in that it allows the definition of abundantly complex hierarchical data structures (and even allows for hints at data types). However, this flexibility comes with some overhead in the usage of special characters to define the structure. Consider the following JSON excerpt of an economic time series fetched from the Federal Reserve’s <a href="https://fred.stlouisfed.org/docs/api/fred/series_observations.html#example_json">FRED API</a>.</p>
<pre><code>{
    &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
    &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
    &quot;observation_start&quot;: &quot;1776-07-04&quot;,
    &quot;observation_end&quot;: &quot;9999-12-31&quot;,
    &quot;units&quot;: &quot;lin&quot;,
    &quot;output_type&quot;: 1,
    &quot;file_type&quot;: &quot;json&quot;,
    &quot;order_by&quot;: &quot;observation_date&quot;,
    &quot;sort_order&quot;: &quot;asc&quot;,
    &quot;count&quot;: 84,
    &quot;offset&quot;: 0,
    &quot;limit&quot;: 100000,
    &quot;observations&quot;: [
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;1929-01-01&quot;,
            &quot;value&quot;: &quot;1065.9&quot;
        },
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;1930-01-01&quot;,
            &quot;value&quot;: &quot;975.5&quot;
        },
        ...,
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;2012-01-01&quot;,
            &quot;value&quot;: &quot;15693.1&quot;
        }
    ]
}</code></pre>
<p>The JSON format is very practical here to separate metadata (like what time frame is covered by this data set etc.) in the first few lines on top from the actual data in <code>"observations"</code> further down. However, note that due to this structure the key names like <code>"date"</code>, and <code>"value"</code> occur for each observation in that time series. In addition <code>"realtime_start"</code> and <code>"realtime_end"</code> occur both in the metadata section and again in each observation. Each of those occurrences costs some bytes of storage space on your hard disk but does not add any information once you have parsed and imported the time series into R. The same information could also be stored in a more efficient way on your hard disk by simply storing the metadata in a separate text file and the actual observations in a CSV file (in a table-like structure):</p>
<pre><code>&quot;date&quot;,&quot;value&quot;
&quot;1929-01-01&quot;, &quot;1065.9&quot;
&quot;1930-01-01&quot;, &quot;975.5&quot;

...,

&quot;2012-01-01&quot;, 15693.1&quot;</code></pre>
<p>In fact, in that particular example, storing the data in JSON format would take up more than double the hard-disk space than CSV. Of course, this is not to say that one should generally store data in CSV files. In many situations, you might really have to rely on JSON’s flexibility to represent more complex structures. However, in practice it is very much worth the while to think about whether you can improve storage efficiency by simply storing the raw data in a different format.</p>
<p>Another related point to storing data in CSV files is to remove redundancies by splitting the data into several tables/CSV-files, whereby each table contains the variables exclusively describing the type of observation in it. For example, when analyzing customer data for marketing purposes, the data set stored in one CSV file might be at the level of individual purchases. That is each row contains both information on what has been purchased on which day by which customer as well as additional variables describing the customer (such as customer id, name, address, etc.). Instead of keeping all of this data in one file, we could split it into two files, where one only contains the order ids and corresponding customer ids as well as attributes of individual orders (but not additional attributes of the customers themselves) and the other contains the customer ids and all customer attributes. Thereby, we avoid redundancies in the form of repeatedly storing the same values of customer attributes (like name and address) for each order.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
</div>
<div id="data-compression" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Data compression</h3>
<p>Data compression essentially follows from the same basic idea of avoiding redundancies in data storage as the simple approaches discussed above. However, it happens on a much more fundamental level. Data compression algorithms encode the information contained in the original representation of the data with fewer bits. In the case of lossless compression, this results in a new data file containing the exact same information but taking up less space on disk. In simple terms, compression replaces repeatedly occurring sequences with shorter expressions and keeps track of replacements in a table. Based on the table, the file can then again be de-compressed to show the original representation of the data. For example, consider the following character string containing.</p>
<pre><code>&quot;xxxxxyyyyyzzzz&quot;</code></pre>
<p>The same data could be represented with fewer bits as:</p>
<pre><code>&quot;5x6y4z&quot;</code></pre>
<p>which needs less than half the bits to be stored (but contains the same information).</p>
<p>There are several easy ways to use your mass storage capacity more efficiently with data compression in R. Most conveniently, some functions to import/export data in R directly allow for reading and writing of compressed formats. For example, the <code>fread()</code>/<code>fwrite()</code> functions provided in the <code>data.table</code>-package will automatically use the GZIP (de-)compression utility when writing to (reading from) a CSV file with a <code>.gz</code> file extension in the file name.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="hardware-computing-resources.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb123-2"><a href="hardware-computing-resources.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb123-3"><a href="hardware-computing-resources.html#cb123-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-4"><a href="hardware-computing-resources.html#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load example data from basic R installation</span></span>
<span id="cb123-5"><a href="hardware-computing-resources.html#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;LifeCycleSavings&quot;</span>)</span>
<span id="cb123-6"><a href="hardware-computing-resources.html#cb123-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-7"><a href="hardware-computing-resources.html#cb123-7" aria-hidden="true" tabindex="-1"></a><span class="co"># write data to normal csv file and check size</span></span>
<span id="cb123-8"><a href="hardware-computing-resources.html#cb123-8" aria-hidden="true" tabindex="-1"></a><span class="fu">fwrite</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb123-9"><a href="hardware-computing-resources.html#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1441</code></pre>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="hardware-computing-resources.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># write data to a GZIPPED (compressed) csv file and check size</span></span>
<span id="cb125-2"><a href="hardware-computing-resources.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fwrite</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv.gz&quot;</span>)</span>
<span id="cb125-3"><a href="hardware-computing-resources.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv.gz&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 744</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="hardware-computing-resources.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read/import the compressed data</span></span>
<span id="cb127-2"><a href="hardware-computing-resources.html#cb127-2" aria-hidden="true" tabindex="-1"></a>lcs <span class="ot">&lt;-</span> data.table<span class="sc">::</span><span class="fu">fread</span>(<span class="st">&quot;lcs.csv.gz&quot;</span>)</span></code></pre></div>
<p>Alternatively, you can also use other types of data compressions as follows.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="hardware-computing-resources.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># common ZIP compression (independent of data.table package)</span></span>
<span id="cb128-2"><a href="hardware-computing-resources.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb128-3"><a href="hardware-computing-resources.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1984</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="hardware-computing-resources.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">zip</span>(<span class="at">zipfile =</span> <span class="st">&quot;lcs.csv.zip&quot;</span>, <span class="at">files =</span>  <span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb130-2"><a href="hardware-computing-resources.html#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv.zip&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1205</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="hardware-computing-resources.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># unzip/decompress and read/import data</span></span>
<span id="cb132-2"><a href="hardware-computing-resources.html#cb132-2" aria-hidden="true" tabindex="-1"></a>lcs_path <span class="ot">&lt;-</span> <span class="fu">unzip</span>(<span class="st">&quot;lcs.csv.zip&quot;</span>)</span>
<span id="cb132-3"><a href="hardware-computing-resources.html#cb132-3" aria-hidden="true" tabindex="-1"></a>lcs <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(lcs_path)</span></code></pre></div>
<p>Note that data compression is subject to a time-memory trade-off. Compression and de-compression is computationally intense and needs time. When using compression in order to make more efficient use of the available mass storage capacity, think about how frequently you expect the data to be loaded into R as part of the data analysis tasks ahead and for how long your will need to keep the data stored on your hard disk. Importing GBs of compressed data can be uncomfortably slower than importing from a decompressed file.</p>
<p>So far, we have only focused on data size in the context of mass storage capacity. But what happens once you load a large data set into R (e.g., by means of <code>read.csv()</code>? A program called a “parser” is executed that reads the raw data from the hard disk and creates a representation of that data in the R environment, that is, in random access memory (RAM). All common computers have more GBs of mass storage available than GBs of RAM. Hence, new problems to hardware capacity loom at the stage of data import, which brings us to the next subsection.</p>
</div>
</div>
<div id="random-access-memory-ram" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Random access memory (RAM)</h2>
<p>Currently, a common laptop or desktop computer has 8-32 GB of RAM capacity. These are more-or-less the numbers you should keep in the back of your mind for the examples/discussions that follow. That is, we will consider a data set as “big” if it takes up several GBs in RAM (and therefore might overwhelm a machine with 8GB RAM capacity).</p>
<p>There are several types of problems that you might run into in practice when attempting to import and analyze a data set of the size close to or larger than your computers RAM capacity. First, importing the data might take much longer than expected, your computer might freeze during import (or later during the analysis), R/Rstudio might crash, you might get an Error message hinting at a lack of RAM. How can you anticipate such problems and what can you do about them?</p>
<p>Many of the techniques and packages discussed in the following chapters are in one or the other way solutions to this kind of problems. However, there are a few relatively simple things to keep in mind before we go into these details.</p>
<ol style="list-style-type: decimal">
<li><p>The same data stored on the mass storage device (e.g., in a CSV file) might take up more or less space in RAM. This is due to the fact that the data is (technically speaking) structured differently in a CSV or JSON file than in, for example, a data table or a matrix in R. For example, it is reasonable to anticipate that the example JSON file with the economic time series data, will take up less space as a time series object in R (in RAM) than it does on the hard disk (for one thing just simply due to the fact that we will not keep the redundancies mentioned before).</p></li>
<li><p>The import might work well but some parts of the data analysis script might require much more memory to run through even without loading additional data from disk. A classical example for this is regression analysis performed with, for example, <code>lm()</code> in R. As part of the OLS estimation procedure, <code>lm</code> will need to create the model matrix (usually denoted <span class="math inline">\(X\)</span>). Depending on the model you want to estimate, the model matrix might actually be larger than the data frame containing the data set. In fact, this can happen quite easily if you specify a fixed effects model in which you want to account for the fixed effects via dummy variables (for example, for each country except for one).<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> Again, the result can be one of several. An error message hinting to a lack of memory, a crash, or the computer slowing down a lot. Anticipating these types of problems is very tricky since the memory problems are often caused at a lower level of a function from the package that provides you with the data analytics routine you intend to use. Accordingly, error messages might be rather cryptic.</p></li>
<li><p>Keep in mind that you have some leeway to guide how much space imported data takes up in R by considering data structures and data types. For example, you can use factors instead of character vectors when importing categorical variables into R (the default in <code>read.csv</code>) and for some operations it makes sense to work with matrices instead of data frames.</p></li>
</ol>
<p>Finally, recall the lessons regarding memory usage from the section “Writing efficient R code” in chapter 1.</p>
</div>
<div id="combining-ram-and-hard-disk-virtual-memory" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Combining RAM and hard-disk: virtual memory</h2>
<p>what if all RAM of our computer is not enough to store all the data we want to analyze?</p>
<p>Modern operating systems have a way to dealing with such a situation. Once all RAM is used up by the currently running programs, the OS allocates parts of the memory back to the hard-disk which then works as <em>virtual memory</em>. The following figure illustrates this point.</p>
<div class="figure" style="text-align: center"><span id="fig:vm"></span>
<img src="img/03_virtualmemory.png" alt="Virtual memory. Figure by Ehamberg (CC BY-SA 3.0)." width="30%" />
<p class="caption">
Figure 4.2: Virtual memory. Figure by Ehamberg (CC BY-SA 3.0).
</p>
</div>

<p>For example, when we implement an R-script that imports one file after the other into the R environment, ignoring the RAM capacity of our computer, the OS will start <em>paging</em> data to the virtual memory. This happens ‘under the hood’ without explicit instructions by the user. We quite likely notice that the computer slows down a lot when this happens.</p>
<p>While this default usage of virtual memory by the OS is helpful to run several applications at the same time, each taking up a moderate amount of memory, it is not a really useful tool for processing large amounts of data in one application (R). However, the underlying idea of using both RAM and Mass storage simultaneously in order to cope with a lack of memory is very useful in the context of big data analytics.</p>
<p>Several R packages have been developed that exploit the idea behind virtual memory explicitly for analyzing large amounts of data. The basic idea behind these packages is to map a data set to the hard disk when loading it into R. The actual data values are stored in chunks on the hard-disk, while the structure/metadata of the data set is loaded into R. See this week’s slide set as well as <span class="citation"><a href="references.html#ref-walkowiak_2016" role="doc-biblioref">Walkowiak</a> (<a href="references.html#ref-walkowiak_2016" role="doc-biblioref">2016</a>)</span>, Chapter 3 for more details and example code.</p>
</div>
<div id="cpu-and-parallelization" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> CPU and parallelization</h2>
<p>The actual processing of the data is done in the computer’s central processing unit (CPU). Consequently, the performance of the CPU has a substantial effect on how fast a data analytics task runs. Thereby, a CPU’s performance is usually denoted by its <em>clock rate</em> measured in gigaherz (GHz). In simple terms, a CPU with a clock rate of 4.8 GHz can execute 4.8 billion basic operations per second. Holding all other aspects constant, you can thus expect an analytics task to run faster if it runs on a computer with higher CPU clock rate. Alternatively to scaling up the CPU, we can exploit that modern CPUs have several <em>cores</em>. In the normal usage of a PC, the operating system makes use of these cores in order to run several applications smoothly <em>in parallel</em> (e.g., you listen to music on Spotify while browsing the web and running some analytics script in RStudio in the background).</p>
<p>Modern computing environments such as R allow us to explicitly run parts of the same analytics task in parallel, that is, on several CPU cores at the same time. Following the same logic, we can also connect several computers (each with several CPU cores) in a cluster computer and run the program in parallel on all of these computing nodes. Both of these approaches are generally referred to as <em>parallelization</em> and both are supported in several R packages.</p>
<p>Thereby, an R program run in parallel typically involves the following steps</p>
<ul>
<li>First, several instances of R are running at the same time (across one machine with multiple CPU cores or across a cluster computer). One of the instances (i.e., the <em>master</em> instance) breaks the computation into batches and sends those to the other instances.</li>
<li>Second, each of the instances processes its batch and sends the results back to the master instance.</li>
<li>Finally, the master instance combines the partial results to the final result and returns it to the user.</li>
</ul>
<p>To illustrate this point, consider the following econometric problem: you have a customer <a href="https://www.kaggle.com/jackdaoud/marketing-data?select=marketing_data.csv">data set</a> with detailed data on customer characteristics, past customer behavior and information on online marketing campaigns. Your task is to figure out, which customers are more likely to react positively to the most recent online marketing campaign. The aim is to optimize personalized marketing campaigns in the future based on insights gained from this exercise. In a first step you take a computationally intense “brute force” approach: you run all possible regressions with the dependent variable <code>Response</code> (equal to 1 if the customer took the offer in the campaign and 0 otherwise). In total you have 21 independent variables, thus you need to run <span class="math inline">\(2^20=1048576\)</span> logit regressions (this is without considering linear combinations of covariates etc.). Finally, you want to select the model with the best fit according to deviance.</p>
<p>A simple sequential implementation to solve this problem could look like this (for the sake of time, we cap the number of regression models with N=10).</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="hardware-computing-resources.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># you can download the data set from </span></span>
<span id="cb133-2"><a href="hardware-computing-resources.html#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.kaggle.com/jackdaoud/marketing-data?select=marketing_data.csv</span></span>
<span id="cb133-3"><a href="hardware-computing-resources.html#cb133-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-4"><a href="hardware-computing-resources.html#cb133-4" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARATION -----------------------------</span></span>
<span id="cb133-5"><a href="hardware-computing-resources.html#cb133-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-6"><a href="hardware-computing-resources.html#cb133-6" aria-hidden="true" tabindex="-1"></a><span class="co"># packages</span></span>
<span id="cb133-7"><a href="hardware-computing-resources.html#cb133-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb133-8"><a href="hardware-computing-resources.html#cb133-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-9"><a href="hardware-computing-resources.html#cb133-9" aria-hidden="true" tabindex="-1"></a><span class="co"># import data</span></span>
<span id="cb133-10"><a href="hardware-computing-resources.html#cb133-10" aria-hidden="true" tabindex="-1"></a>marketing <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/marketing_data.csv&quot;</span>)</span>
<span id="cb133-11"><a href="hardware-computing-resources.html#cb133-11" aria-hidden="true" tabindex="-1"></a><span class="co"># clean/prepare data</span></span>
<span id="cb133-12"><a href="hardware-computing-resources.html#cb133-12" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Income <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">gsub</span>(<span class="st">&quot;[[:punct:]]&quot;</span>, <span class="st">&quot;&quot;</span>, marketing<span class="sc">$</span>Income)) </span>
<span id="cb133-13"><a href="hardware-computing-resources.html#cb133-13" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>days_customer <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="fu">Sys.Date</span>())<span class="sc">-</span> <span class="fu">as.Date</span>(marketing<span class="sc">$</span>Dt_Customer, <span class="st">&quot;%m/%d/%y&quot;</span>)</span>
<span id="cb133-14"><a href="hardware-computing-resources.html#cb133-14" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Dt_Customer <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb133-15"><a href="hardware-computing-resources.html#cb133-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-16"><a href="hardware-computing-resources.html#cb133-16" aria-hidden="true" tabindex="-1"></a><span class="co"># all sets of independent vars</span></span>
<span id="cb133-17"><a href="hardware-computing-resources.html#cb133-17" aria-hidden="true" tabindex="-1"></a>indep <span class="ot">&lt;-</span> <span class="fu">names</span>(marketing)[ <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">19</span>, <span class="dv">27</span>,<span class="dv">28</span>)]</span>
<span id="cb133-18"><a href="hardware-computing-resources.html#cb133-18" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(indep),</span>
<span id="cb133-19"><a href="hardware-computing-resources.html#cb133-19" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">function</span>(x) <span class="fu">combn</span>(indep, x, <span class="at">simplify =</span> <span class="cn">FALSE</span>))</span>
<span id="cb133-20"><a href="hardware-computing-resources.html#cb133-20" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">unlist</span>(combinations_list, <span class="at">recursive =</span> <span class="cn">FALSE</span>)</span>
<span id="cb133-21"><a href="hardware-computing-resources.html#cb133-21" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">lapply</span>(combinations_list,</span>
<span id="cb133-22"><a href="hardware-computing-resources.html#cb133-22" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;Response ~&quot;</span>, <span class="fu">paste</span>(x, <span class="at">collapse=</span><span class="st">&quot;+&quot;</span>)))</span>
<span id="cb133-23"><a href="hardware-computing-resources.html#cb133-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-24"><a href="hardware-computing-resources.html#cb133-24" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS --------------------------</span></span>
<span id="cb133-25"><a href="hardware-computing-resources.html#cb133-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-26"><a href="hardware-computing-resources.html#cb133-26" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb133-27"><a href="hardware-computing-resources.html#cb133-27" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb133-28"><a href="hardware-computing-resources.html#cb133-28" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(pseudo_Rsq) <span class="ot">&lt;-</span> N</span>
<span id="cb133-29"><a href="hardware-computing-resources.html#cb133-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb133-30"><a href="hardware-computing-resources.html#cb133-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb133-31"><a href="hardware-computing-resources.html#cb133-31" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb133-32"><a href="hardware-computing-resources.html#cb133-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb133-33"><a href="hardware-computing-resources.html#cb133-33" aria-hidden="true" tabindex="-1"></a>  pseudo_Rsq[[i]] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance)</span>
<span id="cb133-34"><a href="hardware-computing-resources.html#cb133-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb133-35"><a href="hardware-computing-resources.html#cb133-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-36"><a href="hardware-computing-resources.html#cb133-36" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb133-37"><a href="hardware-computing-resources.html#cb133-37" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ MntWines&quot;</code></pre>
<div id="naive-multi-session-approach" class="section level3" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Naive multi-session approach</h3>
<p>There is actually a simple way of doing this “manually” on a multi-core PC, which intuitively illustrates the point of parallelization (although it would not be a very practical approach): you write an R script that loads the data set, runs the fist <span class="math inline">\(n\)</span> of the total of <span class="math inline">\(N\)</span> regressions and stores the result in a local text file. Next, you run the script in your current RStudio session, open an additional RStudio session and run the script with the next <span class="math inline">\(n\)</span> regressions, and so on until all cores are occupied with one RStudio session. In the end you collect all of the results from the separate text files and combine them to get the final result. Depending on the problem at hand, this could indeed speed up the overall task and it is technically speaking a form of a “multi-session” approach. However, as you have surely noticed, this is unlikely a very practical approach.</p>
</div>
<div id="multi-core-and-multi-node-approach" class="section level3" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Multi-core and multi-node approach</h3>
<p>A more practical approach is to write one R script (with the help of some specialized packages) that instructs R to automatically distribute the batches to different cores (or different computing nodes in a cluster computer), control and monitor the progress in all cores, and then automatically collect and combine the results from all cores. There are several approaches to achieve this in R.</p>
<div id="parallel-for-loops-using-socket" class="section level4" number="4.5.2.1">
<h4><span class="header-section-number">4.5.2.1</span> Parallel for-loops using socket</h4>
<p>Likely the most intuitive approach to parallelizing a task in R is the <code>foreach</code> package. It allows you to write a <code>foreach</code> statement that is very similar to the for-loop syntax in R. Hence, you can straightforwardly “translate” an already implemented sequential approach with a common for-loop to a parallel implementation.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="hardware-computing-resources.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) --------------------------</span></span>
<span id="cb135-2"><a href="hardware-computing-resources.html#cb135-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-3"><a href="hardware-computing-resources.html#cb135-3" aria-hidden="true" tabindex="-1"></a><span class="co"># packages for parallel processing</span></span>
<span id="cb135-4"><a href="hardware-computing-resources.html#cb135-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb135-5"><a href="hardware-computing-resources.html#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doSNOW)</span></code></pre></div>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: snow</code></pre>
<pre><code>## 
## Attaching package: &#39;snow&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:parallel&#39;:
## 
##     clusterApply, clusterApplyLB, clusterCall,
##     clusterEvalQ, clusterExport, clusterMap,
##     clusterSplit, makeCluster, parApply,
##     parCapply, parLapply, parRapply, parSapply,
##     splitIndices, stopCluster</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="hardware-computing-resources.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get the number of cores available</span></span>
<span id="cb141-2"><a href="hardware-computing-resources.html#cb141-2" aria-hidden="true" tabindex="-1"></a>ncores <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb141-3"><a href="hardware-computing-resources.html#cb141-3" aria-hidden="true" tabindex="-1"></a><span class="co"># set cores for parallel processing</span></span>
<span id="cb141-4"><a href="hardware-computing-resources.html#cb141-4" aria-hidden="true" tabindex="-1"></a>ctemp <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(ncores)</span>
<span id="cb141-5"><a href="hardware-computing-resources.html#cb141-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoSNOW</span>(ctemp)</span>
<span id="cb141-6"><a href="hardware-computing-resources.html#cb141-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-7"><a href="hardware-computing-resources.html#cb141-7" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare loop</span></span>
<span id="cb141-8"><a href="hardware-computing-resources.html#cb141-8" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb141-9"><a href="hardware-computing-resources.html#cb141-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run loop in parallel</span></span>
<span id="cb141-10"><a href="hardware-computing-resources.html#cb141-10" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span></span>
<span id="cb141-11"><a href="hardware-computing-resources.html#cb141-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">foreach</span> ( <span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span>N, <span class="at">.combine =</span> c) <span class="sc">%dopar%</span> {</span>
<span id="cb141-12"><a href="hardware-computing-resources.html#cb141-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb141-13"><a href="hardware-computing-resources.html#cb141-13" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb141-14"><a href="hardware-computing-resources.html#cb141-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb141-15"><a href="hardware-computing-resources.html#cb141-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb141-16"><a href="hardware-computing-resources.html#cb141-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb141-17"><a href="hardware-computing-resources.html#cb141-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-18"><a href="hardware-computing-resources.html#cb141-18" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb141-19"><a href="hardware-computing-resources.html#cb141-19" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
<p>With relatively few cases, this approach is not very fast due to the overhead of “distributing” variables/objects from the master process to all cores/workers. In simple terms, the socket approach means that the cores do not share the same variables/the same environment, which creates overhead. However, this approach is usually very stable and runs on all platforms.</p>
</div>
<div id="parallel-lapply-using-forking" class="section level4" number="4.5.2.2">
<h4><span class="header-section-number">4.5.2.2</span> Parallel lapply using forking</h4>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="hardware-computing-resources.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) --------------------------</span></span>
<span id="cb143-2"><a href="hardware-computing-resources.html#cb143-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-3"><a href="hardware-computing-resources.html#cb143-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-4"><a href="hardware-computing-resources.html#cb143-4" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare parallel lapply (based on forking, here clearly faster than foreach)</span></span>
<span id="cb143-5"><a href="hardware-computing-resources.html#cb143-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb143-6"><a href="hardware-computing-resources.html#cb143-6" aria-hidden="true" tabindex="-1"></a><span class="co"># run parallel lapply</span></span>
<span id="cb143-7"><a href="hardware-computing-resources.html#cb143-7" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">mclapply</span>(<span class="dv">1</span><span class="sc">:</span>N,</span>
<span id="cb143-8"><a href="hardware-computing-resources.html#cb143-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mc.cores =</span> ncores,</span>
<span id="cb143-9"><a href="hardware-computing-resources.html#cb143-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">FUN =</span> <span class="cf">function</span>(i){</span>
<span id="cb143-10"><a href="hardware-computing-resources.html#cb143-10" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb143-11"><a href="hardware-computing-resources.html#cb143-11" aria-hidden="true" tabindex="-1"></a>                         fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb143-12"><a href="hardware-computing-resources.html#cb143-12" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb143-13"><a href="hardware-computing-resources.html#cb143-13" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb143-14"><a href="hardware-computing-resources.html#cb143-14" aria-hidden="true" tabindex="-1"></a>                         })</span>
<span id="cb143-15"><a href="hardware-computing-resources.html#cb143-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-16"><a href="hardware-computing-resources.html#cb143-16" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER, SHOW FINAL OUTPUT ---------------</span></span>
<span id="cb143-17"><a href="hardware-computing-resources.html#cb143-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-18"><a href="hardware-computing-resources.html#cb143-18" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span>
<span id="cb143-19"><a href="hardware-computing-resources.html#cb143-19" aria-hidden="true" tabindex="-1"></a>best_model</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="hardware-computing-resources.html#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(glm(best_model, data=marketing, family = binomial()))</span></span></code></pre></div>
<p>In the fork approach, each core works with the same objects/variables in a shared environment, which makes this approach very fast. However, depending on what exactly is computed, sharing an environment can cause problems.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> If you are not sure whether your set up might run into issues with forking, better rely on a non-fork approach.</p>
<!-- #### Parallelization based on futures -->
<!-- https://github.com/HenrikBengtsson/future -->
<!-- https://cran.r-project.org/web/packages/future/vignettes/future-3-topologies.html -->
</div>
</div>
</div>
<div id="gpus-for-scientific-computing" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> GPUs for scientific computing</h2>
<p>The success of the computer games industry in the late 1990s/early 2000s led to an interesting positive externality for scientific computing. The ever more demanding graphics of modern computer games and the huge economic success of the computer games industry set incentives for hardware producers to invest in research and development of more powerful ‘graphic cards,’ extending a normal PC/computing environment with additional computing power solely dedicated to graphics. At the heart of these graphic cards are so-called GPUs (Graphic Processing Units), microprocessors specifically optimized for graphics processing. The image below depicts a modern graphics card with NVIDIA GPUs, which is quite common in today’s ‘gaming’ PCs.</p>
<p><img src="img/nvidia_geeforce.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Why did the hardware industry not simply invest in the development of more powerful CPUs to deal with the more demanding PC games? The main reason is that the architecture of CPUs is designed not only for efficiency but also flexibility. That is, a CPU needs to perform well in all kind of computations, some parallel, some sequential, etc. Computing graphics is a comparatively narrow domain of computation and designing a processing unit architecture that is custom-made to excel just at this one task is thus much more cost efficient. Interestingly, this graphics-specific architecture (specialized on highly parallel numerical [floating point] workloads) turns out to be also very useful in some core scientific computing tasks. In particular, matrix multiplications (see <span class="citation"><a href="references.html#ref-fatahalian_etal2004" role="doc-biblioref">Fatahalian, Sugerman, and Hanrahan</a> (<a href="references.html#ref-fatahalian_etal2004" role="doc-biblioref">2004</a>)</span> for a detailed discussion of why that is the case). A key aspect of GPUs is that they are composed of several multiprocessor units, of which each has in turn several cores. GPUS thus can perform computations with hundreds or even thousands of threads in parallel. The figure below illustrates this point.</p>
<p><img src="img/nvidia_gpu.png" width="60%" style="display: block; margin: auto;" /></p>
<!-- ```{r nvidia_architecture, echo=FALSE, out.width = "60%", fig.align='center', fig.cap= "(ref:nvidiaarchitecture)", purl=FALSE} -->
<!-- include_graphics("img/nvidia_gpu.png") -->
<!-- ``` -->
<!-- (ref:nvidiaarchitecture) Typical NVIDIA GPU architecture (illustration and notes by @hernandez_etal2013). The GPU is comprised of a set of Streaming MultiProcessors (SM). Each SM is comprised of several Stream Processor (SP) cores, as shown for the NVIDIA’s Fermi architecture (a). The GPU resources are controlled by the programmer through the CUDA programming model, shown in (b). -->
<p>While, initially, programming GPUs for scientific computing required a very good understanding of the hardware. Graphics card producers have realized that there is an additional market for their products (in particular with the recent rise of deep learning), and provide several high-level APIs to use GPUs for other tasks than graphics processing. Over the last few years more high-level software has been developed, which makes it much easier to use GPUs in parallel computing tasks. The following subsections shows some examples of such software in the R environment.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></p>
<div id="gpus-in-r" class="section level3" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> GPUs in R</h3>
<!-- ## Installation -->
<!-- This is for pop OS machines. Install drivers etc. for NVIDIA card -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install OpenCL -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install `gpuR` in R (`install.packages("gpuR")`). -->
<div id="gpu-computing-example-matrix-multiplication-comparison-gpur" class="section level4" number="4.6.1.1">
<h4><span class="header-section-number">4.6.1.1</span> GPU computing example: Matrix multiplication comparison (<code>gpuR</code>)</h4>
<p>The <code>gpuR</code> package provides basic R functions to compute with GPUs from within the R environment. In the following example we compare the performance of the CPU with the GPU based on a matrix multiplication exercise. For a large <span class="math inline">\(N\times P\)</span> matrix <span class="math inline">\(X\)</span>, we want to compute <span class="math inline">\(X^tX\)</span>.</p>
<p>In a first step, we load the <code>gpuR</code>-package.<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> Note the output to the console. It shows the type of GPU identified by <code>gpuR</code>. This is the platform on which <code>gpuR</code> will compute the GPU examples. In order to compare the performances, we also load the <code>bench</code> package.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="hardware-computing-resources.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load package</span></span>
<span id="cb146-2"><a href="hardware-computing-resources.html#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bench)</span>
<span id="cb146-3"><a href="hardware-computing-resources.html#cb146-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gpuR)</span></code></pre></div>
<pre><code>## Number of platforms: 1
## - platform: NVIDIA Corporation: OpenCL 3.0 CUDA 11.6.134
##   - context device index: 0
##     - NVIDIA GeForce GTX 1650
## checked all devices
## completed initialization</code></pre>
<p>Next, we initiate a large matrix filled with pseudo random numbers, representing a data set with <span class="math inline">\(N\)</span> observations and <span class="math inline">\(P\)</span> variables.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="hardware-computing-resources.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initiate data set with pseudo random numbers</span></span>
<span id="cb148-2"><a href="hardware-computing-resources.html#cb148-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span>  <span class="co"># number of observations</span></span>
<span id="cb148-3"><a href="hardware-computing-resources.html#cb148-3" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># number of variables</span></span>
<span id="cb148-4"><a href="hardware-computing-resources.html#cb148-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(N <span class="sc">*</span> P, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N, <span class="at">ncol =</span>P)</span></code></pre></div>
<p>For the GPU examples to work, we need one more preparatory step. GPUs have their own memory, which they can access faster than they can access RAM. However, this GPU memory is typically not very large compared to the memory CPUs have access to. Hence, there is a potential trade-off between losing some efficiency but working with more data or vice versa.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> Here, we show both variants. With <code>gpuMatrix()</code> we create an object representing matrix <code>X</code> for computation on the GPU. However, this only points the GPU to the matrix and does not actually transfer data to the GPU’s memory. The latter is done in the other variant with <code>vclMatrix()</code>.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="hardware-computing-resources.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare GPU-specific objects/settings</span></span>
<span id="cb149-2"><a href="hardware-computing-resources.html#cb149-2" aria-hidden="true" tabindex="-1"></a>gpuX <span class="ot">&lt;-</span> <span class="fu">gpuMatrix</span>(X, <span class="at">type =</span> <span class="st">&quot;float&quot;</span>)  <span class="co"># point GPU to matrix (matrix stored in non-GPU memory)</span></span>
<span id="cb149-3"><a href="hardware-computing-resources.html#cb149-3" aria-hidden="true" tabindex="-1"></a>vclX <span class="ot">&lt;-</span> <span class="fu">vclMatrix</span>(X, <span class="at">type =</span> <span class="st">&quot;float&quot;</span>)  <span class="co"># transfer matrix to GPU (matrix stored in GPU memory)</span></span></code></pre></div>
<p>Now we run the three examples: first, based on standard R, using the CPU. Then, computing on the GPU but using CPU memory. And finally, computing on the GPU and using GPU memory. In order to make the comparison fair, we force <code>bench::mark()</code> to run at least 20 iterations per benchmarked variant.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="hardware-computing-resources.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compare three approaches</span></span>
<span id="cb150-2"><a href="hardware-computing-resources.html#cb150-2" aria-hidden="true" tabindex="-1"></a>(gpu_cpu <span class="ot">&lt;-</span> bench<span class="sc">::</span><span class="fu">mark</span>(</span>
<span id="cb150-3"><a href="hardware-computing-resources.html#cb150-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-4"><a href="hardware-computing-resources.html#cb150-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute with CPU </span></span>
<span id="cb150-5"><a href="hardware-computing-resources.html#cb150-5" aria-hidden="true" tabindex="-1"></a>  cpu <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> X,</span>
<span id="cb150-6"><a href="hardware-computing-resources.html#cb150-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-7"><a href="hardware-computing-resources.html#cb150-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GPU version, GPU pointer to CPU memory (gpuMatrix is simply a pointer)</span></span>
<span id="cb150-8"><a href="hardware-computing-resources.html#cb150-8" aria-hidden="true" tabindex="-1"></a>  gpu1_pointer <span class="ot">&lt;-</span> <span class="fu">t</span>(gpuX) <span class="sc">%*%</span> gpuX,</span>
<span id="cb150-9"><a href="hardware-computing-resources.html#cb150-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb150-10"><a href="hardware-computing-resources.html#cb150-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GPU version, in GPU memory (vclMatrix formation is a memory transfer)</span></span>
<span id="cb150-11"><a href="hardware-computing-resources.html#cb150-11" aria-hidden="true" tabindex="-1"></a>  gpu2_memory <span class="ot">&lt;-</span> <span class="fu">t</span>(vclX) <span class="sc">%*%</span> vclX,</span>
<span id="cb150-12"><a href="hardware-computing-resources.html#cb150-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb150-13"><a href="hardware-computing-resources.html#cb150-13" aria-hidden="true" tabindex="-1"></a><span class="at">check =</span> <span class="cn">FALSE</span>, <span class="at">memory =</span> <span class="cn">FALSE</span>, <span class="at">min_iterations =</span> <span class="dv">20</span>))</span></code></pre></div>
<pre><code>## # A tibble: 3 x 6
##   expression                            min   median
##   &lt;bch:expr&gt;                       &lt;bch:tm&gt; &lt;bch:tm&gt;
## 1 cpu &lt;- t(X) %*% X                 71.87ms   75.2ms
## 2 gpu1_pointer &lt;- t(gpuX) %*% gpuX  33.18ms   34.6ms
## 3 gpu2_memory &lt;- t(vclX) %*% vclX    9.71ms   15.6ms
## # … with 3 more variables: itr/sec &lt;dbl&gt;,
## #   mem_alloc &lt;bch:byt&gt;, gc/sec &lt;dbl&gt;</code></pre>
<p>The performance comparison is visualized with boxplots.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="hardware-computing-resources.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gpu_cpu, <span class="at">type =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<p><img src="bigdata_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>The theoretically expected pattern becomes clearly visible. When using the GPU + GPU memory, the matrix operation takes on average less than 20ms , with GPU + RAM over 30ms and with the common CPU operation close to 100ms to finish. In the chapters on applied data analysis, we will look at some applications of GPUs in the domain of deep learning (which heavily relies on matrix multiplications).</p>
<!-- ## Resource allocation  -->
<!-- When optimizing the performance of an analytics program processing large amounts of data, it is useful to differentiate between the efficient allocation of computational (CPU) power, and the allocation of RAM (and mass storage).^[In many data analysis tasks the two are, of course, intertwined. However, keeping both aspects in mind when optimizing an analytics program helps to choose the right tools.] Below, we will look at both aspects in turn.  -->

</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p>This concept of organizing data in several tables is the basis of relational database management systems, which we will look at in more detail in chapter 5. However, the basic idea is also very useful to store the raw data efficiently even if there is not intention to later build a database and run SQL queries on it.<a href="hardware-computing-resources.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>For example, if you specify something like <code>lm(y~x1 + x2 + country, data=mydata)</code> and <code>country</code> is a categorical variable (factor).<a href="hardware-computing-resources.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Also, this approach does not work on Windows machines (see <code>?mclapply</code> for details).<a href="hardware-computing-resources.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Note that while these examples are easy to implement and run, setting up a GPU for scientific computing still can involve many steps and some knowledge of your computer’s system. The examples presuppose that all installation and configuration steps (GPU drivers, CUDA, etc.) have already been completed successfully.<a href="hardware-computing-resources.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>As with the setting up of GPUs on your machine in general, installing all prerequisites to make <code>gpuR</code> work on your local machine can be a bit of work and can depend a lot on your system.<a href="hardware-computing-resources.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>If we instruct the GPU to use the own memory, but the data does not fit in it, the program will result in an error.<a href="hardware-computing-resources.html#fnref24" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="software-programming-with-big-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distributed-systems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bigdata.pdf", "bigdata.html", "bigdata.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
