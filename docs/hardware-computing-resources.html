<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Hardware: Computing Resources | Big Data Analytics</title>
  <meta name="description" content="Chapter 5 Hardware: Computing Resources | Big Data Analytics" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Hardware: Computing Resources | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://umatter.github.io/BigData/img/cover_print.jpg" />
  
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Hardware: Computing Resources | Big Data Analytics" />
  
  
  <meta name="twitter:image" content="https://umatter.github.io/BigData/img/cover_print.jpg" />

<meta name="author" content="Ulrich Matter" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="software-programming-with-big-data.html"/>
<link rel="next" href="distributed-systems.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style/style_new.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#background-and-goals-of-this-book"><i class="fa fa-check"></i>Background and goals of this book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#a-moving-target"><i class="fa fa-check"></i>A moving target</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#content-and-organization-of-the-book"><i class="fa fa-check"></i>Content and organization of the book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#prerequisites-and-requirements"><i class="fa fa-check"></i>Prerequisites and requirements</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#supplementary-materials-code-examples-datasets-and-documentation"><i class="fa fa-check"></i>Supplementary Materials: Code Examples, Datasets, and Documentation</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#thanks"><i class="fa fa-check"></i>Thanks</a></li>
</ul></li>
<li class="part"><span><b>I Setting the Scene: Analyzing Big Data</b></span></li>
<li class="chapter" data-level="" data-path="s.html"><a href="s.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="what-is-big-in-big-data.html"><a href="what-is-big-in-big-data.html"><i class="fa fa-check"></i><b>1</b> What is <em>Big</em> in “Big Data”?</a></li>
<li class="chapter" data-level="2" data-path="approaches-to-analyzing-big-data.html"><a href="approaches-to-analyzing-big-data.html"><i class="fa fa-check"></i><b>2</b> Approaches to Analyzing Big Data</a></li>
<li class="chapter" data-level="3" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html"><i class="fa fa-check"></i><b>3</b> The Two Domains of Big Data Analytics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>3.1</b> A practical <em>big P</em> problem </a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#simple-logistic-regression-naive-approach"><i class="fa fa-check"></i><b>3.1.1</b> Simple logistic regression (naive approach)</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#regularization-the-lasso-estimator"><i class="fa fa-check"></i><b>3.1.2</b> Regularization: the lasso estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>3.2</b> A practical <em>big N</em> problem </a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>3.2.1</b> OLS as a point of reference </a></li>
<li class="chapter" data-level="3.2.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>3.2.2</b> The <em>Uluru</em> algorithm as an alternative to OLS </a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Platform: Software and Computing Resources</b></span></li>
<li class="chapter" data-level="" data-path="p.html"><a href="p.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>4</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>4.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>4.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="4.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>4.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>4.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="4.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>4.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="4.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>4.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="4.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoiding-unnecessary-copying"><i class="fa fa-check"></i><b>4.3.4</b> Avoiding unnecessary copying</a></li>
<li class="chapter" data-level="4.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>4.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="4.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>4.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>4.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>4.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="4.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>4.4.2</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#with-a-little-help-from-my-friends-gpt-and-rsql-coding"><i class="fa fa-check"></i><b>4.5</b> With a little help from my friends: GPT and R/SQL coding</a></li>
<li class="chapter" data-level="4.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#wrapping-up"><i class="fa fa-check"></i><b>4.6</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>5</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>5.1</b> Mass storage</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoiding-redundancies"><i class="fa fa-check"></i><b>5.1.1</b> Avoiding redundancies</a></li>
<li class="chapter" data-level="5.1.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>5.1.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>5.2</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="5.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>5.3</b> Combining RAM and hard disk: Virtual memory</a></li>
<li class="chapter" data-level="5.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>5.4</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>5.4.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="5.4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-session-approach-with-futures"><i class="fa fa-check"></i><b>5.4.2</b> Multi-session approach with futures</a></li>
<li class="chapter" data-level="5.4.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>5.4.3</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>5.5</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>5.5.1</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The road ahead: Hardware made for machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#wrapping-up-1"><i class="fa fa-check"></i><b>5.7</b> Wrapping up</a></li>
<li class="chapter" data-level="5.8" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#still-have-insufficient-computing-resources"><i class="fa fa-check"></i><b>5.8</b> Still have insufficient computing resources?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>6</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>6.1</b> MapReduce</a></li>
<li class="chapter" data-level="6.2" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-hadoop"><i class="fa fa-check"></i><b>6.2</b> Apache Hadoop</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>6.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-spark"><i class="fa fa-check"></i><b>6.3</b> Apache Spark</a></li>
<li class="chapter" data-level="6.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>6.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>6.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="6.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>6.6</b> Spark with R + SQL</a></li>
<li class="chapter" data-level="6.7" data-path="distributed-systems.html"><a href="distributed-systems.html#wrapping-up-2"><i class="fa fa-check"></i><b>6.7</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>7</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cloud-computing.html"><a href="cloud-computing.html#cloud-computing-basics-and-platforms"><i class="fa fa-check"></i><b>7.1</b> Cloud computing basics and platforms</a></li>
<li class="chapter" data-level="7.2" data-path="cloud-computing.html"><a href="cloud-computing.html#transitioning-to-the-cloud"><i class="fa fa-check"></i><b>7.2</b> Transitioning to the cloud</a></li>
<li class="chapter" data-level="7.3" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-in-the-cloud-virtual-servers"><i class="fa fa-check"></i><b>7.3</b> Scaling up in the cloud: Virtual servers</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>7.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-gpus"><i class="fa fa-check"></i><b>7.4</b> Scaling up with GPUs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>7.4.1</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="7.4.2" data-path="cloud-computing.html"><a href="cloud-computing.html#rstudio-and-ec2-with-gpus-on-aws"><i class="fa fa-check"></i><b>7.4.2</b> RStudio and EC2 with GPUs on AWS</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-out-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>7.5</b> Scaling out: MapReduce in the cloud</a></li>
<li class="chapter" data-level="7.6" data-path="cloud-computing.html"><a href="cloud-computing.html#wrapping-up-3"><i class="fa fa-check"></i><b>7.6</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>III Components of Big Data Analytics</b></span></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>8</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>8.1</b> Gathering and compilation of raw data</a></li>
<li class="chapter" data-level="8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#stackcombine-raw-source-files"><i class="fa fa-check"></i><b>8.2</b> Stack/combine raw source files</a></li>
<li class="chapter" data-level="8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>8.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>8.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="8.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>8.3.2</b> Efficient data access: Indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-an-rdbms"><i class="fa fa-check"></i><b>8.4</b> Connecting R to an RDBMS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>8.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>8.4.2</b> Importing data</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issuing-queries"><i class="fa fa-check"></i><b>8.4.3</b> Issuing queries</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>8.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>8.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#column-based-analytics-databases"><i class="fa fa-check"></i><b>8.6</b> Column-based analytics databases</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#installation-and-start-up"><i class="fa fa-check"></i><b>8.6.1</b> Installation and start up</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#first-steps-via-druids-gui"><i class="fa fa-check"></i><b>8.6.2</b> First steps via Druid’s GUI</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#query-druid-from-r"><i class="fa fa-check"></i><b>8.6.3</b> Query Druid from R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouses"><i class="fa fa-check"></i><b>8.7</b> Data warehouses</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example"><i class="fa fa-check"></i><b>8.7.1</b> Data warehouse for analytics: Google BigQuery example</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service"><i class="fa fa-check"></i><b>8.8</b> Data lakes and simple storage service</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps"><i class="fa fa-check"></i><b>8.8.1</b> AWS S3 with R: First steps</a></li>
<li class="chapter" data-level="8.8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#uploading-data-to-s3"><i class="fa fa-check"></i><b>8.8.2</b> Uploading data to S3</a></li>
<li class="chapter" data-level="8.8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-amazon-athena"><i class="fa fa-check"></i><b>8.8.3</b> More than just simple storage: S3 + Amazon Athena</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#wrapping-up-4"><i class="fa fa-check"></i><b>8.9</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>9</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics"><i class="fa fa-check"></i><b>9.1</b> Out-of-memory strategies and lazy evaluation: Practical basics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>9.1.1</b> Chunking data with the <code>ff</code> package</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>9.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow"><i class="fa fa-check"></i><b>9.1.3</b> Connecting to Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-ff"><i class="fa fa-check"></i><b>9.2</b> Big Data preparation tutorial with <code>ff</code></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-import"><i class="fa fa-check"></i><b>9.2.2</b> Data import</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-imported-files"><i class="fa fa-check"></i><b>9.2.3</b> Inspect imported files</a></li>
<li class="chapter" data-level="9.2.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation"><i class="fa fa-check"></i><b>9.2.4</b> Data cleaning and transformation</a></li>
<li class="chapter" data-level="9.2.5" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-difference-in-in-memory-operation"><i class="fa fa-check"></i><b>9.2.5</b> Inspect difference in in-memory operation</a></li>
<li class="chapter" data-level="9.2.6" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#subsetting"><i class="fa fa-check"></i><b>9.2.6</b> Subsetting</a></li>
<li class="chapter" data-level="9.2.7" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#saveloadexport-ff-files"><i class="fa fa-check"></i><b>9.2.7</b> Save/load/export <code>ff</code> files</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-arrow"><i class="fa fa-check"></i><b>9.3</b> Big Data preparation tutorial with <code>arrow</code></a></li>
<li class="chapter" data-level="9.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#wrapping-up-5"><i class="fa fa-check"></i><b>9.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>10</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>10.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a></li>
<li class="chapter" data-level="10.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>10.2</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="10.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-arrow"><i class="fa fa-check"></i><b>10.3</b> High-speed in-memory data aggregation with <code>arrow</code></a></li>
<li class="chapter" data-level="10.4" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>10.4</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
<li class="chapter" data-level="10.5" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#wrapping-up-6"><i class="fa fa-check"></i><b>10.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>11</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#challenges-of-big-data-visualization"><i class="fa fa-check"></i><b>11.1</b> Challenges of Big Data visualization</a></li>
<li class="chapter" data-level="11.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>11.2</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="11.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualizing-time-and-space"><i class="fa fa-check"></i><b>11.3</b> Visualizing time and space</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>11.3.1</b> Preparations</a></li>
<li class="chapter" data-level="11.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>11.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#wrapping-up-7"><i class="fa fa-check"></i><b>11.4</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>IV Application: Topics in Big Data Econometrics</b></span></li>
<li class="chapter" data-level="" data-path="a.html"><a href="a.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html"><i class="fa fa-check"></i><b>12</b> Bottlenecks in Everyday Data Analytics Tasks</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>12.1</b> Case study: Efficient fixed effects estimation</a></li>
<li class="chapter" data-level="12.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>12.2</b> Case study: Loops, memory, and vectorization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>12.2.1</b> Naïve approach (ignorant of R)</a></li>
<li class="chapter" data-level="12.2.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>12.2.2</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="12.2.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>12.2.3</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>12.3</b> Case study: Bootstrapping and parallel processing</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>12.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html"><i class="fa fa-check"></i><b>13</b> Econometrics with GPUs</a>
<ul>
<li class="chapter" data-level="13.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#ols-on-gpus"><i class="fa fa-check"></i><b>13.1</b> OLS on GPUs</a></li>
<li class="chapter" data-level="13.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#a-word-of-caution"><i class="fa fa-check"></i><b>13.2</b> A word of caution</a></li>
<li class="chapter" data-level="13.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#higher-level-interfaces-for-basic-econometrics-with-gpus"><i class="fa fa-check"></i><b>13.3</b> Higher-level interfaces for basic econometrics with GPUs</a></li>
<li class="chapter" data-level="13.4" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>13.4</b> TensorFlow/Keras example: Predict housing prices</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#data-preparation"><i class="fa fa-check"></i><b>13.4.1</b> Data preparation</a></li>
<li class="chapter" data-level="13.4.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#model-specification"><i class="fa fa-check"></i><b>13.4.2</b> Model specification</a></li>
<li class="chapter" data-level="13.4.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#training-and-prediction"><i class="fa fa-check"></i><b>13.4.3</b> Training and prediction</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#wrapping-up-8"><i class="fa fa-check"></i><b>13.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html"><i class="fa fa-check"></i><b>14</b> Regression Analysis and Categorization with Spark and R</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-linear-regression-analysis"><i class="fa fa-check"></i><b>14.1</b> Simple linear regression analysis</a></li>
<li class="chapter" data-level="14.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification"><i class="fa fa-check"></i><b>14.2</b> Machine learning for classification</a></li>
<li class="chapter" data-level="14.3" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark"><i class="fa fa-check"></i><b>14.3</b> Building machine learning pipelines with R and Spark</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import"><i class="fa fa-check"></i><b>14.3.1</b> Set up and data import</a></li>
<li class="chapter" data-level="14.3.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline"><i class="fa fa-check"></i><b>14.3.2</b> Building the pipeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-9"><i class="fa fa-check"></i><b>14.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html"><i class="fa fa-check"></i><b>15</b> Large-scale Text Analysis with sparklyr</a>
<ul>
<li class="chapter" data-level="15.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count"><i class="fa fa-check"></i><b>15.1</b> Getting started: Import, pre-processing, and word count</a></li>
<li class="chapter" data-level="15.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#tutorial-political-slant"><i class="fa fa-check"></i><b>15.2</b> Tutorial: political slant</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#data-download-and-import"><i class="fa fa-check"></i><b>15.2.1</b> Data download and import</a></li>
<li class="chapter" data-level="15.2.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#cleaning-speeches-data"><i class="fa fa-check"></i><b>15.2.2</b> Cleaning speeches data</a></li>
<li class="chapter" data-level="15.2.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#create-a-bigrams-count-per-party"><i class="fa fa-check"></i><b>15.2.3</b> Create a bigrams count per party</a></li>
<li class="chapter" data-level="15.2.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#find-partisan-phrases"><i class="fa fa-check"></i><b>15.2.4</b> Find “partisan” phrases</a></li>
<li class="chapter" data-level="15.2.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#results-most-partisan-phrases-by-congress"><i class="fa fa-check"></i><b>15.2.5</b> Results: Most partisan phrases by congress</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#natural-language-processing-at-scale"><i class="fa fa-check"></i><b>15.3</b> Natural Language Processing at Scale</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#preparatory-steps"><i class="fa fa-check"></i><b>15.3.1</b> Preparatory steps</a></li>
<li class="chapter" data-level="15.3.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sentiment-annotation"><i class="fa fa-check"></i><b>15.3.2</b> Sentiment annotation</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#aggregation-and-visualization"><i class="fa fa-check"></i><b>15.4</b> Aggregation and visualization</a></li>
<li class="chapter" data-level="15.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sparklyr-and-lazy-evaluation"><i class="fa fa-check"></i><b>15.5</b> <code>sparklyr</code> and lazy evaluation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html"><i class="fa fa-check"></i>Appendix A: GitHub</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#initiate-a-new-repository"><i class="fa fa-check"></i>Initiate a new repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#clone-this-books-repository"><i class="fa fa-check"></i>Clone this book’s repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#fork-this-books-repository"><i class="fa fa-check"></i>Fork this book’s repository</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html"><i class="fa fa-check"></i>Appendix B: R Basics</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-types-and-memorystorage"><i class="fa fa-check"></i>Data types and memory/storage</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#example-data-types-and-information-storage"><i class="fa fa-check"></i>Example: Data types and information storage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-structures"><i class="fa fa-check"></i>Data structures</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#vectors-vs.-factors-in-r"><i class="fa fa-check"></i>Vectors vs. Factors in R</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#matricesarrays"><i class="fa fa-check"></i>Matrices/Arrays</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-frames-tibbles-and-data-tables"><i class="fa fa-check"></i>Data frames, tibbles, and data tables</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i>R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-c-install-hadoop.html"><a href="appendix-c-install-hadoop.html"><i class="fa fa-check"></i>Appendix C: Install Hadoop</a></li>
<li class="part"><span><b>VI References and Index</b></span></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hardware-computing-resources" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Hardware: Computing Resources<a href="hardware-computing-resources.html#hardware-computing-resources" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In order to better understand how we can use the available computing resources most efficiently in an analytics task, we first need to get an idea of what we mean by capacity and <em>big</em> regarding the most important hardware components. We then look at each of these components (and additional specialized components) through the lens of Big Data. That is, for each component, we look at how it can become a crucial bottleneck when processing large amounts of data and what we can do about it in R. First we focus on mass storage and memory, then on the CPU, and finally on new alternatives to the CPU.</p>
<div id="mass-storage" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Mass storage<a href="hardware-computing-resources.html#mass-storage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In a simple computing environment, the mass storage device (hard disk) is where the data to be analyzed is stored. So, in what units do we measure the size of datasets and consequently the mass storage capacity of a computer? The smallest unit of information in computing/digital data is called a <em>bit</em> (from <em>bi</em>nary dig<em>it</em>; abbrev. ‘b’) and can take one of two (symbolic) values, either a <code>0</code> or a <code>1</code> (“off” or “on”). Consider, for example, the decimal number <code>139</code>. Written in the binary system, <code>139</code> corresponds to the binary number <code>10001011</code>. In order to store this number on a hard disk, we require a capacity of 8 bits, or one <em>byte</em> (1 byte = 8 bits; abbrev. ‘B’). Historically, one byte encoded a single character of text (e.g., in the ASCII character encoding system). When thinking of a given dataset in its raw/binary representation, we can simply think of it as a row of <code>0</code>s and <code>1</code>s.</p>
<p>Bigger units for storage capacity usually build on bytes, for example:</p>
<ul>
<li><span class="math inline">\(1 \text{ kilobyte (KB)} = 1000^{1} \approx 2^{10} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ megabyte (MB)} = 1000^{2} \approx 2^{20} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ gigabyte (GB)} = 1000^{3} \approx 2^{30} \text{ bytes}\)</span></li>
</ul>
<p>Currently, a common laptop or desktop computer has several hundred GBs of mass storage capacity. The problems related to a lack of mass storage capacity in Big Data analytics are likely the easiest to understand. Suppose you collect large amounts of data from an online source such as the Twitter. At some point, R will throw an error and stop the data collection procedure as the operating system will not allow R to use up more disk space. The simplest solution to this problem is to clean up your hard disk: empty the trash, archive files in the cloud or onto an external drive and delete them on the main disk, etc. In addition, there are some easy-to-learn tricks to use from within R to save some disk space.</p>
<div id="avoiding-redundancies" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Avoiding redundancies<a href="hardware-computing-resources.html#avoiding-redundancies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Different formats for structuring data stored on disk use up more or less space. A simple example is the comparison of JSON (JavaScript Object Notation) and CSV (Comma Separated Values), both data structures that are widely used to store data for analytics purposes. JSON is much more flexible in that it allows the definition of arbitrarily complex hierarchical data structures (and even allows for hints at data types). However, this flexibility comes with some overhead in the usage of special characters to define the structure. Consider the following JSON excerpt of an economic time series fetched from the Federal Reserve’s <a href="https://fred.stlouisfed.org/docs/api/fred/series_observations.html#example_json">FRED API</a>.</p>
<pre><code>{
    &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
    &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
    &quot;observation_start&quot;: &quot;1776-07-04&quot;,
    &quot;observation_end&quot;: &quot;9999-12-31&quot;,
    &quot;units&quot;: &quot;lin&quot;,
    &quot;output_type&quot;: 1,
    &quot;file_type&quot;: &quot;json&quot;,
    &quot;order_by&quot;: &quot;observation_date&quot;,
    &quot;sort_order&quot;: &quot;asc&quot;,
    &quot;count&quot;: 84,
    &quot;offset&quot;: 0,
    &quot;limit&quot;: 100000,
    &quot;observations&quot;: [
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;1929-01-01&quot;,
            &quot;value&quot;: &quot;1065.9&quot;
        },
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;1930-01-01&quot;,
            &quot;value&quot;: &quot;975.5&quot;
        },
        ...,
        {
            &quot;realtime_start&quot;: &quot;2013-08-14&quot;,
            &quot;realtime_end&quot;: &quot;2013-08-14&quot;,
            &quot;date&quot;: &quot;2012-01-01&quot;,
            &quot;value&quot;: &quot;15693.1&quot;
        }
    ]
}</code></pre>
<p>The JSON format is very practical here in separating metadata (such as what time frame is covered by this dataset, etc.) in the first few lines on top from the actual data in <code>"observations"</code> further down. However, note that due to this structure, the key names like <code>"date"</code>, and <code>"value"</code> occur for each observation in that time series. In addition, <code>"realtime_start"</code> and <code>"realtime_end"</code> occur both in the metadata section and again in each observation. Each of those occurrences costs some bytes of storage space on your hard disk but does not add any information once you have parsed and imported the time series into R. The same information could also be stored in a more efficient way on your hard disk by simply storing the metadata in a separate text file and the actual observations in a CSV file (in a table-like structure):</p>
<pre><code>&quot;date&quot;,&quot;value&quot;
&quot;1929-01-01&quot;, &quot;1065.9&quot;
&quot;1930-01-01&quot;, &quot;975.5&quot;

...,

&quot;2012-01-01&quot;, 15693.1&quot;</code></pre>
<p>In fact, in this particular example, storing the data in JSON format would take up more than double the hard-disk space as CSV. Of course, this is not to say that one should generally store data in CSV files. In many situations, you might really have to rely on JSON’s flexibility to represent more complex structures. However, in practice it is very much worthwhile to think about whether you can improve storage efficiency by simply storing raw data in a different format.</p>
<p>Another related point to storing data in CSV files is to remove redundancies by splitting the data into several tables/CSV files, whereby each table contains the variables exclusively describing the type of observation in it. For example, when analyzing customer data for marketing purposes, the dataset stored in one CSV file might be at the level of individual purchases. That is, each row contains information on what has been purchased on which day by which customer as well as additional variables describing the customer (such as customer ID, name, address, etc.). Instead of keeping all of this data in one file, we could split it into two files, where one only contains the order IDs and corresponding customer IDs as well as attributes of individual orders (but not additional attributes of the customers themselves), and the other contains the customer IDs and all customer attributes. Thereby, we avoid redundancies in the form of repeatedly storing the same values of customer attributes (like name and address) for each order.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></p>
</div>
<div id="data-compression" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Data compression<a href="hardware-computing-resources.html#data-compression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>Data compression essentially follows from the same basic idea of avoiding redundancies in data storage as the simple approaches discussed above. However, it happens on a much more fundamental level. Data compression algorithms encode the information contained in the original representation of the data with fewer bits. In the case of lossless compression, this results in a new data file containing the exact same information but taking up less space on disk. In simple terms, compression replaces repeatedly occurring sequences with shorter expressions and keeps track of replacements in a table. Based on the table, the file can then be de-compressed to recreate the original representation of the data. For example, consider the following character string.</p>
<pre><code>&quot;xxxxxyyyyyzzzz&quot;</code></pre>
<p>The same data could be represented with fewer bits as:</p>
<pre><code>&quot;5x6y4z&quot;</code></pre>
<p>which needs fewer than half the number of bits to be stored (but contains the same information).</p>
<p>There are several easy ways to use your mass storage capacity more efficiently with data compression in R. Most conveniently, some functions to import/export data in R directly allow for reading and writing of compressed formats. For example, the <code>fread()</code>/<code>fwrite()</code> functions provided in the <code>data.table</code> package will automatically use the GZIP (de-)compression utility when writing to (reading from) a CSV file with a <code>.gz</code> file extension in the file name.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="hardware-computing-resources.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb123-2"><a href="hardware-computing-resources.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb123-3"><a href="hardware-computing-resources.html#cb123-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-4"><a href="hardware-computing-resources.html#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load example data from basic R installation</span></span>
<span id="cb123-5"><a href="hardware-computing-resources.html#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;LifeCycleSavings&quot;</span>)</span>
<span id="cb123-6"><a href="hardware-computing-resources.html#cb123-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-7"><a href="hardware-computing-resources.html#cb123-7" aria-hidden="true" tabindex="-1"></a><span class="co"># write data to normal csv file and check size</span></span>
<span id="cb123-8"><a href="hardware-computing-resources.html#cb123-8" aria-hidden="true" tabindex="-1"></a><span class="fu">fwrite</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb123-9"><a href="hardware-computing-resources.html#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1441</code></pre>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="hardware-computing-resources.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># write data to a GZIPped (compressed) csv file and check size</span></span>
<span id="cb125-2"><a href="hardware-computing-resources.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fwrite</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv.gz&quot;</span>)</span>
<span id="cb125-3"><a href="hardware-computing-resources.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv.gz&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 744</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="hardware-computing-resources.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read/import the compressed data</span></span>
<span id="cb127-2"><a href="hardware-computing-resources.html#cb127-2" aria-hidden="true" tabindex="-1"></a>lcs <span class="ot">&lt;-</span> data.table<span class="sc">::</span><span class="fu">fread</span>(<span class="st">&quot;lcs.csv.gz&quot;</span>)</span></code></pre></div>
<p>Alternatively, you can also use other types of data compression as follows.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="hardware-computing-resources.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># common ZIP compression (independent of data.table package)</span></span>
<span id="cb128-2"><a href="hardware-computing-resources.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(LifeCycleSavings, <span class="at">file=</span><span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb128-3"><a href="hardware-computing-resources.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1984</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="hardware-computing-resources.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">zip</span>(<span class="at">zipfile =</span> <span class="st">&quot;lcs.csv.zip&quot;</span>, <span class="at">files =</span>  <span class="st">&quot;lcs.csv&quot;</span>)</span>
<span id="cb130-2"><a href="hardware-computing-resources.html#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="fu">file.size</span>(<span class="st">&quot;lcs.csv.zip&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1205</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="hardware-computing-resources.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># unzip/decompress and read/import data</span></span>
<span id="cb132-2"><a href="hardware-computing-resources.html#cb132-2" aria-hidden="true" tabindex="-1"></a>lcs_path <span class="ot">&lt;-</span> <span class="fu">unzip</span>(<span class="st">&quot;lcs.csv.zip&quot;</span>)</span>
<span id="cb132-3"><a href="hardware-computing-resources.html#cb132-3" aria-hidden="true" tabindex="-1"></a>lcs <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(lcs_path)</span></code></pre></div>
<p>Note that data compression is subject to a time–memory trade-off. Compression and de-compression are computationally intensive and need time. When using compression to make more efficient use of the available mass storage capacity, think about how frequently you expect the data to be loaded into R as part of the data analysis tasks ahead and for how long you will need to keep the data stored on your hard disk. Importing GBs of compressed data can be uncomfortably slower than importing from an uncompressed file.</p>
<p>So far, we have only focused on data size in the context of mass storage capacity. But what happens once you load a large dataset into R (e.g., by means of <code>read.csv()</code>)? A program called a “parser” is executed that reads the raw data from the hard disk and creates a representation of that data in the R environment, that is, in random access memory (RAM). All common computers have more GBs of mass storage available than GBs of RAM. Hence, new issues of hardware capacity loom at the stage of data import, which brings us to the next subsection.</p>
</div>
</div>
<div id="random-access-memory-ram" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Random access memory (RAM)<a href="hardware-computing-resources.html#random-access-memory-ram" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>Currently, a common laptop or desktop computer has 8–32 GB of RAM capacity. These are more-or-less the numbers you should keep in the back of your mind for the examples/discussions that follow. That is, we will consider a dataset as “big” if it takes up several GBs in RAM (and therefore might overwhelm a machine with 8GB RAM capacity).</p>
<p>There are several types of problems that you might run into in practice when attempting to import and analyze a dataset of the size close to or larger than your computer’s RAM capacity. Importing the data might take much longer than expected, your computer might freeze during import (or later during the analysis), R/Rstudio might crash, or you might get an error message hinting at a lack of RAM. How can you anticipate such problems, and what can you do about them?</p>
<p>Many of the techniques and packages discussed in the following chapters are in one way or another solutions to these kinds of problems. However, there are a few relatively simple things to keep in mind before we go into the details.</p>
<ol style="list-style-type: decimal">
<li><p>The same data stored on the mass storage device (e.g., in a CSV file) might take up more or less space in RAM. This is due to the fact that the data is (technically speaking) structured differently in a CSV or JSON file than in, for example, a data table or a matrix in R. For example, it is reasonable to anticipate that the example JSON file with the economic time series data will take up less space as a time series object in R (in RAM) than it does on the hard disk (for one thing simply due to the fact that we will not keep the redundancies mentioned before).</p></li>
<li><p>The import might work well, but some parts of the data analysis script might require much more memory to run through even without loading additional data from disk. A classic example of this is regression analysis performed with, for example, <code>lm()</code> in R. As part of the OLS estimation procedure, <code>lm</code> will need to create the model matrix (usually denoted <span class="math inline">\(X\)</span>). Depending on the model you want to estimate, the model matrix might actually be larger than the data frame containing the dataset. In fact, this can happen quite easily if you specify a fixed effects model in which you want to account for the fixed effects via dummy variables (for example, for each country except for one).<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> Again, the result can be one of several: an error message hinting at a lack of memory, a crash, or the computer slowing down significantly. Anticipating these types of problems is very tricky since memory problems are often caused at a lower level of a function from the package that provides you with the data analytics routine you intend to use. Accordingly, error messages can be rather cryptic.</p></li>
<li><p>Keep in mind that you have some leeway in how much space imported data takes up in R by considering data structures and data types. For example, you can use factors instead of character vectors when importing categorical variables into R (the default in <code>read.csv</code>), and for some operations it makes sense to work with matrices instead of data frames.</p></li>
</ol>
<p>Finally, recall the lessons regarding memory usage from the section “Writing efficient R code” in Chapter 1.</p>
</div>
<div id="combining-ram-and-hard-disk-virtual-memory" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Combining RAM and hard disk: Virtual memory<a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>What if all the RAM in our computer is not enough to store all the data we want to analyze?</p>
<p>Modern operating systems (OSs) have a way of dealing with such a situation. Once all RAM is used up by the currently running programs, the OS allocates parts of the memory back to the hard disk, which then works as <em>virtual memory</em>. Figure 4.2 illustrates this point.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:vm"></span>
<img src="img/virtual_memory.png" alt="Virtual memory. Overall memory is mapped to RAM and parts of the hard disk." width="60%" />
<p class="caption">
Figure 5.1: Virtual memory. Overall memory is mapped to RAM and parts of the hard disk.
</p>
</div>

<p>For example, when we implement an R-script that imports one file after another into the R environment, ignoring the RAM capacity of our computer, the OS will start <em>paging</em> data to the virtual memory. This happens ‘under the hood’ without explicit instructions by the user. We will quite likely notice that the computer slows down a lot when this happens.</p>
<p>While this default usage of virtual memory by the OS is helpful for running several applications at the same time, each taking up a moderate amount of memory, it is not a really useful tool for processing large amounts of data in one application (R). However, the underlying idea of using both RAM and mass storage simultaneously in order to cope with a lack of memory is very useful in the context of Big Data Analytics.</p>
<p>Several R packages have been developed that exploit the idea behind virtual memory explicitly for analyzing large amounts of data. The basic idea behind these packages is to map a dataset to the hard disk when loading it into R. The actual data values are stored in chunks on the hard disk, while the structure/metadata of the dataset is loaded into R.</p>
</div>
<div id="cpu-and-parallelization" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> CPU and parallelization<a href="hardware-computing-resources.html#cpu-and-parallelization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
</p>
<p>The actual processing of the data is done in the computer’s central processing unit (CPU). Consequently, the performance of the CPU has a substantial effect on how fast a data analytics task runs. A CPU’s performance is usually denoted by its <em>clock rate</em> measured in gigaherz (GHz). In simple terms, a CPU with a clock rate of 4.8 GHz can execute 4.8 billion basic operations per second. Holding all other aspects constant, you can thus expect an analytics task to run faster if it runs on a computer with higher CPU clock rate. As an alternative to scaling up the CPU, we can exploit the fact that modern CPUs have several <em>cores</em>. In the normal usage of a PC, the operating system makes use of these cores to run several applications smoothly <em>in parallel</em> (e.g., you listen to music on Spotify while browsing the web and running some analytics script in RStudio in the background).</p>
<p>Modern computing environments such as R allow us to explicitly run parts of the same analytics task in parallel, that is, on several CPU cores at the same time. Following the same logic, we can also connect several computers (each with several CPU cores) in a cluster computer and run the program in parallel on all of these computing nodes. Both of these approaches are generally referred to as <em>parallelization</em>, and both are supported in several R packages.</p>
<p>An R program run in parallel typically involves the following steps.</p>
<ul>
<li>First, several instances of R are running at the same time (across one machine with multiple CPU cores or across a cluster computer). One of the instances (i.e., the <em>master</em> instance) breaks the computation into batches and sends those to the other instances.</li>
<li>Second, each of the instances processes its batch and sends the results back to the master instance.</li>
<li>Finally, the master instance combines the partial results into the final result and returns it to the user.</li>
</ul>
<p>To illustrate this point, consider the following econometric problem: you have a customer <a href="https://www.kaggle.com/jackdaoud/marketing-data?select=marketing_data.csv">dataset</a> with detailed data on customer characteristics, past customer behavior, and information on online marketing campaigns. Your task is to figure out which customers are more likely to react positively to the most recent online marketing campaign. The aim is to optimize personalized marketing campaigns in the future based on insights gained from this exercise. In a first step you take a computationally intensive “brute force” approach: you run all possible regressions with the dependent variable <code>Response</code> (equal to 1 if the customer took the offer in the campaign and 0 otherwise). In total you have 21 independent variables; thus you need to run <span class="math inline">\(2^{20}=1,048,576\)</span> logit regressions (this is without considering linear combinations of covariates etc.). Finally, you want to select the model with the best fit according to deviance.</p>
<p>A simple sequential implementation to solve this problem could look like this (for the sake of time, we cap the number of regression models to N=10).</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="hardware-computing-resources.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># you can download the dataset from </span></span>
<span id="cb133-2"><a href="hardware-computing-resources.html#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.kaggle.com/jackdaoud/marketing-data?</span></span>
<span id="cb133-3"><a href="hardware-computing-resources.html#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="co"># select=marketing_data.csv</span></span>
<span id="cb133-4"><a href="hardware-computing-resources.html#cb133-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-5"><a href="hardware-computing-resources.html#cb133-5" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARATION -----------------------------</span></span>
<span id="cb133-6"><a href="hardware-computing-resources.html#cb133-6" aria-hidden="true" tabindex="-1"></a><span class="co"># packages</span></span>
<span id="cb133-7"><a href="hardware-computing-resources.html#cb133-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb133-8"><a href="hardware-computing-resources.html#cb133-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-9"><a href="hardware-computing-resources.html#cb133-9" aria-hidden="true" tabindex="-1"></a><span class="co"># import data</span></span>
<span id="cb133-10"><a href="hardware-computing-resources.html#cb133-10" aria-hidden="true" tabindex="-1"></a>marketing <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/marketing_data.csv&quot;</span>)</span>
<span id="cb133-11"><a href="hardware-computing-resources.html#cb133-11" aria-hidden="true" tabindex="-1"></a><span class="co"># clean/prepare data</span></span>
<span id="cb133-12"><a href="hardware-computing-resources.html#cb133-12" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Income <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">gsub</span>(<span class="st">&quot;[[:punct:]]&quot;</span>,</span>
<span id="cb133-13"><a href="hardware-computing-resources.html#cb133-13" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">&quot;&quot;</span>,</span>
<span id="cb133-14"><a href="hardware-computing-resources.html#cb133-14" aria-hidden="true" tabindex="-1"></a>                                    marketing<span class="sc">$</span>Income)) </span>
<span id="cb133-15"><a href="hardware-computing-resources.html#cb133-15" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>days_customer <span class="ot">&lt;-</span> </span>
<span id="cb133-16"><a href="hardware-computing-resources.html#cb133-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">as.Date</span>(<span class="fu">Sys.Date</span>())<span class="sc">-</span> </span>
<span id="cb133-17"><a href="hardware-computing-resources.html#cb133-17" aria-hidden="true" tabindex="-1"></a>     <span class="fu">as.Date</span>(marketing<span class="sc">$</span>Dt_Customer, <span class="st">&quot;%m/%d/%y&quot;</span>)</span>
<span id="cb133-18"><a href="hardware-computing-resources.html#cb133-18" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Dt_Customer <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb133-19"><a href="hardware-computing-resources.html#cb133-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-20"><a href="hardware-computing-resources.html#cb133-20" aria-hidden="true" tabindex="-1"></a><span class="co"># all sets of independent vars</span></span>
<span id="cb133-21"><a href="hardware-computing-resources.html#cb133-21" aria-hidden="true" tabindex="-1"></a>indep <span class="ot">&lt;-</span> <span class="fu">names</span>(marketing)[ <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">19</span>, <span class="dv">27</span>,<span class="dv">28</span>)]</span>
<span id="cb133-22"><a href="hardware-computing-resources.html#cb133-22" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(indep),</span>
<span id="cb133-23"><a href="hardware-computing-resources.html#cb133-23" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">function</span>(x) <span class="fu">combn</span>(indep, x,</span>
<span id="cb133-24"><a href="hardware-computing-resources.html#cb133-24" aria-hidden="true" tabindex="-1"></a>                                              <span class="at">simplify =</span> <span class="cn">FALSE</span>))</span>
<span id="cb133-25"><a href="hardware-computing-resources.html#cb133-25" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">unlist</span>(combinations_list, </span>
<span id="cb133-26"><a href="hardware-computing-resources.html#cb133-26" aria-hidden="true" tabindex="-1"></a>                            <span class="at">recursive =</span> <span class="cn">FALSE</span>)</span>
<span id="cb133-27"><a href="hardware-computing-resources.html#cb133-27" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">lapply</span>(combinations_list,</span>
<span id="cb133-28"><a href="hardware-computing-resources.html#cb133-28" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;Response ~&quot;</span>, </span>
<span id="cb133-29"><a href="hardware-computing-resources.html#cb133-29" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">paste</span>(x, <span class="at">collapse=</span><span class="st">&quot;+&quot;</span>)))</span>
<span id="cb133-30"><a href="hardware-computing-resources.html#cb133-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-31"><a href="hardware-computing-resources.html#cb133-31" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS --------------------------</span></span>
<span id="cb133-32"><a href="hardware-computing-resources.html#cb133-32" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co">#  N &lt;- length(models) for all</span></span>
<span id="cb133-33"><a href="hardware-computing-resources.html#cb133-33" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb133-34"><a href="hardware-computing-resources.html#cb133-34" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(pseudo_Rsq) <span class="ot">&lt;-</span> N</span>
<span id="cb133-35"><a href="hardware-computing-resources.html#cb133-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb133-36"><a href="hardware-computing-resources.html#cb133-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb133-37"><a href="hardware-computing-resources.html#cb133-37" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]],</span>
<span id="cb133-38"><a href="hardware-computing-resources.html#cb133-38" aria-hidden="true" tabindex="-1"></a>             <span class="at">data=</span>marketing,</span>
<span id="cb133-39"><a href="hardware-computing-resources.html#cb133-39" aria-hidden="true" tabindex="-1"></a>             <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb133-40"><a href="hardware-computing-resources.html#cb133-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute the proportion of deviance explained by </span></span>
<span id="cb133-41"><a href="hardware-computing-resources.html#cb133-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the independent vars (~R^2)</span></span>
<span id="cb133-42"><a href="hardware-computing-resources.html#cb133-42" aria-hidden="true" tabindex="-1"></a>  pseudo_Rsq[[i]] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance)</span>
<span id="cb133-43"><a href="hardware-computing-resources.html#cb133-43" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb133-44"><a href="hardware-computing-resources.html#cb133-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-45"><a href="hardware-computing-resources.html#cb133-45" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb133-46"><a href="hardware-computing-resources.html#cb133-46" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ MntWines&quot;</code></pre>
<p>Alternatively, a sequential implementation could be based on an apply-type function like <code>lapply()</code>. As several of the approaches to parallelize computation with R build either on loops or an apply-type syntax, let us also briefly introduce the sequential lapply-implementation of the task above as a point of reference.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="hardware-computing-resources.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS --------------------------</span></span>
<span id="cb135-2"><a href="hardware-computing-resources.html#cb135-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co">#  N &lt;- length(models) for all</span></span>
<span id="cb135-3"><a href="hardware-computing-resources.html#cb135-3" aria-hidden="true" tabindex="-1"></a>run_reg <span class="ot">&lt;-</span> </span>
<span id="cb135-4"><a href="hardware-computing-resources.html#cb135-4" aria-hidden="true" tabindex="-1"></a>     <span class="cf">function</span>(model, data, family){</span>
<span id="cb135-5"><a href="hardware-computing-resources.html#cb135-5" aria-hidden="true" tabindex="-1"></a>          <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb135-6"><a href="hardware-computing-resources.html#cb135-6" aria-hidden="true" tabindex="-1"></a>          fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(model, <span class="at">data=</span>data, <span class="at">family =</span> family)</span>
<span id="cb135-7"><a href="hardware-computing-resources.html#cb135-7" aria-hidden="true" tabindex="-1"></a>          <span class="co"># compute and return the proportion of deviance explained by </span></span>
<span id="cb135-8"><a href="hardware-computing-resources.html#cb135-8" aria-hidden="true" tabindex="-1"></a>          <span class="co"># the independent vars (~R^2)</span></span>
<span id="cb135-9"><a href="hardware-computing-resources.html#cb135-9" aria-hidden="true" tabindex="-1"></a>          <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb135-10"><a href="hardware-computing-resources.html#cb135-10" aria-hidden="true" tabindex="-1"></a>     }</span>
<span id="cb135-11"><a href="hardware-computing-resources.html#cb135-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-12"><a href="hardware-computing-resources.html#cb135-12" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq_list <span class="ot">&lt;-</span><span class="fu">lapply</span>(models[<span class="dv">1</span><span class="sc">:</span>N], run_reg, <span class="at">data=</span>marketing, <span class="at">family=</span><span class="fu">binomial</span>() )</span>
<span id="cb135-13"><a href="hardware-computing-resources.html#cb135-13" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">unlist</span>(pseudo_Rsq_list)</span>
<span id="cb135-14"><a href="hardware-computing-resources.html#cb135-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-15"><a href="hardware-computing-resources.html#cb135-15" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb135-16"><a href="hardware-computing-resources.html#cb135-16" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ MntWines&quot;</code></pre>
<div id="naive-multi-session-approach" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Naive multi-session approach<a href="hardware-computing-resources.html#naive-multi-session-approach" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>There is actually a simple way of doing this “manually” on a multi-core PC, which intuitively illustrates the point of parallelization (although it would not be a very practical approach): you write an R script that loads the dataset, runs the first <span class="math inline">\(n\)</span> of the total of <span class="math inline">\(N\)</span> regressions, and stores the result in a local text file. Next, you run the script in your current RStudio session, open an additional RStudio session, and run the script with the next <span class="math inline">\(n\)</span> regressions, and so on until all cores are occupied with one RStudio session. At the end you collect all of the results from the separate text files and combine them to get the final result. Depending on the problem at hand, this could indeed speed up the overall task, and it is technically speaking a form of “multi-session” approach. However, as you have surely noticed, this is unlikely to be a very practical approach.</p>
</div>
<div id="multi-session-approach-with-futures" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Multi-session approach with futures<a href="hardware-computing-resources.html#multi-session-approach-with-futures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>There is a straightforward way to implement the very basic (naive) idea of running parts of the task in separate R sessions. The <code>future</code> package (see <span class="citation">Bengtsson (<a href="#ref-bengtsson_2021" role="doc-biblioref">2021</a>)</span> for details) provides a lightweight interface (API) to use futures<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>. An additional set of packages (such as <code>future.apply</code>) that build on the <code>future</code> package, provides high-level functionality to run your code in parallel without having to change your (sequential, usual) R code much. In order to demonstrate the simplicity of this approach, let us re-write the sequential implementation through <code>lapply()</code> from above for parallelization through the <code>future</code> package. All we need to do is to load the <code>future</code> and <code>future.apply</code> packages <span class="citation">(<a href="#ref-bengtsson_2021" role="doc-biblioref">Bengtsson 2021</a>)</span> and then simply replace <code>lapply(...)</code> with <code>future_lapply(...)</code>.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="hardware-computing-resources.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP ------------------</span></span>
<span id="cb137-2"><a href="hardware-computing-resources.html#cb137-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-3"><a href="hardware-computing-resources.html#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb137-4"><a href="hardware-computing-resources.html#cb137-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(future)</span>
<span id="cb137-5"><a href="hardware-computing-resources.html#cb137-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(future.apply)</span>
<span id="cb137-6"><a href="hardware-computing-resources.html#cb137-6" aria-hidden="true" tabindex="-1"></a><span class="co"># instruct the package to resolve</span></span>
<span id="cb137-7"><a href="hardware-computing-resources.html#cb137-7" aria-hidden="true" tabindex="-1"></a><span class="co"># futures in parallel (via a SOCK cluster)</span></span>
<span id="cb137-8"><a href="hardware-computing-resources.html#cb137-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plan</span>(multisession)</span>
<span id="cb137-9"><a href="hardware-computing-resources.html#cb137-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-10"><a href="hardware-computing-resources.html#cb137-10" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS --------------------------</span></span>
<span id="cb137-11"><a href="hardware-computing-resources.html#cb137-11" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co">#  N &lt;- length(models) for all</span></span>
<span id="cb137-12"><a href="hardware-computing-resources.html#cb137-12" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq_list <span class="ot">&lt;-</span> <span class="fu">future_lapply</span>(models[<span class="dv">1</span><span class="sc">:</span>N],</span>
<span id="cb137-13"><a href="hardware-computing-resources.html#cb137-13" aria-hidden="true" tabindex="-1"></a>                                 run_reg,</span>
<span id="cb137-14"><a href="hardware-computing-resources.html#cb137-14" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">data=</span>marketing,</span>
<span id="cb137-15"><a href="hardware-computing-resources.html#cb137-15" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">family=</span><span class="fu">binomial</span>() )</span>
<span id="cb137-16"><a href="hardware-computing-resources.html#cb137-16" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">unlist</span>(pseudo_Rsq_list)</span>
<span id="cb137-17"><a href="hardware-computing-resources.html#cb137-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb137-18"><a href="hardware-computing-resources.html#cb137-18" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb137-19"><a href="hardware-computing-resources.html#cb137-19" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ MntWines&quot;</code></pre>
</div>
<div id="multi-core-and-multi-node-approach" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Multi-core and multi-node approach<a href="hardware-computing-resources.html#multi-core-and-multi-node-approach" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>There are several additional approaches to parallelization in R. With the help of some specialized packages, we can instruct R to automatically distribute the workload to different cores (or different computing nodes in a cluster computer), control and monitor the progress in all cores, and then automatically collect and combine the results from all cores. The <code>future</code>-package and the packages building on it provide in themselves different approaches to writing such scripts.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> Below, we look at two additional ways of implementing parallelization with R that are based on other underlying frameworks than <code>future</code>.</p>
<div id="parallel-for-loops-using-socket" class="section level4 hasAnchor" number="5.4.3.1">
<h4><span class="header-section-number">5.4.3.1</span> Parallel for-loops using socket<a href="hardware-computing-resources.html#parallel-for-loops-using-socket" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>
Probably the most intuitive approach to parallelizing a task in R is the <code>foreach</code> package <span class="citation">(<a href="#ref-foreach" role="doc-biblioref">Microsoft and Weston 2022</a>)</span>. It allows you to write a <code>foreach</code> statement that is very similar to the for-loop syntax in R. Hence, you can straightforwardly “translate” an already implemented sequential approach with a common for-loop to a parallel implementation.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="hardware-computing-resources.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) --------------------------</span></span>
<span id="cb139-2"><a href="hardware-computing-resources.html#cb139-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-3"><a href="hardware-computing-resources.html#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="co"># packages for parallel processing</span></span>
<span id="cb139-4"><a href="hardware-computing-resources.html#cb139-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb139-5"><a href="hardware-computing-resources.html#cb139-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doSNOW)</span>
<span id="cb139-6"><a href="hardware-computing-resources.html#cb139-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-7"><a href="hardware-computing-resources.html#cb139-7" aria-hidden="true" tabindex="-1"></a><span class="co"># get the number of cores available</span></span>
<span id="cb139-8"><a href="hardware-computing-resources.html#cb139-8" aria-hidden="true" tabindex="-1"></a>ncores <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb139-9"><a href="hardware-computing-resources.html#cb139-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set cores for parallel processing</span></span>
<span id="cb139-10"><a href="hardware-computing-resources.html#cb139-10" aria-hidden="true" tabindex="-1"></a>ctemp <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(ncores)</span>
<span id="cb139-11"><a href="hardware-computing-resources.html#cb139-11" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoSNOW</span>(ctemp)</span>
<span id="cb139-12"><a href="hardware-computing-resources.html#cb139-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-13"><a href="hardware-computing-resources.html#cb139-13" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare loop</span></span>
<span id="cb139-14"><a href="hardware-computing-resources.html#cb139-14" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co">#  N &lt;- length(models) for all</span></span>
<span id="cb139-15"><a href="hardware-computing-resources.html#cb139-15" aria-hidden="true" tabindex="-1"></a><span class="co"># run loop in parallel</span></span>
<span id="cb139-16"><a href="hardware-computing-resources.html#cb139-16" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span></span>
<span id="cb139-17"><a href="hardware-computing-resources.html#cb139-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">foreach</span> ( <span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span>N, <span class="at">.combine =</span> c) <span class="sc">%dopar%</span> {</span>
<span id="cb139-18"><a href="hardware-computing-resources.html#cb139-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb139-19"><a href="hardware-computing-resources.html#cb139-19" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], </span>
<span id="cb139-20"><a href="hardware-computing-resources.html#cb139-20" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>marketing,</span>
<span id="cb139-21"><a href="hardware-computing-resources.html#cb139-21" aria-hidden="true" tabindex="-1"></a>               <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb139-22"><a href="hardware-computing-resources.html#cb139-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the proportion of deviance explained by </span></span>
<span id="cb139-23"><a href="hardware-computing-resources.html#cb139-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the independent vars (~R^2)</span></span>
<span id="cb139-24"><a href="hardware-computing-resources.html#cb139-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb139-25"><a href="hardware-computing-resources.html#cb139-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb139-26"><a href="hardware-computing-resources.html#cb139-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-27"><a href="hardware-computing-resources.html#cb139-27" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb139-28"><a href="hardware-computing-resources.html#cb139-28" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
<p>With relatively few cases, this approach is not very fast due to the overhead of “distributing” variables/objects from the master process to all cores/workers. In simple terms, the socket approach means that the cores do not share the same variables/the same environment, which creates overhead. However, this approach is usually very stable and runs on all platforms.</p>
</div>
<div id="parallel-lapply-using-forking" class="section level4 hasAnchor" number="5.4.3.2">
<h4><span class="header-section-number">5.4.3.2</span> Parallel lapply using forking<a href="hardware-computing-resources.html#parallel-lapply-using-forking" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p></p>
<p>Finally, let us look at an implementation based on forking (here, implemented in the <code>parallel</code> package by <span class="citation">(<a href="#ref-rfoundation2021" role="doc-biblioref">R Core Team 2021</a>)</span>. In the fork approach, each core works with the same objects/variables in a shared environment, which makes this approach very fast. However, depending on what exactly is being computed, sharing an environment can cause problems.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> If you are not sure whether your setup might run into issues with forking, it would be better to rely on a non-fork approach.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="hardware-computing-resources.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) ---------------</span></span>
<span id="cb141-2"><a href="hardware-computing-resources.html#cb141-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-3"><a href="hardware-computing-resources.html#cb141-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-4"><a href="hardware-computing-resources.html#cb141-4" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare parallel lapply (based on forking, </span></span>
<span id="cb141-5"><a href="hardware-computing-resources.html#cb141-5" aria-hidden="true" tabindex="-1"></a><span class="co"># here clearly faster than foreach)</span></span>
<span id="cb141-6"><a href="hardware-computing-resources.html#cb141-6" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co">#  N &lt;- length(models) for all</span></span>
<span id="cb141-7"><a href="hardware-computing-resources.html#cb141-7" aria-hidden="true" tabindex="-1"></a><span class="co"># run parallel lapply</span></span>
<span id="cb141-8"><a href="hardware-computing-resources.html#cb141-8" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">mclapply</span>(<span class="dv">1</span><span class="sc">:</span>N,</span>
<span id="cb141-9"><a href="hardware-computing-resources.html#cb141-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mc.cores =</span> ncores,</span>
<span id="cb141-10"><a href="hardware-computing-resources.html#cb141-10" aria-hidden="true" tabindex="-1"></a>                       <span class="at">FUN =</span> <span class="cf">function</span>(i){</span>
<span id="cb141-11"><a href="hardware-computing-resources.html#cb141-11" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># fit the logit model </span></span>
<span id="cb141-12"><a href="hardware-computing-resources.html#cb141-12" aria-hidden="true" tabindex="-1"></a>                         fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]],</span>
<span id="cb141-13"><a href="hardware-computing-resources.html#cb141-13" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">data=</span>marketing,</span>
<span id="cb141-14"><a href="hardware-computing-resources.html#cb141-14" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb141-15"><a href="hardware-computing-resources.html#cb141-15" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># compute the proportion of deviance </span></span>
<span id="cb141-16"><a href="hardware-computing-resources.html#cb141-16" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># explained  by the independent vars (~R^2)</span></span>
<span id="cb141-17"><a href="hardware-computing-resources.html#cb141-17" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb141-18"><a href="hardware-computing-resources.html#cb141-18" aria-hidden="true" tabindex="-1"></a>                         })</span>
<span id="cb141-19"><a href="hardware-computing-resources.html#cb141-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-20"><a href="hardware-computing-resources.html#cb141-20" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER, SHOW FINAL OUTPUT ---------------</span></span>
<span id="cb141-21"><a href="hardware-computing-resources.html#cb141-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-22"><a href="hardware-computing-resources.html#cb141-22" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span>
<span id="cb141-23"><a href="hardware-computing-resources.html#cb141-23" aria-hidden="true" tabindex="-1"></a>best_model</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
</div>
</div>
</div>
<div id="gpus-for-scientific-computing" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> GPUs for scientific computing<a href="hardware-computing-resources.html#gpus-for-scientific-computing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>The success of the computer games industry in the late 1990s/early 2000s led to an interesting positive externality for scientific computing. The ever more demanding graphics of modern computer games and the huge economic success of the computer games industry set incentives for hardware producers to invest in research and development of more powerful ‘graphics cards’, extending a normal PC/computing environment with additional computing power solely dedicated to graphics. At the heart of these graphic cards are so-called GPUs (graphics processing units), microprocessors specifically optimized for graphics processing. Figure <a href="hardware-computing-resources.html#fig:rtx">5.2</a> depicts a modern graphics card similar to those commonly built into today’s ‘gaming’ PCs.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rtx"></span>
<img src="img/rtx_2080.png" alt="Illustration of a Nvidia GEFORCE RTX 2080 graphics card with a modern GPU (illustration by MarcusBurns1977 under CC BY 3.0 license)." width="60%" />
<p class="caption">
Figure 5.2: Illustration of a Nvidia GEFORCE RTX 2080 graphics card with a modern GPU (illustration by MarcusBurns1977 under CC BY 3.0 license).
</p>
</div>

<!-- Illustration of a Nvidia GEFORCE RTX 2080 graphics card with a modern GPU (illustration by MarcusBurns1977 under CC BY 3.0 license). Illustration of a Nvidia GEFORCE RTX 2080 graphics card with a modern graphic processing unit (GPU) (illustration by [MarcusBurns1977](https://www.deviantart.com/marcusburns1977) under [CC BY 3.0 license](https://creativecommons.org/licenses/by/3.0/)). -->
<p>Why did the hardware industry not simply invest in the development of more powerful CPUs to deal with the more demanding PC games? The main reason is that the architecture of CPUs is designed not only for efficiency but also flexibility. That is, a CPU needs to perform well in all kinds of computations, some parallel, some sequential, etc. Computing graphics is a comparatively narrow domain of computation, and designing a processing unit architecture that is custom-made to excel just at this one task is thus much more cost efficient. Interestingly, this graphics-specific architecture (specialized in highly parallel numerical [floating point] workloads) turns out to also be very useful in some core scientific computing tasks – in particular, matrix multiplications (see <span class="citation">Fatahalian, Sugerman, and Hanrahan (<a href="#ref-fatahalian_etal2004" role="doc-biblioref">2004</a>)</span> for a detailed discussion of why that is the case). A key aspect of GPUs is that they are composed of several multiprocessor units, of which each in turn has several cores. GPUs can thus perform computations with hundreds or even thousands of threads in parallel. The figure below illustrates this point by showing the typical architecture of an NVIDIA GPU.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gpuarchitecture"></span>
<img src="img/gpu_details.png" alt="Illustration of a graphics processing unit’s components/architecture. The GPU consists of several Texture Processing Clusters (TPC), which in turn consist of several Streaming Multiprocessors (SM; the primary unit of parallelism in the GPU) that contain ten Streaming Processors (SP; cores, responsible for executing a single thread), shared memory (can be accessed by multiple SPs simultaneously), instruction cache (I-Cache; responsible for storing and managing the instructions needed to execute a program), constant cache (C-Cache; store constant data that is needed during program execution), and a multi-threaded issue component (MT issue; responsible for scheduling and managing the execution of multiple threads simultaneously)." width="99%" />
<p class="caption">
Figure 5.3: Illustration of a graphics processing unit’s components/architecture. The GPU consists of several Texture Processing Clusters (TPC), which in turn consist of several Streaming Multiprocessors (SM; the primary unit of parallelism in the GPU) that contain ten Streaming Processors (SP; cores, responsible for executing a single thread), shared memory (can be accessed by multiple SPs simultaneously), instruction cache (I-Cache; responsible for storing and managing the instructions needed to execute a program), constant cache (C-Cache; store constant data that is needed during program execution), and a multi-threaded issue component (MT issue; responsible for scheduling and managing the execution of multiple threads simultaneously).
</p>
</div>

<p>While initially, programming GPUs for scientific computing required a very good understanding of the hardware, graphics card producers have realized that there is an additional market for their products (in particular with the recent rise of deep learning) and now provide several high-level APIs to use GPUs for tasks other than graphics processing. Over the last few years, more high-level software has been developed that makes it much easier to use GPUs in parallel computing tasks. The following subsections show some examples of such software in the R environment.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a></p>
<div id="gpus-in-r" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> GPUs in R<a href="hardware-computing-resources.html#gpus-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!-- ## Installation -->
<!-- This is for pop OS machines. Install drivers etc. for NVIDIA card -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install OpenCL -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install `gpuR` in R (`install.packages("gpuR")`). -->
<p>The <code>gpuR</code> package <span class="citation">(<a href="#ref-gpuR" role="doc-biblioref">Determan 2019</a>)</span> provides basic R functions to compute with GPUs from within the R environment.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> In the following example we compare the performance of a CPU with a GPU for a matrix multiplication exercise. For a large <span class="math inline">\(N\times P\)</span> matrix <span class="math inline">\(X\)</span>, we want to compute <span class="math inline">\(X^tX\)</span>.</p>
<p>In a first step, we load the <code>gpuR</code> package.<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> Note the output to the console. It shows the type of GPU identified by <code>gpuR</code>. This is the platform on which <code>gpuR</code> will compute the GPU examples. In order to compare the performances, we also load the <code>bench</code> package.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="hardware-computing-resources.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load package</span></span>
<span id="cb143-2"><a href="hardware-computing-resources.html#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bench)</span>
<span id="cb143-3"><a href="hardware-computing-resources.html#cb143-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gpuR)</span></code></pre></div>
<pre><code>## Number of platforms: 1
## - platform: NVIDIA Corporation: OpenCL 3.0 CUDA 12.2.138
##   - context device index: 0
##     - NVIDIA GeForce GTX 1650
## checked all devices
## completed initialization</code></pre>
<p>Note how loading the <code>gpuR</code> package triggers a check of GPU devices and outputs information on the detected GPUs as well as the lower-level software platform to run GPU computations. Next, we initialize a large matrix filled with pseudo-random numbers, representing a dataset with <span class="math inline">\(N\)</span> observations and <span class="math inline">\(P\)</span> variables.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="hardware-computing-resources.html#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize dataset with pseudo-random numbers</span></span>
<span id="cb145-2"><a href="hardware-computing-resources.html#cb145-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span>  <span class="co"># number of observations</span></span>
<span id="cb145-3"><a href="hardware-computing-resources.html#cb145-3" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># number of variables</span></span>
<span id="cb145-4"><a href="hardware-computing-resources.html#cb145-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(N <span class="sc">*</span> P, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N, <span class="at">ncol =</span>P)</span></code></pre></div>
<p>For the GPU examples to work, we need one more preparatory step. GPUs have their own memory, which they can access faster than they can access RAM. However, this GPU memory is typically not very large compared to the memory CPUs have access to. Hence, there is a potential trade-off between losing some efficiency but working with more data or vice versa.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> Here, we transfer the matrix to GPU memory with <code>vclMatrix()</code>.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="hardware-computing-resources.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare GPU-specific objects/settings</span></span>
<span id="cb146-2"><a href="hardware-computing-resources.html#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="co"># transfer matrix to GPU (matrix stored in GPU memory)</span></span>
<span id="cb146-3"><a href="hardware-computing-resources.html#cb146-3" aria-hidden="true" tabindex="-1"></a>vclX <span class="ot">&lt;-</span> <span class="fu">vclMatrix</span>(X, <span class="at">type =</span> <span class="st">&quot;float&quot;</span>)  </span></code></pre></div>
<p>Now we run the two examples, first, based on standard R, using the CPU, and then, computing on the GPU and using GPU memory. In order to make the comparison fair, we force <code>bench::mark()</code> to run at least 200 iterations per variant.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="hardware-computing-resources.html#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compare three approaches</span></span>
<span id="cb147-2"><a href="hardware-computing-resources.html#cb147-2" aria-hidden="true" tabindex="-1"></a>gpu_cpu <span class="ot">&lt;-</span> bench<span class="sc">::</span><span class="fu">mark</span>(</span>
<span id="cb147-3"><a href="hardware-computing-resources.html#cb147-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb147-4"><a href="hardware-computing-resources.html#cb147-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute with CPU </span></span>
<span id="cb147-5"><a href="hardware-computing-resources.html#cb147-5" aria-hidden="true" tabindex="-1"></a>  cpu <span class="ot">&lt;-</span><span class="fu">t</span>(X) <span class="sc">%*%</span> X,</span>
<span id="cb147-6"><a href="hardware-computing-resources.html#cb147-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb147-7"><a href="hardware-computing-resources.html#cb147-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GPU version, in GPU memory </span></span>
<span id="cb147-8"><a href="hardware-computing-resources.html#cb147-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># (vclMatrix formation is a memory transfer)</span></span>
<span id="cb147-9"><a href="hardware-computing-resources.html#cb147-9" aria-hidden="true" tabindex="-1"></a>  gpu <span class="ot">&lt;-</span> <span class="fu">t</span>(vclX) <span class="sc">%*%</span> vclX,</span>
<span id="cb147-10"><a href="hardware-computing-resources.html#cb147-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb147-11"><a href="hardware-computing-resources.html#cb147-11" aria-hidden="true" tabindex="-1"></a><span class="at">check =</span> <span class="cn">FALSE</span>, <span class="at">memory =</span> <span class="cn">FALSE</span>, <span class="at">min_iterations =</span> <span class="dv">200</span>)</span></code></pre></div>
<p>The performance comparison is visualized with boxplots.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="hardware-computing-resources.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gpu_cpu, <span class="at">type =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<p><img src="img/gpu_cpu.png" width="75%" style="display: block; margin: auto;" /></p>
<p>The theoretically expected pattern becomes clearly visible. When using the GPU + GPU memory, the matrix operation is substantially faster than the common CPU computation. However, in this simple example of only one matrix operation, the real strength of GPU computation vs. CPU computation does not really become visible. In Chapter 13, we will look at a computationally much more intensive application of GPUs in the domain of deep learning (which relies heavily on matrix multiplications).</p>
</div>
</div>
<div id="the-road-ahead-hardware-made-for-machine-learning" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> The road ahead: Hardware made for machine learning<a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
Due to the high demand for more computational power in the domain of training complex neural network models (for example, in computer vision), Google has recently developed a new hardware platform specifically designed to work with complex neural networks using TensorFlow: Tensor Processing Units (TPUs). TPUs were designed from the ground up to improve performance in dense vector and matrix computations with the aim of substantially increasing the speed of training deep learning models implemented with TensorFlow <span class="citation">(<a href="#ref-tensorflow2015-whitepaper" role="doc-biblioref">Abadi et al. 2015</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tpu"></span>
<img src="img/TPU.png" alt="Illustration of a tensor processing unit (TPU)." width="40%" />
<p class="caption">
Figure 5.4: Illustration of a tensor processing unit (TPU).
</p>
</div>

<p>While initially only used internally by Google, the Google Cloud platform now offers cloud TPUs to the general public.</p>
</div>
<div id="wrapping-up-1" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Wrapping up<a href="hardware-computing-resources.html#wrapping-up-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Be aware of and avoid redundancies in data storage. Consider, for example, storing data in CSV-files instead of JSON-files (if there is no need to store hierarchical structures).</li>
<li>File compression is a more general strategy to avoid redundancies and save mass storage space. It can help you store even large datasets on disk. However, reading and saving compressed files takes longer, as additional processing is necessary. As a rule of thumb, store the raw datasets (which don’t have to be accessed that often) in a compressed format.</li>
<li>Standard R for data analytics expects the datasets to be imported and available as R objects in the R environment (i.e., in RAM). Hence, the step of importing large datasets to R with the conventional approaches is aimed to parsing and loading the entire dataset into RAM, which might fail if your dataset is larger than the available RAM.</li>
<li>Even if a dataset is not too large to fit into RAM, running data analysis scripts on it might then lead to R reaching RAM limits due to the creation of additional R objects in RAM needed for the computation. For example, when running regressions in the conventional way in R, R will generate, among other objects, an object containing the model matrix. However, at this point your original dataset object will still also reside in RAM. Not uncommonly, R would then crash or slow down substantially.</li>
<li>The reason R might slow down substantially when working with large datasets in RAM is that your computer’s operating system (OS) has a default approach of handling situations with a lack of available RAM: it triggers <em>paging</em> between the RAM and a dedicated part of the hard disk called <em>virtual memory</em>. In simple terms, your computer starts using parts of the hard disk as an extension of RAM. However, reading/writing from/to the hard disk is much slower than from/to RAM, so your entire data analytics script (and any other programs running at the same time) will slow down substantially.</li>
<li>Based on the points above, when working locally with a large dataset, recognize why your computer is slowing down or why R is crashing. Consider whether the dataset could theoretically fit into memory. Clarify whether analyzing the already imported data triggers the OS’s virtual memory mechanism.</li>
<li>Taken together, your program might run slower than expected due to a lack of RAM (and thus the paging) and/or due to a very high computational burden on the CPU – for example, bootstrapping the standard errors of regression coefficients.</li>
<li>By default essentially all basic R functions use one CPU thread/core for computation. If RAM is not an issue, setting up repetitive tasks to run in parallel (i.e., using more than one CPU thread/core at a time) can substantially speed up your program. Easy-to-use solutions to do this are <code>foreach</code> for a parallel version of <code>for</code>-loops and <code>mclapply</code> for a parallel version of <code>lapply</code>.</li>
<li>Finally, if your analytics script builds extensively on matrix multiplication, consider implementing it for processing on your GPU via the <code>gpuR</code> package. Note, though, that this approach presupposes that you have installed and set up your GPU with the right drivers to use it not only for graphics but also for scientific computation.</li>
</ul>
</div>
<div id="still-have-insufficient-computing-resources" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Still have insufficient computing resources?<a href="hardware-computing-resources.html#still-have-insufficient-computing-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When working with very large datasets (i.e., terabytes of data), processing the data on one common computer might not work due to a lack of memory or would be way too slow due to a lack of computing power (CPU cores). The architecture or basic hardware setup of a common computer is subject to a limited amount of RAM and a limited number of CPUs/CPU cores. Hence, simply scaling up might not be sufficient. Instead, we need to scale out. In simple terms, this means connecting several computers (each with its own RAM, CPU, and mass storage) in a network, distributing the dataset across all computers (“nodes”) in this network, and working on the data simultaneously across all nodes. In the next chapter, we look into how such ``distributed systems’’ basically work, what software frameworks are commonly used to work on distributed systems, and how we can interact with this software (and the distributed system) via R and SQL.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-tensorflow2015-whitepaper" class="csl-entry">
Abadi, Martín, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, et al. 2015. <span>“<span>TensorFlow</span>: Large-Scale Machine Learning on Heterogeneous Systems.”</span> <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>.
</div>
<div id="ref-bengtsson_2021" class="csl-entry">
Bengtsson, Henrik. 2021. <span>“<span class="nocase">A Unifying Framework for Parallel and Distributed Processing in R using Futures</span>.”</span> <em><span>The R Journal</span></em> 13 (2): 273–91. <a href="https://doi.org/10.32614/RJ-2021-048">https://doi.org/10.32614/RJ-2021-048</a>.
</div>
<div id="ref-gpuR" class="csl-entry">
Determan, Charles. 2019. <em>gpuR: GPU Functions for r Objects</em>. <a href="http://github.com/cdeterman/gpuR">http://github.com/cdeterman/gpuR</a>.
</div>
<div id="ref-fatahalian_etal2004" class="csl-entry">
Fatahalian, K., J. Sugerman, and P. Hanrahan. 2004. <span>“<span class="nocase">Understanding the Efficiency of GPU Algorithms for Matrix-Matrix Multiplication</span>.”</span> In <em>Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware</em>, 133–37. HWWS ’04. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/1058129.1058148">https://doi.org/10.1145/1058129.1058148</a>.
</div>
<div id="ref-foreach" class="csl-entry">
Microsoft, and Steve Weston. 2022. <em>Foreach: Provides Foreach Looping Construct</em>. <a href="https://CRAN.R-project.org/package=foreach">https://CRAN.R-project.org/package=foreach</a>.
</div>
<div id="ref-rfoundation2021" class="csl-entry">
R Core Team. 2021. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="22">
<li id="fn22"><p>This concept of organizing data into several tables is the basis of relational database management systems, which we will look at in more detail in Chapter 5. However, the basic idea is also very useful for storing raw data efficiently even if there is no intention to later build a database and run SQL queries on it.<a href="hardware-computing-resources.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>For example, if you specify something like <code>lm(y~x1 + x2 + country, data=mydata)</code> and <code>country</code> is a categorical variable (factor).<a href="hardware-computing-resources.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>In simple terms, futures are a programming concept that allows for the asynchronous execution of a task. A future is a placeholder object that represents the result of an asynchronous operation. The future object can be used to check the status of the asynchronous operation and to retrieve the result of the operation when it is completed. By using futures, tasks can be broken down into smaller tasks that can be executed in parallel, resulting in faster completion times.<a href="hardware-computing-resources.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>See <a href="https://www.futureverse.org/packages-overview.html" class="uri">https://www.futureverse.org/packages-overview.html</a> for an overview of the <em>futureverse</em>, and <a href="https://www.futureverse.org/#ref-bengtsson-future" class="uri">https://www.futureverse.org/#ref-bengtsson-future</a> for a set of simple examples of using <code>future</code> in different ways (with different syntaxes/coding styles).<a href="hardware-computing-resources.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>Also, this approach does not work on Windows machines (see <code>?mclapply</code> for details).<a href="hardware-computing-resources.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Note that you can use the forking approach also to resolve futures. By setting <code>plan(multicore)</code> instead of <code>plan(multisession)</code> when working with the <code>future</code> package, parallelization based on futures will be run via forking (again, this will not work on Windows machines).<a href="hardware-computing-resources.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>Note that while these examples are easy to implement and run, setting up a GPU for scientific computing can still involve many steps and some knowledge of your computer’s system. The examples presuppose that all installation and configuration steps (GPU drivers, CUDA, etc.) have already been completed successfully.<a href="hardware-computing-resources.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>See <a href="https://github.com/cdeterman/gpuR/wiki" class="uri">https://github.com/cdeterman/gpuR/wiki</a> for installation instructions regarding the dependencies. Once the package dependencies are installed you can install the <code>gpuR</code>-package directly from GitHub: <code>devtools::install_github("cdeterman/gpuR")</code> (make sure the <code>devtools</code>-package is installed before doing this).<a href="hardware-computing-resources.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>As with setting up GPUs on your machine in general, installing all prerequisites to make <code>gpuR</code> work on your local machine can be a bit of work and can depend a lot on your system.<a href="hardware-computing-resources.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>If we instruct the GPU to use its own memory but the data does not fit in it, the program will result in an error.<a href="hardware-computing-resources.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>Alternatively, with <code>gpuMatrix()</code> we can create an object representing matrix <code>X</code> for computation on the GPU, while only pointing the GPU to the matrix and without actually transferring data to the GPU’s memory.<a href="hardware-computing-resources.html#fnref32" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="software-programming-with-big-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distributed-systems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
