<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Hardware: Computing Resources | Big Data Analytics</title>
  <meta name="description" content="A guide to practical big data analytics in R." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Hardware: Computing Resources | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://umatter.github.io/BigData" />
  <meta property="og:image" content="https://umatter.github.io/BigDataimg/cover.png" />
  <meta property="og:description" content="A guide to practical big data analytics in R." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Hardware: Computing Resources | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to practical big data analytics in R." />
  <meta name="twitter:image" content="https://umatter.github.io/BigDataimg/cover.png" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2022-02-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="software-programming-with-big-data.html"/>
<link rel="next" href="distributed-systems.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/d3/d3.min.js"></script>
<link href="libs/profvis/profvis.css" rel="stylesheet" />
<script src="libs/profvis/profvis.js"></script>
<script src="libs/profvis/scroll.js"></script>
<link href="libs/highlight/textmate.css" rel="stylesheet" />
<script src="libs/highlight/highlight.js"></script>
<script src="libs/profvis-binding/profvis.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-big-in-big-data"><i class="fa fa-check"></i><b>1.1</b> What is <em>big</em> in “Big Data?”</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#approaches-to-analyzing-big-data"><i class="fa fa-check"></i><b>1.2</b> Approaches to analyzing Big Data</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#content-overview"><i class="fa fa-check"></i><b>1.3</b> Content overview</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#prerequisits"><i class="fa fa-check"></i><b>1.4</b> Prerequisits</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>2</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#building-blocks-for-programming-with-big-data"><i class="fa fa-check"></i><b>2.1</b> Building blocks for programming with big data</a></li>
<li class="chapter" data-level="2.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>2.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="2.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-code"><i class="fa fa-check"></i><b>2.3</b> Writing efficient code</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>2.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="2.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>2.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="2.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>2.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="2.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>2.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="2.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>2.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="2.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>2.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>2.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>2.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="2.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>2.4.2</b> Joins</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>3</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="3.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#components-of-a-standard-computing-environment"><i class="fa fa-check"></i><b>3.1</b> Components of a standard computing environment</a></li>
<li class="chapter" data-level="3.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage-and-memory"><i class="fa fa-check"></i><b>3.2</b> Mass Storage and Memory</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#units-of-informationdata-storage"><i class="fa fa-check"></i><b>3.2.1</b> Units of information/data storage</a></li>
<li class="chapter" data-level="3.2.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>3.2.2</b> Combining RAM and hard-disk: virtual memory</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#computation-cpu"><i class="fa fa-check"></i><b>3.3</b> Computation: CPU</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#parallelization"><i class="fa fa-check"></i><b>3.3.1</b> Parallelization</a></li>
<li class="chapter" data-level="3.3.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>3.3.2</b> GPUs for Scientific Computing</a></li>
<li class="chapter" data-level="3.3.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>3.3.3</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#resource-allocation"><i class="fa fa-check"></i><b>3.4</b> Resource allocation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>4</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>4.1</b> MapReduce</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce-concept-illustrated-in-r"><i class="fa fa-check"></i><b>4.1.1</b> Map/Reduce Concept Illustrated in R</a></li>
<li class="chapter" data-level="4.1.2" data-path="distributed-systems.html"><a href="distributed-systems.html#mapper"><i class="fa fa-check"></i><b>4.1.2</b> Mapper</a></li>
<li class="chapter" data-level="4.1.3" data-path="distributed-systems.html"><a href="distributed-systems.html#reducer"><i class="fa fa-check"></i><b>4.1.3</b> Reducer</a></li>
<li class="chapter" data-level="4.1.4" data-path="distributed-systems.html"><a href="distributed-systems.html#simpler-example-compute-the-total-number-of-words"><i class="fa fa-check"></i><b>4.1.4</b> Simpler example: Compute the total number of words</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop"><i class="fa fa-check"></i><b>4.2</b> Hadoop</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count"><i class="fa fa-check"></i><b>4.2.1</b> Hadoop Word Count</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>5</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-parallel-computing"><i class="fa fa-check"></i><b>5.1</b> Scaling up: parallel computing</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="cloud-computing.html"><a href="cloud-computing.html#setting-up-aws-ec2-with-rrstudio"><i class="fa fa-check"></i><b>5.1.1</b> Setting up AWS EC2 with R/RStudio</a></li>
<li class="chapter" data-level="5.1.2" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>5.1.2</b> Parallelization with an EC2 instance</a></li>
<li class="chapter" data-level="5.1.3" data-path="cloud-computing.html"><a href="cloud-computing.html#aws-emr-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>5.1.3</b> AWS EMR: MapReduce in the cloud</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html"><i class="fa fa-check"></i><b>6</b> Data Storage and Databases</a>
<ul>
<li class="chapter" data-level="6.1" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#big-data-storage"><i class="fa fa-check"></i><b>6.1</b> (Big) Data Storage</a></li>
<li class="chapter" data-level="6.2" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#rdbms-basics"><i class="fa fa-check"></i><b>6.2</b> RDBMS basics</a></li>
<li class="chapter" data-level="6.3" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#row-based-vs-column-based-databases"><i class="fa fa-check"></i><b>6.3</b> Row-based vs column-based databases</a></li>
<li class="chapter" data-level="6.4" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#getting-started-with-rsqlite"><i class="fa fa-check"></i><b>6.4</b> Getting started with RSQLite</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#warm-up-in-sqlite-indices-and-joins"><i class="fa fa-check"></i><b>6.4.1</b> Warm up in SQLite: indices and joins</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#sqlite-from-within-r"><i class="fa fa-check"></i><b>6.5</b> SQLite from within R</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>6.5.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#importing-data"><i class="fa fa-check"></i><b>6.5.2</b> Importing data</a></li>
<li class="chapter" data-level="6.5.3" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#issue-queries"><i class="fa fa-check"></i><b>6.5.3</b> Issue queries</a></li>
<li class="chapter" data-level="6.5.4" data-path="data-storage-and-databases.html"><a href="data-storage-and-databases.html#mass-storage-mariadb-on-an-ec2-instance"><i class="fa fa-check"></i><b>6.5.4</b> Mass Storage: MariaDB on an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>7</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies"><i class="fa fa-check"></i><b>7.1</b> ‘Out-of-memory’ strategies</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>7.1.1</b> Chunking data with the <code>ff</code>-package</a></li>
<li class="chapter" data-level="7.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>7.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#typical-cleaning-tasks"><i class="fa fa-check"></i><b>7.2</b> Typical cleaning tasks</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-preparation-with-ff"><i class="fa fa-check"></i><b>7.2.1</b> Data Preparation with <code>ff</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>8</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="8.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>8.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a></li>
<li class="chapter" data-level="8.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-tutorial"><i class="fa fa-check"></i><b>8.2</b> Data aggregation tutorial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#gathering-and-compilation-of-all-the-raw-data"><i class="fa fa-check"></i><b>8.2.1</b> Gathering and Compilation of all the raw data</a></li>
<li class="chapter" data-level="8.2.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>8.2.2</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="8.2.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>8.2.3</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>9</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-set"><i class="fa fa-check"></i><b>9.1</b> Data Set</a></li>
<li class="chapter" data-level="9.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#excursus-modify-and-create-themes"><i class="fa fa-check"></i><b>9.2</b> Excursus: modify and create themes</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#create-your-own-theme-simple-approach"><i class="fa fa-check"></i><b>9.2.1</b> Create your own theme: simple approach</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#implementing-actual-themes-as-functions."><i class="fa fa-check"></i><b>9.2.2</b> Implementing actual themes as functions.</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualize-time-and-space"><i class="fa fa-check"></i><b>9.3</b> Visualize Time and Space</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>9.3.1</b> Preparations</a></li>
<li class="chapter" data-level="9.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>9.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#excursus-change-color-schemes"><i class="fa fa-check"></i><b>9.4</b> Excursus: change color schemes</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html"><i class="fa fa-check"></i><b>10</b> Bottle Necks in Local Big Data Analytics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#example-of-computation-time-and-memory-allocation"><i class="fa fa-check"></i><b>10.1</b> Example of Computation Time and Memory Allocation</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#preparation"><i class="fa fa-check"></i><b>10.1.1</b> Preparation</a></li>
<li class="chapter" data-level="10.1.2" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>10.1.2</b> Naïve Approach (ignorant of R)</a></li>
<li class="chapter" data-level="10.1.3" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>10.1.3</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="10.1.4" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>10.1.4</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-parallel-processing"><i class="fa fa-check"></i><b>10.2</b> Case study: Parallel processing</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>10.2.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#case-study-memory-allocation"><i class="fa fa-check"></i><b>10.3</b> Case study: Memory allocation</a></li>
<li class="chapter" data-level="10.4" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#big-data-econometrics"><i class="fa fa-check"></i><b>10.4</b> Big Data econometrics</a></li>
<li class="chapter" data-level="10.5" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#example-fast-least-squares-regression"><i class="fa fa-check"></i><b>10.5</b> Example: Fast least squares regression</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>10.5.1</b> OLS as a point of reference</a></li>
<li class="chapter" data-level="10.5.2" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>10.5.2</b> The Uluru algorithm as an alternative to OLS</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#gpus-and-machine-learning"><i class="fa fa-check"></i><b>10.6</b> GPUs and Machine Learning</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>10.6.1</b> Tensorflow/Keras example: predict housing prices</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="bottle-necks-in-local-big-data-analytics.html"><a href="bottle-necks-in-local-big-data-analytics.html#a-word-of-caution"><i class="fa fa-check"></i><b>10.7</b> A word of caution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="applied-econometrics-with-apache-spark.html"><a href="applied-econometrics-with-apache-spark.html"><i class="fa fa-check"></i><b>11</b> Applied Econometrics with Apache Spark</a>
<ul>
<li class="chapter" data-level="11.1" data-path="applied-econometrics-with-apache-spark.html"><a href="applied-econometrics-with-apache-spark.html#spark-basics"><i class="fa fa-check"></i><b>11.1</b> Spark basics</a></li>
<li class="chapter" data-level="11.2" data-path="applied-econometrics-with-apache-spark.html"><a href="applied-econometrics-with-apache-spark.html#spark-in-r"><i class="fa fa-check"></i><b>11.2</b> Spark in R</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="applied-econometrics-with-apache-spark.html"><a href="applied-econometrics-with-apache-spark.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>11.2.1</b> Data import and summary statistics</a></li>
<li class="chapter" data-level="11.2.2" data-path="applied-econometrics-with-apache-spark.html"><a href="applied-econometrics-with-apache-spark.html#regression-analysis-with-sparklyr"><i class="fa fa-check"></i><b>11.2.2</b> Regression analysis with <code>sparklyr</code></a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-a.html"><a href="appendix-a.html"><i class="fa fa-check"></i><b>A</b> Appendix A</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendix-a.html"><a href="appendix-a.html#github"><i class="fa fa-check"></i><b>A.1</b> GitHub</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendix-a.html"><a href="appendix-a.html#initiate-a-new-repository"><i class="fa fa-check"></i><b>A.1.1</b> Initiate a new repository</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendix-a.html"><a href="appendix-a.html#clone-this-courses-repository"><i class="fa fa-check"></i><b>A.1.2</b> Clone this course’s repository</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendix-a.html"><a href="appendix-a.html#fork-this-courses-repository"><i class="fa fa-check"></i><b>A.1.3</b> Fork this course’s repository</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendix-b.html"><a href="appendix-b.html"><i class="fa fa-check"></i><b>B</b> Appendix B</a>
<ul>
<li class="chapter" data-level="B.0.1" data-path="appendix-b.html"><a href="appendix-b.html#data-types-and-memorystorage"><i class="fa fa-check"></i><b>B.0.1</b> Data types and memory/storage</a></li>
<li class="chapter" data-level="B.0.2" data-path="appendix-b.html"><a href="appendix-b.html#data-structures"><i class="fa fa-check"></i><b>B.0.2</b> Data structures</a></li>
<li class="chapter" data-level="B.0.3" data-path="appendix-b.html"><a href="appendix-b.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i><b>B.0.3</b> Vectors vs Factors in R</a></li>
<li class="chapter" data-level="B.0.4" data-path="appendix-b.html"><a href="appendix-b.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i><b>B.0.4</b> R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hardware-computing-resources" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Hardware: Computing Resources</h1>
<div id="components-of-a-standard-computing-environment" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Components of a standard computing environment</h2>
<p>Figure <a href="hardware-computing-resources.html#fig:components">3.1</a> illustrates the key components of a standard computing environment to process digital data. In our case, these components serve the purpose of computing a statistic, given a large data set as input.</p>
<div class="figure" style="text-align: center"><span id="fig:components"></span>
<img src="img/03_script-hardware_w.jpg" alt="Basic components of a standard computing environment." width="60%" />
<p class="caption">
Figure 3.1: Basic components of a standard computing environment.
</p>
</div>

<ul>
<li><p>The component actually <em>processing</em> data is the Central Processing Unit (CPU). When using R to process data, R commands are translated into complex combinations of a small set of basic operations which the <em>CPU</em> then executes.</p></li>
<li><p>In order to work with data (e.g., in R), it first has to be loaded into the <em>memory</em> of our computer. More specifically, into the Random Access Memory (<em>RAM</em>). Typically, data is only loaded in the RAM as long as we work with it.</p></li>
<li><p><em>Mass Storage</em> refers to the type of computer memory we use to store data in the long run. This is what we call the <em>hard drive</em> or <em>hard disk</em>. In these days, the relevant hard disk is actually often not the one physically built into our computer but a hard disk ‘in the cloud’ (built into a server to which we connect over the Internet).</p></li>
</ul>
<p>Very simply put, the difference between ‘data analytics’ and ‘Big Data analytics’ is that in the latter case, the standard usage of one or several of these components fails or works very inefficiently because the amount of data overwhelms its normal capacity.</p>
<p>From this hardware-perspective, there are two basic strategies to cope with the situation that one of these components is overwhelmed by the amount of data:</p>
<ul>
<li><em>Scale up (‘horizontal scaling’)</em>: Extend the physical capacity of the affected component by building a system with large RAM shared between applications. This sounds like a trivial solution (‘if RAM is too small, buy more RAM…’), but in practice it can be very expensive.</li>
<li><em>Scale out (‘vertical scaling’)</em>: Distribute the workload over several computers (or separate components of a system).</li>
</ul>
<p>From a software-perspective, there are many (context-specific) strategies that can help us to use the resources available more efficiently in order to process large amounts of data. In the context of computing statistics based on big data, this can involve:</p>
<ul>
<li>Implementing the computation of a given statistical procedure in a more efficient way (make better use of a given programming language or choose another programming language).</li>
<li>Choosing/implementing a more efficient statistical procedure/algorithm (see, e.g., the <em>Uluru</em> algorithm).</li>
<li>At a lower level, improving how the system allocates resources.</li>
</ul>
</div>
<div id="mass-storage-and-memory" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Mass Storage and Memory</h2>
<div id="units-of-informationdata-storage" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Units of information/data storage</h3>
<p>The smallest unit of information in computing/digital data is called a <em>bit</em> (from <em>bi</em>nary dig<em>it</em>; abbrev. ‘b’) and can take one of two (symbolic) values, either a <code>0</code> or a <code>1</code> (“off” or “on”). Consider, for example, the decimal number <code>139</code>. Written in the binary system, <code>139</code> corresponds to the binary number <code>10001011</code>. In order to store this number on a hard disk, we require a capacity of 8 bits, or one <em>byte</em> (1 byte = 8 bits; abbrev. ‘B’). Historically, one byte encoded a single character of text (i.e., in the ASCII character encoding system). 4 bytes (or 32 bits) are called a <em>word</em>. When thinking of a given data set in its raw/binary representation, we can simply think of it as a row of <code>0</code>s and <code>1</code>s, as illustrated in the following figure.</p>
<div class="figure" style="text-align: center"><span id="fig:bitbyteword"></span>
<img src="img/03_store-bitbyteword.png" alt="Writing data stored in RAM to a Mass Storage device (hard drive). Figure by Murrell (2009) (licensed under CC BY-NC-SA 3.0 NZ)." width="50%" />
<p class="caption">
Figure 3.2: Writing data stored in RAM to a Mass Storage device (hard drive). Figure by <span class="citation"><a href="references.html#ref-murrell_2009" role="doc-biblioref">Murrell</a> (<a href="references.html#ref-murrell_2009" role="doc-biblioref">2009</a>)</span> (licensed under CC BY-NC-SA 3.0 NZ).
</p>
</div>

<p>Bigger units for storage capacity usually build on bytes:</p>
<ul>
<li><span class="math inline">\(1 \text{ kilobyte (KB)} = 1000^{1} \approx 2^{10} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ megabyte (MB)} = 1000^{2} \approx 2^{20} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ gigabyte (GB)} = 1000^{3} \approx 2^{30} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ terabyte (TB)} = 1000^{4} \approx 2^{40} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ petabyte (PB)} = 1000^{5} \approx 2^{50} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ exabyte (EB)} = 1000^{6} \approx 2^{60} \text{ bytes}\)</span></li>
<li><span class="math inline">\(1 \text{ zettabyte (ZB)} = 1000^{7} \approx 2^{70} \text{ bytes}\)</span></li>
</ul>
<p><span class="math display">\[1 ZB = 1000000000000000000000\text{ bytes} = 1 \text{ billion terabytes} = 1 \text{ trillion gigabytes}.\]</span></p>
</div>
<div id="combining-ram-and-hard-disk-virtual-memory" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Combining RAM and hard-disk: virtual memory</h3>
<p>In the previous example we have inspected how RAM is allocated to store objects in the R computing environment. But what if all RAM of our computer is not enough to store all the data we want to analyze?</p>
<p>Modern operating systems have a way to dealing with such a situation. Once all RAM is used up by the currently running programs, the OS allocates parts of the memory back to the hard-disk which then works as <em>virtual memory</em>. The following figure illustrates this point.</p>
<div class="figure" style="text-align: center"><span id="fig:vm"></span>
<img src="img/03_virtualmemory.png" alt="Virtual memory. Figure by Ehamberg (CC BY-SA 3.0)." width="30%" />
<p class="caption">
Figure 3.3: Virtual memory. Figure by Ehamberg (CC BY-SA 3.0).
</p>
</div>

<p>For example, when we implement an R-script that imports one file after the other into the R environment, ignoring the RAM capacity of our computer, the OS will start <em>paging</em> data to the virtual memory. This happens ‘under the hood’ without explicit instructions by the user. We quite likely notice that the computer slows down a lot when this happens.</p>
<p>While this default usage of virtual memory by the OS is helpful to run several applications at the same time, each taking up a moderate amount of memory, it is not a really useful tool for processing large amounts of data in one application (R). However, the underlying idea of using both RAM and Mass storage simultaneously in order to cope with a lack of memory is very useful in the context of big data analytics.</p>
<p>Several R packages have been developed that exploit the idea behind virtual memory explicitly for analyzing large amounts of data. The basic idea behind these packages is to map a data set to the hard disk when loading it into R. The actual data values are stored in chunks on the hard-disk, while the structure/metadata of the data set is loaded into R. See this week’s slide set as well as <span class="citation"><a href="references.html#ref-walkowiak_2016" role="doc-biblioref">Walkowiak</a> (<a href="references.html#ref-walkowiak_2016" role="doc-biblioref">2016</a>)</span>, Chapter 3 for more details and example code.</p>
</div>
</div>
<div id="computation-cpu" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Computation: CPU</h2>
<p>The actual processing of the data is done in the computer’s central processing unit (CPU). Consequently, the performance of the CPU has a substantial effect on how fast a data analytics task runs. Thereby, a CPU’s performance is usually denoted by its <em>clock rate</em> measured in gigaherz (GHz). In simple terms, a CPU with a clock rate of 4.8 GHz can execute 4.8 billion basic operations per second. Holding all other aspects constant, you can thus expect an analytics task to run faster if it runs on a computer with higher CPU clock rate. Alternatively to scaling up the CPU, we can exploit that modern CPUs have several <em>cores</em>. In the normal usage of a PC, the operating system makes use of these cores in order to run several applications smoothly <em>in parallel</em> (e.g., you listen to music on Spotify while browsing the web and running some analytics script in RStudio in the background).</p>
<div id="parallelization" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Parallelization</h3>
<p>Modern computing environments such as R allow us to explicitly run one program in parallel, that is on several CPU cores at the same time. Following the same logic, we can also connect several computers (each with several CPU cores) in a cluster computer and run the program in parallel on all of these computing nodes. Both of these approaches are generally referred to as <em>parallelization</em> and both are supported in several R packages.</p>
<p>Thereby, an R program run in parallel typically involves the following steps</p>
<ul>
<li>First, several instances of R are running at the same time (across one machine with multiple CPU cores or across a cluster computer). One of the instances (i.e., the <em>master</em> instance) breaks the computation into batches and sends those to the other instances.</li>
<li>Second, each of the instances processes its batch and sends the results back to the master instance.</li>
<li>Finally, the master instance combines the partial results to the final result and returns it to the user.</li>
</ul>
<p>To illustrate this point, consider the following econometric problem: you have customer <a href="https://www.kaggle.com/jackdaoud/marketing-data?select=marketing_data.csv">dataset</a> with detailed data on customer characteristics, past customer behavior and information on online marketing campaigns. Your task is to figure out, which customers are more likely to react positively to to the most recent online marketing campaign in order to optimize personalized marketing campaigns in the future. In a first step you take a “brute force” approach that is computationally very intense: you run all possible regressions with the dependent variable <code>Response</code> (equal to 1 if the customer took the offer in the campaign and 0 otherwise). In total you have 21 independent variables, thus you need to run <span class="math inline">\(2^20=1048576\)</span> logit regressions (without considering linear combinations of covariates etc.). Finally, you want to select the model with the best fit according to deviance.</p>
<p>A simple sequential implementation to solve this problem could look like this (for the sake of time, we cap the number of regression models with N=10).</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="hardware-computing-resources.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># you can download the dataset from </span></span>
<span id="cb104-2"><a href="hardware-computing-resources.html#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.kaggle.com/jackdaoud/marketing-data?select=marketing_data.csv</span></span>
<span id="cb104-3"><a href="hardware-computing-resources.html#cb104-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-4"><a href="hardware-computing-resources.html#cb104-4" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARATION -----------------------------</span></span>
<span id="cb104-5"><a href="hardware-computing-resources.html#cb104-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-6"><a href="hardware-computing-resources.html#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="co"># packages</span></span>
<span id="cb104-7"><a href="hardware-computing-resources.html#cb104-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb104-8"><a href="hardware-computing-resources.html#cb104-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-9"><a href="hardware-computing-resources.html#cb104-9" aria-hidden="true" tabindex="-1"></a><span class="co"># import data</span></span>
<span id="cb104-10"><a href="hardware-computing-resources.html#cb104-10" aria-hidden="true" tabindex="-1"></a>marketing <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/marketing_data.csv&quot;</span>)</span>
<span id="cb104-11"><a href="hardware-computing-resources.html#cb104-11" aria-hidden="true" tabindex="-1"></a><span class="co"># clean/prepare data</span></span>
<span id="cb104-12"><a href="hardware-computing-resources.html#cb104-12" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Income <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">gsub</span>(<span class="st">&quot;[[:punct:]]&quot;</span>, <span class="st">&quot;&quot;</span>, marketing<span class="sc">$</span>Income)) </span>
<span id="cb104-13"><a href="hardware-computing-resources.html#cb104-13" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>days_customer <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="fu">Sys.Date</span>())<span class="sc">-</span> <span class="fu">as.Date</span>(marketing<span class="sc">$</span>Dt_Customer, <span class="st">&quot;%m/%d/%y&quot;</span>)</span>
<span id="cb104-14"><a href="hardware-computing-resources.html#cb104-14" aria-hidden="true" tabindex="-1"></a>marketing<span class="sc">$</span>Dt_Customer <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb104-15"><a href="hardware-computing-resources.html#cb104-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-16"><a href="hardware-computing-resources.html#cb104-16" aria-hidden="true" tabindex="-1"></a><span class="co"># all sets of independent vars</span></span>
<span id="cb104-17"><a href="hardware-computing-resources.html#cb104-17" aria-hidden="true" tabindex="-1"></a>indep <span class="ot">&lt;-</span> <span class="fu">names</span>(marketing)[ <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">19</span>, <span class="dv">27</span>,<span class="dv">28</span>)]</span>
<span id="cb104-18"><a href="hardware-computing-resources.html#cb104-18" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(indep),</span>
<span id="cb104-19"><a href="hardware-computing-resources.html#cb104-19" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">function</span>(x) <span class="fu">combn</span>(indep, x, <span class="at">simplify =</span> <span class="cn">FALSE</span>))</span>
<span id="cb104-20"><a href="hardware-computing-resources.html#cb104-20" aria-hidden="true" tabindex="-1"></a>combinations_list <span class="ot">&lt;-</span> <span class="fu">unlist</span>(combinations_list, <span class="at">recursive =</span> <span class="cn">FALSE</span>)</span>
<span id="cb104-21"><a href="hardware-computing-resources.html#cb104-21" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">lapply</span>(combinations_list,</span>
<span id="cb104-22"><a href="hardware-computing-resources.html#cb104-22" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;Response ~&quot;</span>, <span class="fu">paste</span>(x, <span class="at">collapse=</span><span class="st">&quot;+&quot;</span>)))</span>
<span id="cb104-23"><a href="hardware-computing-resources.html#cb104-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-24"><a href="hardware-computing-resources.html#cb104-24" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS --------------------------</span></span>
<span id="cb104-25"><a href="hardware-computing-resources.html#cb104-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-26"><a href="hardware-computing-resources.html#cb104-26" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb104-27"><a href="hardware-computing-resources.html#cb104-27" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb104-28"><a href="hardware-computing-resources.html#cb104-28" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(pseudo_Rsq) <span class="ot">&lt;-</span> N</span>
<span id="cb104-29"><a href="hardware-computing-resources.html#cb104-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb104-30"><a href="hardware-computing-resources.html#cb104-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb104-31"><a href="hardware-computing-resources.html#cb104-31" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb104-32"><a href="hardware-computing-resources.html#cb104-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb104-33"><a href="hardware-computing-resources.html#cb104-33" aria-hidden="true" tabindex="-1"></a>  pseudo_Rsq[[i]] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance)</span>
<span id="cb104-34"><a href="hardware-computing-resources.html#cb104-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb104-35"><a href="hardware-computing-resources.html#cb104-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-36"><a href="hardware-computing-resources.html#cb104-36" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb104-37"><a href="hardware-computing-resources.html#cb104-37" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ MntWines&quot;</code></pre>
<div id="naive-multi-session-approach" class="section level4" number="3.3.1.1">
<h4><span class="header-section-number">3.3.1.1</span> Naive multi-session approach</h4>
<p>There is actually a simple way of doing this “manually” on a multi-core PC, which intuitively illustrates the point of parallelization (although it would not be a very practical approach: you write an R script that loads the dataset, runs the fist <span class="math inline">\(n\)</span> of the total of <span class="math inline">\(N\)</span> regressions, and stores the result in a local text file. Next, you run the script in your current RStudio session, open an additional RStudio session and run the script with the next <span class="math inline">\(n\)</span> regressions, and so on until all cores are occupied with one RStudio session. In the end you collect all of the results from the separate text files and combine them to get the final result. Depending on the problem at hand, this could indeed speed up the overall task and it is technically speaking a form of a “multi-session” approach. However, as you have surely noticed, this is unlikely a very pracatical approach.</p>
</div>
<div id="multi-core-and-multi-node-approach" class="section level4" number="3.3.1.2">
<h4><span class="header-section-number">3.3.1.2</span> Multi-core and multi-node approach</h4>
<p>A more practical approach is to write one R script (with the help of some specialized packages) that instructs R to automatically distribute the batches to different cores (or different computing nodes in a cluster computer), control and monitor the progress in all cores, and then automatically collect and combine the results from all cores. There are several approaches to achieve this in R.</p>
<div id="parallel-for-loops-using-socket" class="section level5" number="3.3.1.2.1">
<h5><span class="header-section-number">3.3.1.2.1</span> Parallel for-loops using socket</h5>
<p>Likely the most intuitive approach to parallelizing a task in R is the <code>foreach</code> package. It allows you to write a <code>foreach</code> statement that is very similar to the for-loop syntax in R. This allows you to straightforwardly “translate” an already implemented sequential approach in a for loop to a parallelized implementation.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="hardware-computing-resources.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) --------------------------</span></span>
<span id="cb106-2"><a href="hardware-computing-resources.html#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="hardware-computing-resources.html#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="co"># packages for parallel processing</span></span>
<span id="cb106-4"><a href="hardware-computing-resources.html#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb106-5"><a href="hardware-computing-resources.html#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doSNOW)</span></code></pre></div>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: snow</code></pre>
<pre><code>## 
## Attaching package: &#39;snow&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:parallel&#39;:
## 
##     clusterApply, clusterApplyLB, clusterCall,
##     clusterEvalQ, clusterExport, clusterMap,
##     clusterSplit, makeCluster, parApply,
##     parCapply, parLapply, parRapply, parSapply,
##     splitIndices, stopCluster</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="hardware-computing-resources.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get the number of cores available</span></span>
<span id="cb112-2"><a href="hardware-computing-resources.html#cb112-2" aria-hidden="true" tabindex="-1"></a>ncores <span class="ot">&lt;-</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>()</span>
<span id="cb112-3"><a href="hardware-computing-resources.html#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="co"># set cores for parallel processing</span></span>
<span id="cb112-4"><a href="hardware-computing-resources.html#cb112-4" aria-hidden="true" tabindex="-1"></a>ctemp <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(ncores)</span>
<span id="cb112-5"><a href="hardware-computing-resources.html#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoSNOW</span>(ctemp)</span>
<span id="cb112-6"><a href="hardware-computing-resources.html#cb112-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-7"><a href="hardware-computing-resources.html#cb112-7" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare loop</span></span>
<span id="cb112-8"><a href="hardware-computing-resources.html#cb112-8" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb112-9"><a href="hardware-computing-resources.html#cb112-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run loop in parallel</span></span>
<span id="cb112-10"><a href="hardware-computing-resources.html#cb112-10" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span></span>
<span id="cb112-11"><a href="hardware-computing-resources.html#cb112-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">foreach</span> ( <span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span>N, <span class="at">.combine =</span> c) <span class="sc">%dopar%</span> {</span>
<span id="cb112-12"><a href="hardware-computing-resources.html#cb112-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb112-13"><a href="hardware-computing-resources.html#cb112-13" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb112-14"><a href="hardware-computing-resources.html#cb112-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb112-15"><a href="hardware-computing-resources.html#cb112-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb112-16"><a href="hardware-computing-resources.html#cb112-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb112-17"><a href="hardware-computing-resources.html#cb112-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-18"><a href="hardware-computing-resources.html#cb112-18" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER ---------------</span></span>
<span id="cb112-19"><a href="hardware-computing-resources.html#cb112-19" aria-hidden="true" tabindex="-1"></a>models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
<p>Note: with few relatively few cases, this approach is not very fast due to the overhead of “distributing” variables/objects from the master process to all cores/workers. In simple terms, the socket approach means that the cores do not share the same variables/the same environment, which creates overhead. However, this approach is usually very stable and runs on all platforms.</p>
</div>
<div id="parallel-lapply-using-forking" class="section level5" number="3.3.1.2.2">
<h5><span class="header-section-number">3.3.1.2.2</span> Parallel lapply using Forking</h5>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="hardware-computing-resources.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPUTE REGRESSIONS IN PARALLEL (MULTI-CORE) --------------------------</span></span>
<span id="cb114-2"><a href="hardware-computing-resources.html#cb114-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-3"><a href="hardware-computing-resources.html#cb114-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-4"><a href="hardware-computing-resources.html#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare parallel lapply (based on forking, here clearly faster than foreach)</span></span>
<span id="cb114-5"><a href="hardware-computing-resources.html#cb114-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># just for illustration, the actual code is N &lt;- length(models)</span></span>
<span id="cb114-6"><a href="hardware-computing-resources.html#cb114-6" aria-hidden="true" tabindex="-1"></a><span class="co"># run parallel lapply</span></span>
<span id="cb114-7"><a href="hardware-computing-resources.html#cb114-7" aria-hidden="true" tabindex="-1"></a>pseudo_Rsq <span class="ot">&lt;-</span> <span class="fu">mclapply</span>(<span class="dv">1</span><span class="sc">:</span>N,</span>
<span id="cb114-8"><a href="hardware-computing-resources.html#cb114-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mc.cores =</span> ncores,</span>
<span id="cb114-9"><a href="hardware-computing-resources.html#cb114-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">FUN =</span> <span class="cf">function</span>(i){</span>
<span id="cb114-10"><a href="hardware-computing-resources.html#cb114-10" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># fit the logit model via maximum likelihood</span></span>
<span id="cb114-11"><a href="hardware-computing-resources.html#cb114-11" aria-hidden="true" tabindex="-1"></a>                         fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(models[[i]], <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb114-12"><a href="hardware-computing-resources.html#cb114-12" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># compute the proportion of deviance explained by the independent vars (~R^2)</span></span>
<span id="cb114-13"><a href="hardware-computing-resources.html#cb114-13" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">return</span>(<span class="dv">1</span><span class="sc">-</span>(fit<span class="sc">$</span>deviance<span class="sc">/</span>fit<span class="sc">$</span>null.deviance))</span>
<span id="cb114-14"><a href="hardware-computing-resources.html#cb114-14" aria-hidden="true" tabindex="-1"></a>                         })</span>
<span id="cb114-15"><a href="hardware-computing-resources.html#cb114-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-16"><a href="hardware-computing-resources.html#cb114-16" aria-hidden="true" tabindex="-1"></a><span class="co"># SELECT THE WINNER, SHOW FINAL OUTPUT ---------------</span></span>
<span id="cb114-17"><a href="hardware-computing-resources.html#cb114-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-18"><a href="hardware-computing-resources.html#cb114-18" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> models[[<span class="fu">which.max</span>(pseudo_Rsq)]]</span>
<span id="cb114-19"><a href="hardware-computing-resources.html#cb114-19" aria-hidden="true" tabindex="-1"></a>best_model</span></code></pre></div>
<pre><code>## [1] &quot;Response ~ Year_Birth+Teenhome+Recency+MntWines+days_customer&quot;</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="hardware-computing-resources.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">glm</span>(best_model, <span class="at">data=</span>marketing, <span class="at">family =</span> <span class="fu">binomial</span>()))</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = best_model, family = binomial(), data = marketing)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.891  -0.553  -0.358  -0.206   3.060  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)   -8.075258  11.052664   -0.73     0.47
## Year_Birth    -0.001108   0.005603   -0.20     0.84
## Teenhome      -1.049052   0.141725   -7.40  1.3e-13
## Recency       -0.024592   0.002471   -9.95  &lt; 2e-16
## MntWines       0.001751   0.000176    9.96  &lt; 2e-16
## days_customer  0.002940   0.000349    8.43  &lt; 2e-16
##                  
## (Intercept)      
## Year_Birth       
## Teenhome      ***
## Recency       ***
## MntWines      ***
## days_customer ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1886.8  on 2239  degrees of freedom
## Residual deviance: 1530.3  on 2234  degrees of freedom
## AIC: 1542
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>In the fork approach, each core works with the same objects/variables in a shared environment, which makes this approach very fast. However, it can run into issues and does not work on Windows machines (see <code>?mclapply</code> for details). If you are not sure whether your set up and parallelization-problem might run into issues when using this approach, better rely on a non-fork approach.</p>
</div>
</div>
<div id="parallelization-based-on-futures" class="section level4" number="3.3.1.3">
<h4><span class="header-section-number">3.3.1.3</span> Parallelization based on futures</h4>
<p><a href="https://github.com/HenrikBengtsson/future" class="uri">https://github.com/HenrikBengtsson/future</a>
<a href="https://cran.r-project.org/web/packages/future/vignettes/future-3-topologies.html" class="uri">https://cran.r-project.org/web/packages/future/vignettes/future-3-topologies.html</a></p>
</div>
</div>
<div id="gpus-for-scientific-computing" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> GPUs for Scientific Computing</h3>
<p>The success of the computer games industry in the late 1990s/early 2000s led to an interesting positive externality for scientific computing. The ever more demanding graphics of modern computer games and the huge economic success of the computer games industry set incentives for hardware producers to invest in research and development of more powerful ‘graphic cards,’ extending a normal PC/computing environment with additional computing power solely dedicated to graphics. At the heart of these graphic cards are so-called GPUs (Graphic Processing Units), microprocessors specifically optimized for graphics processing. The image below depicts a modern graphics card with NVIDIA GPUs, which is quite common in today’s ‘gaming’ PCs.</p>
<p><img src="img/nvidia_geeforce.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Why did the hardware industry not simply invest in the development of more powerful CPUs to deal with the more demanding PC games? The main reason is that the architecture of CPUs is designed not only for efficiency but also flexibility. That is, a CPU needs to perform well in all kind of computations, some parallel, some sequential, etc. Computing graphics is a comparatively narrow domain of computation and designing a processing unit architecture that is custom-made to excel just at this one task is thus much more cost efficient. Interestingly, this graphics-specific architecture (specialized on highly parallel numerical [floating point] workloads) turns out to be also very useful in some core scientific computing tasks. In particular, matrix multiplications (see <span class="citation"><a href="references.html#ref-fatahalian_etal2004" role="doc-biblioref">Fatahalian, Sugerman, and Hanrahan</a> (<a href="references.html#ref-fatahalian_etal2004" role="doc-biblioref">2004</a>)</span> for a detailed discussion of why that is the case). A key aspect of GPUs is that they are composed of several multiprocessor units, of which each has in turn several cores. GPUS thus can perform computations with hundreds or even thousands of threads in parallel. The figure below illustrates this point.</p>
<p><img src="img/nvidia_gpu.png" width="60%" style="display: block; margin: auto;" /></p>
<!-- ```{r nvidia_architecture, echo=FALSE, out.width = "60%", fig.align='center', fig.cap= "(ref:nvidiaarchitecture)", purl=FALSE} -->
<!-- include_graphics("img/nvidia_gpu.png") -->
<!-- ``` -->
<!-- (ref:nvidiaarchitecture) Typical NVIDIA GPU architecture (illustration and notes by @hernandez_etal2013). The GPU is comprised of a set of Streaming MultiProcessors (SM). Each SM is comprised of several Stream Processor (SP) cores, as shown for the NVIDIA’s Fermi architecture (a). The GPU resources are controlled by the programmer through the CUDA programming model, shown in (b). -->
<p>While, initially, programming GPUs for scientific computing required a very good understanding of the hardware. Graphics card producers have realized that there is an additional market for their products (in particular with the recent rise of deep learning), and provide several high-level APIs to use GPUs for other tasks than graphics processing. Over the last few years more high-level software has been developed, which makes it much easier to use GPUs in parallel computing tasks. The following subsections shows some examples of such software in the R environment.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
</div>
<div id="gpus-in-r" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> GPUs in R</h3>
<!-- ## Installation -->
<!-- This is for pop OS machines. Install drivers etc. for NVIDIA card -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install OpenCL -->
<!-- ```{bash eval=FALSE} -->
<!-- # sudo apt install tensorflow-cuda-latest -->
<!-- ``` -->
<!-- Install `gpuR` in R (`install.packages("gpuR")`). -->
<div id="gpu-computing-example-matrix-multiplication-comparison-gpur" class="section level4" number="3.3.3.1">
<h4><span class="header-section-number">3.3.3.1</span> GPU computing example: Matrix multiplication comparison (<code>gpuR</code>)</h4>
<p>The <code>gpuR</code> package provides basic R functions to compute with GPUs from within the R environmnent. In the following example we compare the performance of the CPU with the GPU based on a matrix multiplication exercise. For a large <span class="math inline">\(N\times P\)</span> matrix <span class="math inline">\(X\)</span>, we want to compute <span class="math inline">\(X^tX\)</span>.</p>
<p>In a first step, we load the <code>gpuR</code>-package.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> Note the output to the console. It shows the type of GPU identified by <code>gpuR</code>. This is the platform on which <code>gpuR</code> will compute the GPU examples. In order to compare the performances, we also load the <code>bench</code> package used in previous lectures.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="hardware-computing-resources.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load package</span></span>
<span id="cb118-2"><a href="hardware-computing-resources.html#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bench)</span>
<span id="cb118-3"><a href="hardware-computing-resources.html#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gpuR)</span></code></pre></div>
<pre><code>## Number of platforms: 1
## - platform: NVIDIA Corporation: OpenCL 3.0 CUDA 11.4.158
##   - context device index: 0
##     - NVIDIA GeForce GTX 1650
## checked all devices
## completed initialization</code></pre>
<p>Next, we initiate a large matrix filled with pseudo random numbers, representing a dataset with <span class="math inline">\(N\)</span> observations and <span class="math inline">\(P\)</span> variables.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="hardware-computing-resources.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initiate dataset with pseudo random numbers</span></span>
<span id="cb120-2"><a href="hardware-computing-resources.html#cb120-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10000</span>  <span class="co"># number of observations</span></span>
<span id="cb120-3"><a href="hardware-computing-resources.html#cb120-3" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># number of variables</span></span>
<span id="cb120-4"><a href="hardware-computing-resources.html#cb120-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(N <span class="sc">*</span> P, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N, <span class="at">ncol =</span>P)</span></code></pre></div>
<p>For the GPU examples to work, we need one more preparatory step. GPUs have their own memory, which they can access faster than they can access RAM. However, this GPU memory is typically not very large compared to the memory CPUs have access to. Hence, there is a potential trade-off between losing some efficiency but working with more data or vice versa.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Here, we show both variants. With <code>gpuMatrix()</code> we create an object representing matrix <code>X</code> for computation on the GPU. However, this only points the GPU to the matrix and does not actually transfer data to the GPU’s memory. The latter is done in the other variant with <code>vclMatrix()</code>.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="hardware-computing-resources.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare GPU-specific objects/settings</span></span>
<span id="cb121-2"><a href="hardware-computing-resources.html#cb121-2" aria-hidden="true" tabindex="-1"></a>gpuX <span class="ot">&lt;-</span> <span class="fu">gpuMatrix</span>(X, <span class="at">type =</span> <span class="st">&quot;float&quot;</span>)  <span class="co"># point GPU to matrix (matrix stored in non-GPU memory)</span></span>
<span id="cb121-3"><a href="hardware-computing-resources.html#cb121-3" aria-hidden="true" tabindex="-1"></a>vclX <span class="ot">&lt;-</span> <span class="fu">vclMatrix</span>(X, <span class="at">type =</span> <span class="st">&quot;float&quot;</span>)  <span class="co"># transfer matrix to GPU (matrix stored in GPU memory)</span></span></code></pre></div>
<p>Now we run the three examples: first, based on standard R, using the CPU. Then, computing on the GPU but using CPU memory. And finally, computing on the GPU and using GPU memory. In order to make the comparison fair, we force <code>bench::mark()</code> to run at least 20 iterations per benchmarked variant.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="hardware-computing-resources.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compare three approaches</span></span>
<span id="cb122-2"><a href="hardware-computing-resources.html#cb122-2" aria-hidden="true" tabindex="-1"></a>(gpu_cpu <span class="ot">&lt;-</span> bench<span class="sc">::</span><span class="fu">mark</span>(</span>
<span id="cb122-3"><a href="hardware-computing-resources.html#cb122-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb122-4"><a href="hardware-computing-resources.html#cb122-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute with CPU </span></span>
<span id="cb122-5"><a href="hardware-computing-resources.html#cb122-5" aria-hidden="true" tabindex="-1"></a>  cpu <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> X,</span>
<span id="cb122-6"><a href="hardware-computing-resources.html#cb122-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb122-7"><a href="hardware-computing-resources.html#cb122-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GPU version, GPU pointer to CPU memory (gpuMatrix is simply a pointer)</span></span>
<span id="cb122-8"><a href="hardware-computing-resources.html#cb122-8" aria-hidden="true" tabindex="-1"></a>  gpu1_pointer <span class="ot">&lt;-</span> <span class="fu">t</span>(gpuX) <span class="sc">%*%</span> gpuX,</span>
<span id="cb122-9"><a href="hardware-computing-resources.html#cb122-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb122-10"><a href="hardware-computing-resources.html#cb122-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># GPU version, in GPU memory (vclMatrix formation is a memory transfer)</span></span>
<span id="cb122-11"><a href="hardware-computing-resources.html#cb122-11" aria-hidden="true" tabindex="-1"></a>  gpu2_memory <span class="ot">&lt;-</span> <span class="fu">t</span>(vclX) <span class="sc">%*%</span> vclX,</span>
<span id="cb122-12"><a href="hardware-computing-resources.html#cb122-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb122-13"><a href="hardware-computing-resources.html#cb122-13" aria-hidden="true" tabindex="-1"></a><span class="at">check =</span> <span class="cn">FALSE</span>, <span class="at">memory =</span> <span class="cn">FALSE</span>, <span class="at">min_iterations =</span> <span class="dv">20</span>))</span></code></pre></div>
<pre><code>## # A tibble: 3 x 6
##   expression                            min   median
##   &lt;bch:expr&gt;                       &lt;bch:tm&gt; &lt;bch:tm&gt;
## 1 cpu &lt;- t(X) %*% X                 69.08ms   71.1ms
## 2 gpu1_pointer &lt;- t(gpuX) %*% gpuX  31.89ms   32.6ms
## 3 gpu2_memory &lt;- t(vclX) %*% vclX    9.92ms     15ms
## # … with 3 more variables: itr/sec &lt;dbl&gt;,
## #   mem_alloc &lt;bch:byt&gt;, gc/sec &lt;dbl&gt;</code></pre>
<p>The performance comparison is visualized with boxplots.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="hardware-computing-resources.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gpu_cpu, <span class="at">type =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<p><img src="bigdata_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="resource-allocation" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Resource allocation</h2>
<p>When optimizing the performance of an analytics program processing large amounts of data, it is useful to differentiate between the efficient allocation of computational (CPU) power, and the allocation of RAM (and mass storage).<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> Below, we will look at both aspects in turn.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="11">
<li id="fn11"><p>Note that while these examples are easy to implement and run, setting up a GPU for scientific computing still can involve many steps and some knowledge of your computer’s system. The examples presuppose that all installation and configuration steps (GPU drivers, CUDA, etc.) have already been completed successfully.<a href="hardware-computing-resources.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>As with the setting up of GPUs on your machine in general, installing all prerequisites to make <code>gpuR</code> work on your local machine can be a bit of work and can depend a lot on your system.<a href="hardware-computing-resources.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>If we instruct the GPU to use the own memory, but the data does not fit in it, the program will result in an error.<a href="hardware-computing-resources.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>In many data analysis tasks the two are, of course, intertwined. However, keeping both aspects in mind when optimizing an analytics program helps to choose the right tools.<a href="hardware-computing-resources.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="software-programming-with-big-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distributed-systems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bigdata.pdf", "bigdata.html", "bigdata.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
