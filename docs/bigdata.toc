\contentsline {fm}{List of Figures}{v}{chapter*.1}%
\contentsline {fm}{List of Tables}{vii}{chapter*.2}%
\contentsline {fm}{Preface}{ix}{chapter*.3}%
\contentsline {part}{I\hspace {1em}Setting the Scene: Analyzing Big Data}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}What is \emph {big} in ``Big Data''?}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Approaches to analyzing Big Data}{5}{section.1.2}%
\contentsline {section}{\numberline {1.3}Content overview}{8}{section.1.3}%
\contentsline {chapter}{\numberline {2}Two domains of Big Data Analytics}{11}{chapter.2}%
\contentsline {section}{\numberline {2.1}A practical \emph {big P} problem}{11}{section.2.1}%
\contentsline {section}{\numberline {2.2}A practical \emph {big N} problem}{17}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}OLS as a point of reference}{17}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}The \emph {Uluru} algorithm as an alternative to OLS}{19}{subsection.2.2.2}%
\contentsline {section}{\numberline {2.3}Conclusion}{24}{section.2.3}%
\contentsline {part}{II\hspace {1em}Platform: Software and Computing Resources}{25}{part.2}%
\contentsline {chapter}{\numberline {3}Software: Programming with (Big) Data}{27}{chapter.3}%
\contentsline {section}{\numberline {3.1}Domains of programming with (big) data}{28}{section.3.1}%
\contentsline {section}{\numberline {3.2}Measuring R performance}{29}{section.3.2}%
\contentsline {section}{\numberline {3.3}Writing efficient R code}{35}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Memory allocation and growing objects}{35}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Vectorization in basic R functions}{38}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}\texttt {apply}-type functions and vectorization}{40}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Avoid unnecessary copying}{43}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5}Releasing memory}{45}{subsection.3.3.5}%
\contentsline {subsection}{\numberline {3.3.6}Beyond R}{46}{subsection.3.3.6}%
\contentsline {section}{\numberline {3.4}SQL basics}{48}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}First steps in SQL(ite)}{50}{subsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.1.1}Simple queries}{53}{subsubsection.3.4.1.1}%
\contentsline {subsection}{\numberline {3.4.2}Joins}{53}{subsection.3.4.2}%
\contentsline {chapter}{\numberline {4}Hardware: Computing Resources}{57}{chapter.4}%
\contentsline {section}{\numberline {4.1}Components of a standard computing environment}{57}{section.4.1}%
\contentsline {section}{\numberline {4.2}Mass storage}{59}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Avoid redundancies}{59}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Data compression}{62}{subsection.4.2.2}%
\contentsline {section}{\numberline {4.3}Random access memory (RAM)}{65}{section.4.3}%
\contentsline {section}{\numberline {4.4}Combining RAM and hard disk: virtual memory}{66}{section.4.4}%
\contentsline {section}{\numberline {4.5}CPU and parallelization}{68}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Naive multi-session approach}{70}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Multi-core and multi-node approach}{71}{subsection.4.5.2}%
\contentsline {subsubsection}{\numberline {4.5.2.1}Parallel for-loops using socket}{71}{subsubsection.4.5.2.1}%
\contentsline {subsubsection}{\numberline {4.5.2.2}Parallel lapply using forking}{72}{subsubsection.4.5.2.2}%
\contentsline {section}{\numberline {4.6}GPUs for scientific computing}{74}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}GPUs in R}{75}{subsection.4.6.1}%
\contentsline {subsubsection}{\numberline {4.6.1.1}GPU computing example: Matrix multiplication comparison (\texttt {gpuR})}{75}{subsubsection.4.6.1.1}%
\contentsline {section}{\numberline {4.7}The road ahead: Hardware made for machine learning}{78}{section.4.7}%
\contentsline {section}{\numberline {4.8}Insufficient computing resources?}{79}{section.4.8}%
\contentsline {chapter}{\numberline {5}Distributed Systems}{81}{chapter.5}%
\contentsline {section}{\numberline {5.1}MapReduce}{82}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Map/Reduce Concept Illustrated in R}{83}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Mapper}{84}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Reducer}{86}{subsection.5.1.3}%
\contentsline {section}{\numberline {5.2}Hadoop}{87}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Hadoop word count example}{88}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Spark}{90}{section.5.3}%
\contentsline {section}{\numberline {5.4}Spark with R}{91}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Data import and summary statistics}{92}{subsection.5.4.1}%
\contentsline {section}{\numberline {5.5}Spark with SQL}{96}{section.5.5}%
\contentsline {section}{\numberline {5.6}Spark with R + SQL}{98}{section.5.6}%
\contentsline {chapter}{\numberline {6}Cloud Computing}{101}{chapter.6}%
\contentsline {section}{\numberline {6.1}Cloud computing basics and platforms}{101}{section.6.1}%
\contentsline {section}{\numberline {6.2}Scaling up in the cloud}{103}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Scaling up with AWS EC2 and R/RStudio}{103}{subsection.6.2.1}%
\contentsline {subsubsection}{\numberline {6.2.1.1}Parallelization with an EC2 instance}{104}{subsubsection.6.2.1.1}%
\contentsline {paragraph}{\numberline {6.2.1.1.1}Preparatory steps}{105}{paragraph.6.2.1.1.1}%
\contentsline {paragraph}{\numberline {6.2.1.1.2}Test parallelized code}{107}{paragraph.6.2.1.1.2}%
\contentsline {subsubsection}{\numberline {6.2.1.2}Scale up and run in parallel}{107}{subsubsection.6.2.1.2}%
\contentsline {subsection}{\numberline {6.2.2}Scaling up with GPUs}{108}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}GPUs on Google Colab}{110}{section.6.3}%
\contentsline {section}{\numberline {6.4}AWS EMR: MapReduce in the cloud}{111}{section.6.4}%
\contentsline {part}{III\hspace {1em}Applied Big Data Analytics}{117}{part.3}%
\contentsline {chapter}{\numberline {7}Forms of Big Data and the Data Pipeline}{121}{chapter.7}%
\contentsline {section}{\numberline {7.1}Unstructured, semi-structured, structured data}{121}{section.7.1}%
\contentsline {section}{\numberline {7.2}Data pipelines: a systematic approach to processing big data}{121}{section.7.2}%
\contentsline {chapter}{\numberline {8}Data Collection and Data Storage}{123}{chapter.8}%
\contentsline {section}{\numberline {8.1}Gathering and compilation of raw data}{123}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}NYC taxi data}{123}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Data import and memory allocation}{125}{section.8.2}%
\contentsline {section}{\numberline {8.3}Efficient local data storage}{131}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}RDBMS basics}{131}{subsection.8.3.1}%
\contentsline {subsection}{\numberline {8.3.2}Efficient data access: indices and joins in SQLite}{132}{subsection.8.3.2}%
\contentsline {section}{\numberline {8.4}Connecting R to RDBMS}{136}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Creating a new database with \texttt {RSQLite}}{136}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}Importing data}{136}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}Issue queries}{137}{subsection.8.4.3}%
\contentsline {section}{\numberline {8.5}Cloud solutions for (big) data storage}{138}{section.8.5}%
\contentsline {subsection}{\numberline {8.5.1}Easy-to-use RDBMS in the cloud: AWS RDS}{138}{subsection.8.5.1}%
\contentsline {subsection}{\numberline {8.5.2}Database server in the cloud: MariaDB on an EC2 instance}{142}{subsection.8.5.2}%
\contentsline {subsubsection}{\numberline {8.5.2.1}Data import}{144}{subsubsection.8.5.2.1}%
\contentsline {chapter}{\numberline {9}Big Data Cleaning and Transformation}{149}{chapter.9}%
\contentsline {section}{\numberline {9.1}`Out-of-memory' strategies}{149}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Chunking data with the \texttt {ff}-package}{150}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Memory mapping with \texttt {bigmemory}}{151}{subsection.9.1.2}%
\contentsline {section}{\numberline {9.2}Typical cleaning tasks}{153}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Data Preparation with \texttt {ff}}{154}{subsection.9.2.1}%
\contentsline {subsubsection}{\numberline {9.2.1.1}Set up}{154}{subsubsection.9.2.1.1}%
\contentsline {subsubsection}{\numberline {9.2.1.2}Data import}{155}{subsubsection.9.2.1.2}%
\contentsline {subsubsection}{\numberline {9.2.1.3}Inspect imported files}{157}{subsubsection.9.2.1.3}%
\contentsline {subsubsection}{\numberline {9.2.1.4}Data cleaning and transformation}{158}{subsubsection.9.2.1.4}%
\contentsline {subsubsection}{\numberline {9.2.1.5}Subsetting}{161}{subsubsection.9.2.1.5}%
\contentsline {subsubsection}{\numberline {9.2.1.6}Save/load/export ffdf-files}{161}{subsubsection.9.2.1.6}%
\contentsline {chapter}{\numberline {10}Descriptive Statistics and Aggregation}{167}{chapter.10}%
\contentsline {section}{\numberline {10.1}Data aggregation: The `split-apply-combine' strategy}{167}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}Data aggregation with chunked data files}{167}{subsection.10.1.1}%
\contentsline {subsubsection}{\numberline {10.1.1.1}Data import}{168}{subsubsection.10.1.1.1}%
\contentsline {subsubsection}{\numberline {10.1.1.2}Aggregation with split-apply-combine}{170}{subsubsection.10.1.1.2}%
\contentsline {subsection}{\numberline {10.1.2}Cross-tabulation of \texttt {ff} vectors}{173}{subsection.10.1.2}%
\contentsline {section}{\numberline {10.2}High-speed in-memory data aggregation with \texttt {data.table}}{175}{section.10.2}%
\contentsline {subsubsection}{\numberline {10.2.0.1}Data import}{175}{subsubsection.10.2.0.1}%
\contentsline {subsubsection}{\numberline {10.2.0.2}Data preparation}{175}{subsubsection.10.2.0.2}%
\contentsline {subsubsection}{\numberline {10.2.0.3}\texttt {data.table}-syntax for `split-apply-combine' operations}{176}{subsubsection.10.2.0.3}%
\contentsline {chapter}{\numberline {11}(Big) Data Visualization}{179}{chapter.11}%
\contentsline {section}{\numberline {11.1}Data exploration with \texttt {ggplot2}}{179}{section.11.1}%
\contentsline {section}{\numberline {11.2}Excursus: modify and create themes}{185}{section.11.2}%
\contentsline {subsection}{\numberline {11.2.1}Create your own theme: simple approach}{186}{subsection.11.2.1}%
\contentsline {subsection}{\numberline {11.2.2}Implementing actual themes as functions.}{188}{subsection.11.2.2}%
\contentsline {section}{\numberline {11.3}Visualize Time and Space}{189}{section.11.3}%
\contentsline {subsection}{\numberline {11.3.1}Preparations}{189}{subsection.11.3.1}%
\contentsline {subsection}{\numberline {11.3.2}Pick-up and drop-off locations}{191}{subsection.11.3.2}%
\contentsline {section}{\numberline {11.4}Excursus: change color schemes}{195}{section.11.4}%
\contentsline {chapter}{\numberline {12}Bottle Necks in Local Big Data Analytics}{199}{chapter.12}%
\contentsline {section}{\numberline {12.1}Case study: Data Import and Memory Allocation}{199}{section.12.1}%
\contentsline {section}{\numberline {12.2}Case Study: Loops, Memory, and Vectorization}{204}{section.12.2}%
\contentsline {subsection}{\numberline {12.2.1}Preparation}{204}{subsection.12.2.1}%
\contentsline {subsection}{\numberline {12.2.2}Naïve Approach (ignorant of R)}{205}{subsection.12.2.2}%
\contentsline {subsection}{\numberline {12.2.3}Improvement 1: Pre-allocation of memory}{207}{subsection.12.2.3}%
\contentsline {subsection}{\numberline {12.2.4}Improvement 2: Exploit vectorization}{209}{subsection.12.2.4}%
\contentsline {section}{\numberline {12.3}Case study: Bootstrapping and Parallel Processing}{211}{section.12.3}%
\contentsline {subsection}{\numberline {12.3.1}Parallelization with an EC2 instance}{216}{subsection.12.3.1}%
\contentsline {section}{\numberline {12.4}Case Study: Efficient Fixed Effects Estimation}{220}{section.12.4}%
\contentsline {chapter}{\numberline {13}GPUs and Machine Learning}{227}{chapter.13}%
\contentsline {section}{\numberline {13.1}Tensorflow/Keras example: predict housing prices}{227}{section.13.1}%
\contentsline {section}{\numberline {13.2}Data preparation}{229}{section.13.2}%
\contentsline {section}{\numberline {13.3}Model specification}{232}{section.13.3}%
\contentsline {section}{\numberline {13.4}Training and prediction}{233}{section.13.4}%
\contentsline {subsection}{\numberline {13.4.1}A word of caution}{233}{subsection.13.4.1}%
\contentsline {part}{IV\hspace {1em}Application: Topics in Big Data Econometrics}{235}{part.4}%
\contentsline {chapter}{\numberline {14}Regression Analysis and Categorization with Spark and R}{237}{chapter.14}%
\contentsline {section}{\numberline {14.1}Simple regression analysis}{237}{section.14.1}%
\contentsline {section}{\numberline {14.2}Machine learning for classification}{241}{section.14.2}%
\contentsline {section}{\numberline {14.3}Building machine learning pipelines with R and Spark}{244}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}Set up and data import}{245}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Building the pipeline}{245}{subsection.14.3.2}%
\contentsline {chapter}{\numberline {15}Large-scale Text Analysis with sparklyr}{249}{chapter.15}%
\contentsline {section}{\numberline {15.1}Getting started: import, preparation, and word frequencies}{249}{section.15.1}%
\contentsline {chapter}{Appendix}{253}{section.15.1}%
\contentsline {chapter}{Appendix A}{253}{appendix*.29}%
\contentsline {section}{\numberline {.1}GitHub}{253}{section.Alph0.1}%
\contentsline {subsection}{\numberline {.1.1}Initiate a new repository}{253}{subsection.Alph0.1.1}%
\contentsline {subsection}{\numberline {.1.2}Clone this course's repository}{254}{subsection.Alph0.1.2}%
\contentsline {subsection}{\numberline {.1.3}Fork this course's repository}{254}{subsection.Alph0.1.3}%
\contentsline {chapter}{Appendix B}{257}{appendix*.30}%
\contentsline {section}{\numberline {.2}Data types and memory/storage}{257}{section.Alph0.2}%
\contentsline {subsection}{\numberline {.2.1}Example in R: Data types and information storage}{258}{subsection.Alph0.2.1}%
\contentsline {section}{\numberline {.3}Data structures}{260}{section.Alph0.3}%
\contentsline {subsection}{\numberline {.3.1}Vectors vs Factors in R}{261}{subsection.Alph0.3.1}%
\contentsline {subsection}{\numberline {.3.2}Matrices/Arrays}{262}{subsection.Alph0.3.2}%
\contentsline {subsection}{\numberline {.3.3}Data frames, tibbles, and data tables}{263}{subsection.Alph0.3.3}%
\contentsline {subsection}{\numberline {.3.4}Lists}{264}{subsection.Alph0.3.4}%
\contentsline {section}{\numberline {.4}R-tools to investigate structures and types}{265}{section.Alph0.4}%
\contentsline {chapter}{Appendix C}{267}{appendix*.31}%
\contentsline {section}{\numberline {.5}Install Hadoop (on Ubuntu Linux)}{267}{section.Alph0.5}%
