<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Data Collection and Data Storage | Big Data Analytics</title>
  <meta name="description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Data Collection and Data Storage | Big Data Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://umatter.github.io/BigData/img/cover.jpg" />
  <meta property="og:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="github-repo" content="umatter/BigData" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Data Collection and Data Storage | Big Data Analytics" />
  
  <meta name="twitter:description" content="A guide to data science practitioners making the transition to Big Data." />
  <meta name="twitter:image" content="https://umatter.github.io/BigData/img/cover.jpg" />

<meta name="author" content="Ulrich Matter" />


<meta name="date" content="2023-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="big-data-cleaning-and-transformation.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#background-and-goals-of-this-book"><i class="fa fa-check"></i>Background and goals of this book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#a-moving-target"><i class="fa fa-check"></i>A moving target</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#content-and-organization-of-the-book"><i class="fa fa-check"></i>Content and organization of the book</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#prerequisits-and-requirements"><i class="fa fa-check"></i>Prerequisits and requirements</a></li>
<li class="chapter" data-level="" data-path="c.html"><a href="c.html#thanks"><i class="fa fa-check"></i>Thanks</a></li>
</ul></li>
<li class="part"><span><b>I Setting the Scene: Analyzing Big Data</b></span></li>
<li class="chapter" data-level="" data-path="s.html"><a href="s.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="what-is-big-in-big-data.html"><a href="what-is-big-in-big-data.html"><i class="fa fa-check"></i><b>1</b> What is <em>Big</em> in “Big Data”?</a></li>
<li class="chapter" data-level="2" data-path="approaches-to-analyzing-big-data.html"><a href="approaches-to-analyzing-big-data.html"><i class="fa fa-check"></i><b>2</b> Approaches to Analyzing Big Data</a></li>
<li class="chapter" data-level="3" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html"><i class="fa fa-check"></i><b>3</b> The Two Domains of Big Data Analytics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-p-problem"><i class="fa fa-check"></i><b>3.1</b> A practical <em>big P</em> problem </a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#simple-logistig-regression-naive-approach"><i class="fa fa-check"></i><b>3.1.1</b> Simple logistig regression (naive approach)</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#regularization-the-lasso-estimator"><i class="fa fa-check"></i><b>3.1.2</b> Regularization: the lasso estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#a-practical-big-n-problem"><i class="fa fa-check"></i><b>3.2</b> A practical <em>big N</em> problem </a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#ols-as-a-point-of-reference"><i class="fa fa-check"></i><b>3.2.1</b> OLS as a point of reference </a></li>
<li class="chapter" data-level="3.2.2" data-path="the-two-domains-of-big-data-analytics.html"><a href="the-two-domains-of-big-data-analytics.html#the-uluru-algorithm-as-an-alternative-to-ols"><i class="fa fa-check"></i><b>3.2.2</b> The <em>Uluru</em> algorithm as an alternative to OLS </a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Platform: Software and Computing Resources</b></span></li>
<li class="chapter" data-level="" data-path="p.html"><a href="p.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html"><i class="fa fa-check"></i><b>4</b> Software: Programming with (Big) Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#domains-of-programming-with-big-data"><i class="fa fa-check"></i><b>4.1</b> Domains of programming with (big) data</a></li>
<li class="chapter" data-level="4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#measuring-r-performance"><i class="fa fa-check"></i><b>4.2</b> Measuring R performance</a></li>
<li class="chapter" data-level="4.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#writing-efficient-r-code"><i class="fa fa-check"></i><b>4.3</b> Writing efficient R code</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#memory-allocation-and-growing-objects"><i class="fa fa-check"></i><b>4.3.1</b> Memory allocation and growing objects</a></li>
<li class="chapter" data-level="4.3.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#vectorization-in-basic-r-functions"><i class="fa fa-check"></i><b>4.3.2</b> Vectorization in basic R functions</a></li>
<li class="chapter" data-level="4.3.3" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#apply-type-functions-and-vectorization"><i class="fa fa-check"></i><b>4.3.3</b> <code>apply</code>-type functions and vectorization</a></li>
<li class="chapter" data-level="4.3.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#avoid-unnecessary-copying"><i class="fa fa-check"></i><b>4.3.4</b> Avoid unnecessary copying</a></li>
<li class="chapter" data-level="4.3.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#releasing-memory"><i class="fa fa-check"></i><b>4.3.5</b> Releasing memory</a></li>
<li class="chapter" data-level="4.3.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#beyond-r"><i class="fa fa-check"></i><b>4.3.6</b> Beyond R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#sql-basics"><i class="fa fa-check"></i><b>4.4</b> SQL basics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#first-steps-in-sqlite"><i class="fa fa-check"></i><b>4.4.1</b> First steps in SQL(ite)</a></li>
<li class="chapter" data-level="4.4.2" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#joins"><i class="fa fa-check"></i><b>4.4.2</b> Joins</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#with-a-little-help-from-my-friends-gpt-and-rsql-coding"><i class="fa fa-check"></i><b>4.5</b> With a little help from my friends: GPT and R/SQL coding</a></li>
<li class="chapter" data-level="4.6" data-path="software-programming-with-big-data.html"><a href="software-programming-with-big-data.html#wrapping-up"><i class="fa fa-check"></i><b>4.6</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html"><i class="fa fa-check"></i><b>5</b> Hardware: Computing Resources</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#mass-storage"><i class="fa fa-check"></i><b>5.1</b> Mass storage</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#avoid-redundancies"><i class="fa fa-check"></i><b>5.1.1</b> Avoid redundancies</a></li>
<li class="chapter" data-level="5.1.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#data-compression"><i class="fa fa-check"></i><b>5.1.2</b> Data compression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#random-access-memory-ram"><i class="fa fa-check"></i><b>5.2</b> Random access memory (RAM)</a></li>
<li class="chapter" data-level="5.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#combining-ram-and-hard-disk-virtual-memory"><i class="fa fa-check"></i><b>5.3</b> Combining RAM and hard disk: Virtual memory</a></li>
<li class="chapter" data-level="5.4" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#cpu-and-parallelization"><i class="fa fa-check"></i><b>5.4</b> CPU and parallelization</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#naive-multi-session-approach"><i class="fa fa-check"></i><b>5.4.1</b> Naive multi-session approach</a></li>
<li class="chapter" data-level="5.4.2" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-session-approach-with-futures"><i class="fa fa-check"></i><b>5.4.2</b> Multi-session approach with futures</a></li>
<li class="chapter" data-level="5.4.3" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#multi-core-and-multi-node-approach"><i class="fa fa-check"></i><b>5.4.3</b> Multi-core and multi-node approach</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-for-scientific-computing"><i class="fa fa-check"></i><b>5.5</b> GPUs for scientific computing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#gpus-in-r"><i class="fa fa-check"></i><b>5.5.1</b> GPUs in R</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#the-road-ahead-hardware-made-for-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The road ahead: Hardware made for machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#wrapping-up-1"><i class="fa fa-check"></i><b>5.7</b> Wrapping up</a></li>
<li class="chapter" data-level="5.8" data-path="hardware-computing-resources.html"><a href="hardware-computing-resources.html#still-have-insufficient-computing-resources"><i class="fa fa-check"></i><b>5.8</b> Still have insufficient computing resources?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributed-systems.html"><a href="distributed-systems.html"><i class="fa fa-check"></i><b>6</b> Distributed Systems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributed-systems.html"><a href="distributed-systems.html#mapreduce"><i class="fa fa-check"></i><b>6.1</b> MapReduce</a></li>
<li class="chapter" data-level="6.2" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-hadoop"><i class="fa fa-check"></i><b>6.2</b> Apache Hadoop</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributed-systems.html"><a href="distributed-systems.html#hadoop-word-count-example"><i class="fa fa-check"></i><b>6.2.1</b> Hadoop word count example</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributed-systems.html"><a href="distributed-systems.html#apache-spark"><i class="fa fa-check"></i><b>6.3</b> Apache Spark</a></li>
<li class="chapter" data-level="6.4" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r"><i class="fa fa-check"></i><b>6.4</b> Spark with R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="distributed-systems.html"><a href="distributed-systems.html#data-import-and-summary-statistics"><i class="fa fa-check"></i><b>6.4.1</b> Data import and summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-sql"><i class="fa fa-check"></i><b>6.5</b> Spark with SQL</a></li>
<li class="chapter" data-level="6.6" data-path="distributed-systems.html"><a href="distributed-systems.html#spark-with-r-sql"><i class="fa fa-check"></i><b>6.6</b> Spark with R + SQL</a></li>
<li class="chapter" data-level="6.7" data-path="distributed-systems.html"><a href="distributed-systems.html#wrapping-up-2"><i class="fa fa-check"></i><b>6.7</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cloud-computing.html"><a href="cloud-computing.html"><i class="fa fa-check"></i><b>7</b> Cloud Computing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cloud-computing.html"><a href="cloud-computing.html#cloud-computing-basics-and-platforms"><i class="fa fa-check"></i><b>7.1</b> Cloud computing basics and platforms</a></li>
<li class="chapter" data-level="7.2" data-path="cloud-computing.html"><a href="cloud-computing.html#transitioning-to-the-cloud"><i class="fa fa-check"></i><b>7.2</b> Transitioning to the cloud</a></li>
<li class="chapter" data-level="7.3" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-in-the-cloud-virtual-servers"><i class="fa fa-check"></i><b>7.3</b> Scaling up in the cloud: Virtual servers</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cloud-computing.html"><a href="cloud-computing.html#parallelization-with-an-ec2-instance"><i class="fa fa-check"></i><b>7.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-up-with-gpus"><i class="fa fa-check"></i><b>7.4</b> Scaling up with GPUs</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cloud-computing.html"><a href="cloud-computing.html#gpus-on-google-colab"><i class="fa fa-check"></i><b>7.4.1</b> GPUs on Google Colab</a></li>
<li class="chapter" data-level="7.4.2" data-path="cloud-computing.html"><a href="cloud-computing.html#rstudio-and-ec2-with-gpus-on-aws"><i class="fa fa-check"></i><b>7.4.2</b> RStudio and EC2 with GPUs on AWS</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cloud-computing.html"><a href="cloud-computing.html#scaling-out-mapreduce-in-the-cloud"><i class="fa fa-check"></i><b>7.5</b> Scaling out: MapReduce in the cloud</a></li>
<li class="chapter" data-level="7.6" data-path="cloud-computing.html"><a href="cloud-computing.html#wrapping-up-3"><i class="fa fa-check"></i><b>7.6</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>III Components of Big Data Analytics</b></span></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html"><i class="fa fa-check"></i><b>8</b> Data Collection and Data Storage</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data"><i class="fa fa-check"></i><b>8.1</b> Gathering and compilation of raw data</a></li>
<li class="chapter" data-level="8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#stackcombine-raw-source-files"><i class="fa fa-check"></i><b>8.2</b> Stack/combine raw source files</a></li>
<li class="chapter" data-level="8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-local-data-storage"><i class="fa fa-check"></i><b>8.3</b> Efficient local data storage</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#rdbms-basics"><i class="fa fa-check"></i><b>8.3.1</b> RDBMS basics</a></li>
<li class="chapter" data-level="8.3.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite"><i class="fa fa-check"></i><b>8.3.2</b> Efficient data access: Indices and joins in SQLite</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#connecting-r-to-an-rdbms"><i class="fa fa-check"></i><b>8.4</b> Connecting R to an RDBMS</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite"><i class="fa fa-check"></i><b>8.4.1</b> Creating a new database with <code>RSQLite</code></a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#importing-data"><i class="fa fa-check"></i><b>8.4.2</b> Importing data</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#issue-queries"><i class="fa fa-check"></i><b>8.4.3</b> Issue queries</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage"><i class="fa fa-check"></i><b>8.5</b> Cloud solutions for (big) data storage</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds"><i class="fa fa-check"></i><b>8.5.1</b> Easy-to-use RDBMS in the cloud: AWS RDS</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#column-based-analytics-databases"><i class="fa fa-check"></i><b>8.6</b> Column-based analytics databases</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#installation-and-start-up"><i class="fa fa-check"></i><b>8.6.1</b> Installation and start up</a></li>
<li class="chapter" data-level="8.6.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#first-steps-via-druids-gui"><i class="fa fa-check"></i><b>8.6.2</b> First steps via Druid’s GUI</a></li>
<li class="chapter" data-level="8.6.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#query-druid-from-r"><i class="fa fa-check"></i><b>8.6.3</b> Query Druid from R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouses"><i class="fa fa-check"></i><b>8.7</b> Data warehouses</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example"><i class="fa fa-check"></i><b>8.7.1</b> Data warehouse for analytics: Google BigQuery example</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service"><i class="fa fa-check"></i><b>8.8</b> Data lakes and simple storage service</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps"><i class="fa fa-check"></i><b>8.8.1</b> AWS S3 with R: First steps</a></li>
<li class="chapter" data-level="8.8.2" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#uploading-data-to-s3"><i class="fa fa-check"></i><b>8.8.2</b> Uploading data to S3</a></li>
<li class="chapter" data-level="8.8.3" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-amazon-athena"><i class="fa fa-check"></i><b>8.8.3</b> More than just simple storage: S3 + Amazon Athena</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="data-collection-and-data-storage.html"><a href="data-collection-and-data-storage.html#wrapping-up-4"><i class="fa fa-check"></i><b>8.9</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html"><i class="fa fa-check"></i><b>9</b> Big Data Cleaning and Transformation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#out-of-memory-strategies-and-lazy-evaluation-practical-basics"><i class="fa fa-check"></i><b>9.1</b> Out-of-memory strategies and lazy evaluation: Practical basics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#chunking-data-with-the-ff-package"><i class="fa fa-check"></i><b>9.1.1</b> Chunking data with the <code>ff</code> package</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#memory-mapping-with-bigmemory"><i class="fa fa-check"></i><b>9.1.2</b> Memory mapping with <code>bigmemory</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#connecting-to-apache-arrow"><i class="fa fa-check"></i><b>9.1.3</b> Connecting to Apache Arrow</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-ff"><i class="fa fa-check"></i><b>9.2</b> Big Data preparation tutorial with <code>ff</code></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#set-up"><i class="fa fa-check"></i><b>9.2.1</b> Set up</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-import"><i class="fa fa-check"></i><b>9.2.2</b> Data import</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-imported-files"><i class="fa fa-check"></i><b>9.2.3</b> Inspect imported files</a></li>
<li class="chapter" data-level="9.2.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#data-cleaning-and-transformation"><i class="fa fa-check"></i><b>9.2.4</b> Data cleaning and transformation</a></li>
<li class="chapter" data-level="9.2.5" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#inspect-difference-to-in-memory-operation"><i class="fa fa-check"></i><b>9.2.5</b> Inspect difference to in-memory operation</a></li>
<li class="chapter" data-level="9.2.6" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#subsetting"><i class="fa fa-check"></i><b>9.2.6</b> Subsetting</a></li>
<li class="chapter" data-level="9.2.7" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#saveloadexport-ff-files"><i class="fa fa-check"></i><b>9.2.7</b> Save/load/export <code>ff</code> files</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#big-data-preparation-tutorial-with-arrow"><i class="fa fa-check"></i><b>9.3</b> Big Data preparation tutorial with <code>arrow</code></a></li>
<li class="chapter" data-level="9.4" data-path="big-data-cleaning-and-transformation.html"><a href="big-data-cleaning-and-transformation.html#wrapping-up-5"><i class="fa fa-check"></i><b>9.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html"><i class="fa fa-check"></i><b>10</b> Descriptive Statistics and Aggregation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-the-split-apply-combine-strategy"><i class="fa fa-check"></i><b>10.1</b> Data aggregation: The ‘split-apply-combine’ strategy</a></li>
<li class="chapter" data-level="10.2" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#data-aggregation-with-chunked-data-files"><i class="fa fa-check"></i><b>10.2</b> Data aggregation with chunked data files</a></li>
<li class="chapter" data-level="10.3" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-arrow"><i class="fa fa-check"></i><b>10.3</b> High-speed in-memory data aggregation with <code>arrow</code></a></li>
<li class="chapter" data-level="10.4" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#high-speed-in-memory-data-aggregation-with-data.table"><i class="fa fa-check"></i><b>10.4</b> High-speed in-memory data aggregation with <code>data.table</code></a></li>
<li class="chapter" data-level="10.5" data-path="descriptive-statistics-and-aggregation.html"><a href="descriptive-statistics-and-aggregation.html#wrapping-up-6"><i class="fa fa-check"></i><b>10.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="big-data-visualization.html"><a href="big-data-visualization.html"><i class="fa fa-check"></i><b>11</b> (Big) Data Visualization</a>
<ul>
<li class="chapter" data-level="11.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#challenges-of-big-data-visualization"><i class="fa fa-check"></i><b>11.1</b> Challenges of Big Data visualization</a></li>
<li class="chapter" data-level="11.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#data-exploration-with-ggplot2"><i class="fa fa-check"></i><b>11.2</b> Data exploration with <code>ggplot2</code></a></li>
<li class="chapter" data-level="11.3" data-path="big-data-visualization.html"><a href="big-data-visualization.html#visualizing-time-and-space"><i class="fa fa-check"></i><b>11.3</b> Visualizing time and space</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="big-data-visualization.html"><a href="big-data-visualization.html#preparations"><i class="fa fa-check"></i><b>11.3.1</b> Preparations</a></li>
<li class="chapter" data-level="11.3.2" data-path="big-data-visualization.html"><a href="big-data-visualization.html#pick-up-and-drop-off-locations"><i class="fa fa-check"></i><b>11.3.2</b> Pick-up and drop-off locations</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="big-data-visualization.html"><a href="big-data-visualization.html#wrapping-up-7"><i class="fa fa-check"></i><b>11.4</b> Wrapping up</a></li>
</ul></li>
<li class="part"><span><b>IV Application: Topics in Big Data Econometrics</b></span></li>
<li class="chapter" data-level="" data-path="a.html"><a href="a.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="12" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html"><i class="fa fa-check"></i><b>12</b> Bottlenecks in Everyday Data Analytics Tasks</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-efficient-fixed-effects-estimation"><i class="fa fa-check"></i><b>12.1</b> Case study: Efficient fixed effects estimation</a></li>
<li class="chapter" data-level="12.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-loops-memory-and-vectorization"><i class="fa fa-check"></i><b>12.2</b> Case study: Loops, memory, and vectorization</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#naïve-approach-ignorant-of-r"><i class="fa fa-check"></i><b>12.2.1</b> Naïve approach (ignorant of R)</a></li>
<li class="chapter" data-level="12.2.2" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-1-pre-allocation-of-memory"><i class="fa fa-check"></i><b>12.2.2</b> Improvement 1: Pre-allocation of memory</a></li>
<li class="chapter" data-level="12.2.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#improvement-2-exploit-vectorization"><i class="fa fa-check"></i><b>12.2.3</b> Improvement 2: Exploit vectorization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#case-study-bootstrapping-and-parallel-processing"><i class="fa fa-check"></i><b>12.3</b> Case study: Bootstrapping and parallel processing</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bottlenecks-in-everyday-data-analytics-tasks.html"><a href="bottlenecks-in-everyday-data-analytics-tasks.html#parallelization-with-an-ec2-instance-1"><i class="fa fa-check"></i><b>12.3.1</b> Parallelization with an EC2 instance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html"><i class="fa fa-check"></i><b>13</b> Econometrics with GPUs</a>
<ul>
<li class="chapter" data-level="13.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#ols-on-gpus"><i class="fa fa-check"></i><b>13.1</b> OLS on GPUs</a></li>
<li class="chapter" data-level="13.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#a-word-of-caution"><i class="fa fa-check"></i><b>13.2</b> A word of caution</a></li>
<li class="chapter" data-level="13.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#higher-level-interfaces-for-basic-econometrics-with-gpus"><i class="fa fa-check"></i><b>13.3</b> Higher-level interfaces for basic econometrics with GPUs</a></li>
<li class="chapter" data-level="13.4" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#tensorflowkeras-example-predict-housing-prices"><i class="fa fa-check"></i><b>13.4</b> TensorFlow/Keras example: predict housing prices</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#data-preparation"><i class="fa fa-check"></i><b>13.4.1</b> Data preparation</a></li>
<li class="chapter" data-level="13.4.2" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#model-specification"><i class="fa fa-check"></i><b>13.4.2</b> Model specification</a></li>
<li class="chapter" data-level="13.4.3" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#training-and-prediction"><i class="fa fa-check"></i><b>13.4.3</b> Training and prediction</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="econometrics-with-gpus.html"><a href="econometrics-with-gpus.html#wrapping-up-8"><i class="fa fa-check"></i><b>13.5</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html"><i class="fa fa-check"></i><b>14</b> Regression Analysis and Categorization with Spark and R</a>
<ul>
<li class="chapter" data-level="14.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#simple-linear-regression-analysis"><i class="fa fa-check"></i><b>14.1</b> Simple linear regression analysis</a></li>
<li class="chapter" data-level="14.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#machine-learning-for-classification"><i class="fa fa-check"></i><b>14.2</b> Machine learning for classification</a></li>
<li class="chapter" data-level="14.3" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-machine-learning-pipelines-with-r-and-spark"><i class="fa fa-check"></i><b>14.3</b> Building machine learning pipelines with R and Spark</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#set-up-and-data-import"><i class="fa fa-check"></i><b>14.3.1</b> Set up and data import</a></li>
<li class="chapter" data-level="14.3.2" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#building-the-pipeline"><i class="fa fa-check"></i><b>14.3.2</b> Building the pipeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="regression-analysis-and-categorization-with-spark-and-r.html"><a href="regression-analysis-and-categorization-with-spark-and-r.html#wrapping-up-9"><i class="fa fa-check"></i><b>14.4</b> Wrapping up</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html"><i class="fa fa-check"></i><b>15</b> Large-scale Text Analysis with sparklyr</a>
<ul>
<li class="chapter" data-level="15.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#getting-started-import-pre-processing-and-word-count"><i class="fa fa-check"></i><b>15.1</b> Getting started: Import, pre-processing, and word count</a></li>
<li class="chapter" data-level="15.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#tutorial-political-slant"><i class="fa fa-check"></i><b>15.2</b> Tutorial: political slant</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#data-download-and-import"><i class="fa fa-check"></i><b>15.2.1</b> Data download and import</a></li>
<li class="chapter" data-level="15.2.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#cleaning-speeches-data"><i class="fa fa-check"></i><b>15.2.2</b> Cleaning speeches data</a></li>
<li class="chapter" data-level="15.2.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#create-a-bigrams-count-per-party"><i class="fa fa-check"></i><b>15.2.3</b> Create a bigrams count per party</a></li>
<li class="chapter" data-level="15.2.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#find-partisan-phrases"><i class="fa fa-check"></i><b>15.2.4</b> Find “partisan” phrases</a></li>
<li class="chapter" data-level="15.2.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#results-most-partisan-phrases-by-congress"><i class="fa fa-check"></i><b>15.2.5</b> Results: most partisan phrases by congress</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#natural-language-processing-at-scale"><i class="fa fa-check"></i><b>15.3</b> Natural Language Processing at Scale</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#preparatory-steps"><i class="fa fa-check"></i><b>15.3.1</b> Preparatory steps</a></li>
<li class="chapter" data-level="15.3.2" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sentiment-annotation"><i class="fa fa-check"></i><b>15.3.2</b> Sentiment annotation</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#aggregation-and-visualization"><i class="fa fa-check"></i><b>15.4</b> Aggregation and visualization</a></li>
<li class="chapter" data-level="15.5" data-path="large-scale-text-analysis-with-sparklyr.html"><a href="large-scale-text-analysis-with-sparklyr.html#sparklyr-and-lazy-evaluation"><i class="fa fa-check"></i><b>15.5</b> <code>sparklyr</code> and lazy evaluation</a></li>
</ul></li>
<li class="part"><span><b>V Appendices</b></span></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html"><i class="fa fa-check"></i>Appendix A: GitHub</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#initiate-a-new-repository"><i class="fa fa-check"></i>Initiate a new repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#clone-this-books-repository"><i class="fa fa-check"></i>Clone this book’s repository</a></li>
<li class="chapter" data-level="" data-path="appendix-a-github.html"><a href="appendix-a-github.html#fork-this-books-repository"><i class="fa fa-check"></i>Fork this book’s repository</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html"><i class="fa fa-check"></i>Appendix B: R Basics</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-types-and-memorystorage"><i class="fa fa-check"></i>Data types and memory/storage</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#example-data-types-and-information-storage"><i class="fa fa-check"></i>Example: Data types and information storage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-structures"><i class="fa fa-check"></i>Data structures</a>
<ul>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#vectors-vs-factors-in-r"><i class="fa fa-check"></i>Vectors vs Factors in R</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#matricesarrays"><i class="fa fa-check"></i>Matrices/Arrays</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#data-frames-tibbles-and-data-tables"><i class="fa fa-check"></i>Data frames, tibbles, and data tables</a></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-b-r-basics.html"><a href="appendix-b-r-basics.html#r-tools-to-investigate-structures-and-types"><i class="fa fa-check"></i>R-tools to investigate structures and types</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-c-install-hadoop.html"><a href="appendix-c-install-hadoop.html"><i class="fa fa-check"></i>Appendix C: Install Hadoop</a></li>
<li class="part"><span><b>VI References and Index</b></span></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://umatter.github.io" target="blank">umatter.github.io</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-collection-and-data-storage" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Data Collection and Data Storage<a href="data-collection-and-data-storage.html#data-collection-and-data-storage" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p></p>
<p>The first steps of a data analytics project typically deal with the question of how to collect, organize, and store the raw data for further processing. In this chapter, we cover several approaches of how to practically implement these steps in the context of observational data, as they commonly occur in applied econometrics and business analytics. Thereby, the focus lies on several important aspects of how to implement these steps locally, and then introduces several useful cloud tools to store and query large amounts of data for analytics purposes.</p>
<div id="gathering-and-compilation-of-raw-data" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Gathering and compilation of raw data<a href="data-collection-and-data-storage.html#gathering-and-compilation-of-raw-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The NYC Taxi &amp; Limousine Commission (TLC) provides detailed data on all trip records, including pick-up and drop-off times/locations. When combining all available trip records from 2009 to 2018, we get a rather large dataset of over 200GB. The code examples below illustrate how to collect and compile the entire dataset. In order to avoid long computing times, the code examples shown below are based on a small sub-set of the actual raw data (however, all examples involving virtual memory are in theory scalable to the extent of the entire raw dataset).</p>
<p>The raw data consists of several monthly Parquet files and can be downloaded via the <a href="https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page">TLC’s website</a>. The following short R script automates the downloading of all available trip-record files. <em>NOTE</em>: Downloading all files can take several hours and will occupy over 200GB!</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="data-collection-and-data-storage.html#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fetch all TLC trip records Data source:</span></span>
<span id="cb199-2"><a href="data-collection-and-data-storage.html#cb199-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page</span></span>
<span id="cb199-3"><a href="data-collection-and-data-storage.html#cb199-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: Monthly Parquet files from urls</span></span>
<span id="cb199-4"><a href="data-collection-and-data-storage.html#cb199-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-5"><a href="data-collection-and-data-storage.html#cb199-5" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP -----------------</span></span>
<span id="cb199-6"><a href="data-collection-and-data-storage.html#cb199-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-7"><a href="data-collection-and-data-storage.html#cb199-7" aria-hidden="true" tabindex="-1"></a><span class="co"># packages</span></span>
<span id="cb199-8"><a href="data-collection-and-data-storage.html#cb199-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(R.utils)  <span class="co"># to create directories from within R</span></span>
<span id="cb199-9"><a href="data-collection-and-data-storage.html#cb199-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-10"><a href="data-collection-and-data-storage.html#cb199-10" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb199-11"><a href="data-collection-and-data-storage.html#cb199-11" aria-hidden="true" tabindex="-1"></a>BASE_URL <span class="ot">&lt;-</span> <span class="st">&quot;https://d37ci6vzurychx.cloudfront.net/trip-data/&quot;</span></span>
<span id="cb199-12"><a href="data-collection-and-data-storage.html#cb199-12" aria-hidden="true" tabindex="-1"></a>FILE <span class="ot">&lt;-</span> <span class="st">&quot;yellow_tripdata_2018-01.parquet&quot;</span></span>
<span id="cb199-13"><a href="data-collection-and-data-storage.html#cb199-13" aria-hidden="true" tabindex="-1"></a>URL <span class="ot">&lt;-</span> <span class="fu">paste0</span>(BASE_URL, FILE)</span>
<span id="cb199-14"><a href="data-collection-and-data-storage.html#cb199-14" aria-hidden="true" tabindex="-1"></a>OUTPUT_PATH <span class="ot">&lt;-</span> <span class="st">&quot;data/tlc_trips/&quot;</span></span>
<span id="cb199-15"><a href="data-collection-and-data-storage.html#cb199-15" aria-hidden="true" tabindex="-1"></a>START_DATE <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">&quot;2009-01-01&quot;</span>)</span>
<span id="cb199-16"><a href="data-collection-and-data-storage.html#cb199-16" aria-hidden="true" tabindex="-1"></a>END_DATE <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">&quot;2018-06-01&quot;</span>)</span>
<span id="cb199-17"><a href="data-collection-and-data-storage.html#cb199-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-18"><a href="data-collection-and-data-storage.html#cb199-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-19"><a href="data-collection-and-data-storage.html#cb199-19" aria-hidden="true" tabindex="-1"></a><span class="co"># BUILD URLS -----------</span></span>
<span id="cb199-20"><a href="data-collection-and-data-storage.html#cb199-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-21"><a href="data-collection-and-data-storage.html#cb199-21" aria-hidden="true" tabindex="-1"></a><span class="co"># parse base url</span></span>
<span id="cb199-22"><a href="data-collection-and-data-storage.html#cb199-22" aria-hidden="true" tabindex="-1"></a>base_url <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;2018-01.parquet&quot;</span>, <span class="st">&quot;&quot;</span>, URL)</span>
<span id="cb199-23"><a href="data-collection-and-data-storage.html#cb199-23" aria-hidden="true" tabindex="-1"></a><span class="co"># build urls</span></span>
<span id="cb199-24"><a href="data-collection-and-data-storage.html#cb199-24" aria-hidden="true" tabindex="-1"></a>dates <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> START_DATE, <span class="at">to =</span> END_DATE, <span class="at">by =</span> <span class="st">&quot;month&quot;</span>)</span>
<span id="cb199-25"><a href="data-collection-and-data-storage.html#cb199-25" aria-hidden="true" tabindex="-1"></a>year_months <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;-01$&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="fu">as.character</span>(dates))</span>
<span id="cb199-26"><a href="data-collection-and-data-storage.html#cb199-26" aria-hidden="true" tabindex="-1"></a>data_urls <span class="ot">&lt;-</span> <span class="fu">paste0</span>(base_url, year_months, <span class="st">&quot;.parquet&quot;</span>)</span>
<span id="cb199-27"><a href="data-collection-and-data-storage.html#cb199-27" aria-hidden="true" tabindex="-1"></a>data_paths <span class="ot">&lt;-</span> <span class="fu">paste0</span>(OUTPUT_PATH, year_months, <span class="st">&quot;.parquet&quot;</span>)</span>
<span id="cb199-28"><a href="data-collection-and-data-storage.html#cb199-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-29"><a href="data-collection-and-data-storage.html#cb199-29" aria-hidden="true" tabindex="-1"></a><span class="co"># FETCH AND STACK CSVS ----------------</span></span>
<span id="cb199-30"><a href="data-collection-and-data-storage.html#cb199-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-31"><a href="data-collection-and-data-storage.html#cb199-31" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdirs</span>(OUTPUT_PATH)</span>
<span id="cb199-32"><a href="data-collection-and-data-storage.html#cb199-32" aria-hidden="true" tabindex="-1"></a><span class="co"># download all csvs in the data range</span></span>
<span id="cb199-33"><a href="data-collection-and-data-storage.html#cb199-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(data_urls)) {</span>
<span id="cb199-34"><a href="data-collection-and-data-storage.html#cb199-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-35"><a href="data-collection-and-data-storage.html#cb199-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># download to disk</span></span>
<span id="cb199-36"><a href="data-collection-and-data-storage.html#cb199-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">download.file</span>(data_urls[i], data_paths[i])</span>
<span id="cb199-37"><a href="data-collection-and-data-storage.html#cb199-37" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div id="stackcombine-raw-source-files" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Stack/combine raw source files<a href="data-collection-and-data-storage.html#stackcombine-raw-source-files" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In a next step, we parse and combine the downloaded data. Depending on how you want to further work with the gathered data, one or another storage format might be more convenient. For the sake of illustration (and the following examples building on the downloaded data), we store the downloaded data in one CSV file. To this end, we make use of the <code>arrow</code> package <span class="citation">(<a href="#ref-richardson_etal2022" role="doc-biblioref">Richardson et al. 2022</a>)</span>, an R interface to the Apache Arrow C++ library (a platform to work with large-scale columnar data). The aim of the exercise is to combine the downloaded Parquet files into one compressed CSV file, which will be more easily accessible for some of the libraries used in further examples.</p>
<p>We start by installing the <code>arrow</code> package in the following way.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="data-collection-and-data-storage.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install arrow</span></span>
<span id="cb200-2"><a href="data-collection-and-data-storage.html#cb200-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">LIBARROW_MINIMAL =</span> <span class="st">&quot;false&quot;</span>) <span class="co"># to enable working with compressed files</span></span>
<span id="cb200-3"><a href="data-collection-and-data-storage.html#cb200-3" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;arrow&quot;</span>) <span class="co"># might take a while</span></span></code></pre></div>
<p>The setting <code>LIBARROW_MINIMAL= "false"</code> ensures that the installation of arrow is not restricted to the very basic functionality of the package. Specifically, for our context it will be important that the <code>arrow</code> installation allows for the reading of compressed files.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="data-collection-and-data-storage.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP ---------------------------</span></span>
<span id="cb201-2"><a href="data-collection-and-data-storage.html#cb201-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-3"><a href="data-collection-and-data-storage.html#cb201-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb201-4"><a href="data-collection-and-data-storage.html#cb201-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arrow)</span>
<span id="cb201-5"><a href="data-collection-and-data-storage.html#cb201-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb201-6"><a href="data-collection-and-data-storage.html#cb201-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb201-7"><a href="data-collection-and-data-storage.html#cb201-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-8"><a href="data-collection-and-data-storage.html#cb201-8" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb201-9"><a href="data-collection-and-data-storage.html#cb201-9" aria-hidden="true" tabindex="-1"></a>INPUT_PATH <span class="ot">&lt;-</span> <span class="st">&quot;data/tlc_trips/&quot;</span></span>
<span id="cb201-10"><a href="data-collection-and-data-storage.html#cb201-10" aria-hidden="true" tabindex="-1"></a>OUTPUT_FILE <span class="ot">&lt;-</span> <span class="st">&quot;data/tlc_trips.parquet&quot;</span></span>
<span id="cb201-11"><a href="data-collection-and-data-storage.html#cb201-11" aria-hidden="true" tabindex="-1"></a>OUTPUT_FILE_CSV <span class="ot">&lt;-</span> <span class="st">&quot;data/tlc_trips.csv&quot;</span></span>
<span id="cb201-12"><a href="data-collection-and-data-storage.html#cb201-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-13"><a href="data-collection-and-data-storage.html#cb201-13" aria-hidden="true" tabindex="-1"></a><span class="co"># list of paths to downloaded Parquet files</span></span>
<span id="cb201-14"><a href="data-collection-and-data-storage.html#cb201-14" aria-hidden="true" tabindex="-1"></a>all_files <span class="ot">&lt;-</span> <span class="fu">list.files</span>(INPUT_PATH, <span class="at">full.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb201-15"><a href="data-collection-and-data-storage.html#cb201-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-16"><a href="data-collection-and-data-storage.html#cb201-16" aria-hidden="true" tabindex="-1"></a><span class="co"># LOAD, COMBINE, STORE ----------------------</span></span>
<span id="cb201-17"><a href="data-collection-and-data-storage.html#cb201-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-18"><a href="data-collection-and-data-storage.html#cb201-18" aria-hidden="true" tabindex="-1"></a><span class="co"># read Parquet files</span></span>
<span id="cb201-19"><a href="data-collection-and-data-storage.html#cb201-19" aria-hidden="true" tabindex="-1"></a>all_data <span class="ot">&lt;-</span> <span class="fu">lapply</span>(all_files, read_parquet, <span class="at">as_data_frame =</span> <span class="cn">FALSE</span>)</span>
<span id="cb201-20"><a href="data-collection-and-data-storage.html#cb201-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-21"><a href="data-collection-and-data-storage.html#cb201-21" aria-hidden="true" tabindex="-1"></a><span class="co"># combine all arrow tables into one</span></span>
<span id="cb201-22"><a href="data-collection-and-data-storage.html#cb201-22" aria-hidden="true" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">lift_dl</span>(concat_tables)(all_data)</span>
<span id="cb201-23"><a href="data-collection-and-data-storage.html#cb201-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-24"><a href="data-collection-and-data-storage.html#cb201-24" aria-hidden="true" tabindex="-1"></a><span class="co"># write combined dataset to csv file</span></span>
<span id="cb201-25"><a href="data-collection-and-data-storage.html#cb201-25" aria-hidden="true" tabindex="-1"></a><span class="fu">write_csv_arrow</span>(combined_data,</span>
<span id="cb201-26"><a href="data-collection-and-data-storage.html#cb201-26" aria-hidden="true" tabindex="-1"></a>                <span class="at">file =</span> OUTPUT_FILE_CSV, </span>
<span id="cb201-27"><a href="data-collection-and-data-storage.html#cb201-27" aria-hidden="true" tabindex="-1"></a>                <span class="at">include_header =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Note that in the code example above we use <code>purr::lift_dl()</code> (<code>lift_dl(concat_tables)(all_data)</code>) to facilitate the code. The <code>arrow</code> function <code>concat_tables</code> combines several table objects into one table.</p>
<div class="infobox">
<div class="center">
<p><strong>Aside: CSV import and memory allocation, read.csv vs fread</strong></p>
</div>
<p></p>
<p>The time needed for the simple step of importing rather large CSV files can vary substantially in R, depending on the function/package used. The reason is that there are different ways to allocate RAM when reading data from a CSV file. Depending on the amount of data to be read in, one or another approach might be faster. We first investigate the RAM allocation in R with <code>mem_change()</code> and <code>mem_used()</code>.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="data-collection-and-data-storage.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP -----------------</span></span>
<span id="cb202-2"><a href="data-collection-and-data-storage.html#cb202-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-3"><a href="data-collection-and-data-storage.html#cb202-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fix variables</span></span>
<span id="cb202-4"><a href="data-collection-and-data-storage.html#cb202-4" aria-hidden="true" tabindex="-1"></a>DATA_PATH <span class="ot">&lt;-</span> <span class="st">&quot;data/flights.csv&quot;</span></span>
<span id="cb202-5"><a href="data-collection-and-data-storage.html#cb202-5" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb202-6"><a href="data-collection-and-data-storage.html#cb202-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pryr) </span>
<span id="cb202-7"><a href="data-collection-and-data-storage.html#cb202-7" aria-hidden="true" tabindex="-1"></a><span class="co"># check how much memory is used by R (overall)</span></span>
<span id="cb202-8"><a href="data-collection-and-data-storage.html#cb202-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.72 GB</code></pre>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="data-collection-and-data-storage.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DATA IMPORT ----------------</span></span>
<span id="cb204-2"><a href="data-collection-and-data-storage.html#cb204-2" aria-hidden="true" tabindex="-1"></a><span class="co"># check the change in memory due to each step</span></span>
<span id="cb204-3"><a href="data-collection-and-data-storage.html#cb204-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and stop the time needed for the import</span></span>
<span id="cb204-4"><a href="data-collection-and-data-storage.html#cb204-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(flights <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(DATA_PATH))</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   1.539   0.134   1.703</code></pre>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="data-collection-and-data-storage.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.76 GB</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="data-collection-and-data-storage.html#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DATA PREPARATION --------</span></span>
<span id="cb208-2"><a href="data-collection-and-data-storage.html#cb208-2" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> flights[,<span class="sc">-</span><span class="dv">1</span><span class="sc">:-</span><span class="dv">3</span>]</span>
<span id="cb208-3"><a href="data-collection-and-data-storage.html#cb208-3" aria-hidden="true" tabindex="-1"></a><span class="co"># check how much memory is used by R now</span></span>
<span id="cb208-4"><a href="data-collection-and-data-storage.html#cb208-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mem_used</span>()</span></code></pre></div>
<pre><code>## 1.75 GB</code></pre>
<p>The last result is rather interesting. The object <code>flights</code> must have been larger right after importing it than at the end of the script. We have thrown out several variables, after all. Why does R still use that much memory? R does not by default ‘clean up’ memory unless it is really necessary (meaning no more memory is available). In this case, R has still way more memory available from the operating system, thus there is no need to ‘collect the garbage’ yet. However, we can force R to collect the garbage on the spot with <code>gc()</code>. This can be helpful to better keep track of the memory needed by an analytics script.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="data-collection-and-data-storage.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gc</span>()</span></code></pre></div>
<pre><code>##             used   (Mb) gc trigger   (Mb)  max used
## Ncells   6975201  372.6   11781020  629.2  11781020
## Vcells 170361191 1299.8  399419081 3047.4 398976635
##          (Mb)
## Ncells  629.2
## Vcells 3044.0</code></pre>
<p>Now, let’s see how we can improve the performance of this script with regard to memory allocation. Most memory is allocated when importing the file. Obviously, any improvement of the script must still result in importing all the data. However, there are different ways to read data into RAM. <code>read.csv()</code> reads all lines of a csv file consecutively. In contrast, <code>data.table::fread()</code> first ‘maps’ the data file into memory and only then actually reads it in line by line. This involves an additional initial step, but the larger the file, the less relevant is this first step in the total time needed to read all the data into memory. By switching on the <code>verbose</code> option, we can actually see what <code>fread</code> is doing.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="data-collection-and-data-storage.html#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb212-2"><a href="data-collection-and-data-storage.html#cb212-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb212-3"><a href="data-collection-and-data-storage.html#cb212-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb212-4"><a href="data-collection-and-data-storage.html#cb212-4" aria-hidden="true" tabindex="-1"></a><span class="co"># DATA IMPORT ----------------</span></span>
<span id="cb212-5"><a href="data-collection-and-data-storage.html#cb212-5" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(flights <span class="ot">&lt;-</span> <span class="fu">fread</span>(DATA_PATH, <span class="at">verbose =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.384   0.007   0.069</code></pre>
<p>The output displayed on the console shows what is involved in steps <code>[1]</code> to <code>[12]</code> of the parsing/import procedure. Note in particular the following line under step <code>[7]</code> in the procedure:</p>
<pre><code>Estimated number of rows: 30960501 / 92.03 = 336403
 Initial alloc = 370043 rows (336403 + 9%) using 
 bytes/max(mean-2*sd,min) clamped between [1.1*estn, 2.0*estn]</code></pre>
<p>This is the result of the abovementioned preparatory step in the form of sampling. The <code>fread</code> CSV parser first estimates how large the dataset likely is, and then creates an additional allocation (in this case of <code>370043 rows</code>). Only after this are the rows actually imported into RAM. The summary of the time allocated for the different steps shown at the bottom of the output nicely illustrates that the preparatory steps of memory mapping and allocation are rather fast compared with the time needed to actually read the data into RAM. Given the size of the dataset, <code>fread</code>’s approach to memory allocation results in a much faster import of the dataset than <code>read.csv</code>’s approach.</p>
</div>
</div>
<div id="efficient-local-data-storage" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Efficient local data storage<a href="data-collection-and-data-storage.html#efficient-local-data-storage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- So far, we have primarily been concerned with situations in which a dataset is too large to fit into RAM, making the analysis of this data either impossible or very slow (inefficient) when using standard tools. Thus, we have explored concepts and tools that help us use the available RAM (and virtual memory) most efficiently for data analysis tasks. -->
<p>In this section, we are concerned with a) how we can store large datasets permanently on a mass storage device in an efficient way (here, efficient can be understood as ‘not taking up too much space’) and b) how we can load (parts of) this dataset in an efficient way (here, efficient~fast) for analysis.</p>
<p>We look at this problem in two situations:</p>
<ul>
<li>The data needs to be stored locally (e.g., on the hard disk of our laptop).</li>
<li>The data can be stored on a server ‘in the cloud’.</li>
</ul>
<p>Various tools have been developed over the last few years to improve the efficiency of storing and accessing large amounts of data, many of which go beyond the scope implied by this book’s perspective on applied data analytics. Here, we focus on the basic concept of <em>SQL/Relational Database Management Systems (RDBMSs)</em>, as well as a few alternatives that can be summarized under the term <em>NoSQL (‘non-SQL’, sometimes ‘Not only SQL’)</em> database systems. Conveniently (and contrary to what the latter name would suggest), most of these tools can be worked with by using basic SQL queries to load/query data.</p>
<p>The relational database system follows the relational data model, in which the data is organized in several tables that are connected via some unique data record identifiers (keys). Such systems, for example, SQLite introduced in Chapter 3, have been used for a long time in all kinds of business and analytics contexts. They are well-tried and stable and have a large and diverse user base. There are many technicalities involved in how they work under the hood, but for our purposes three characteristics are most relevant:</p>
<ol style="list-style-type: decimal">
<li>All common RDBMSs, like SQLite and MySQL, are <em>row-based</em> databases. That is, data is thought of as observations/data records stored in rows of a table. One record consists of one row.</li>
<li>They are typically made for storing clean data in a <em>clearly defined set of tables</em>, with clearly defined properties. The organizing of data in various tables has (at least for our perspective here) the aim of avoiding redundancies and thereby using the available storage space more efficiently.</li>
<li>Rows are <em>indexed</em> according to the unique identifiers of tables (or one or several other variables in a table). This allows for fast querying of specific records and efficient merging/joining of tables.</li>
</ol>
<p>While these particular features work very well also with large amounts of data, particularly for exploration and data preparation (joining tables), in the age of big data they might be more relevant for operational databases (in the backend of web applications, or simply the operational database of a business) than for the specific purpose of data analytics.</p>
<p>On the one hand, the data basis of an analytics project might be simpler in terms of the number of tables involved. On the other hand, Big Data, as we have seen, might come in less structured and/or more complex forms than traditional table-like/row-based data. <em>NoSQL</em> databases have been developed for the purposes of storing more complex/less structured data, which might not necessarily be described as a set of tables connected via keys, and for the purpose of fast analysis of large amounts of data. Again, three main characteristics of these types of databases are of particular relevance here:</p>
<ol style="list-style-type: decimal">
<li>Typically, <em>NoSQL</em> databases are not row-based, but follow a <em>column-based</em>, document-based, key-value-based, or graph-based data model. In what follows, the column-based model is most relevant.</li>
<li><em>NoSQL</em> databases are designed for horizontal scaling. That is, scaling such a database out over many nodes of a computing cluster is usually straightforward.</li>
<li>They are optimized to give quick answers based on summarizing large amounts of data, such as frequency counts and averages (sometimes by using approximations rather than exact computations.)</li>
</ol>
<p>Figure <a href="data-collection-and-data-storage.html#fig:columnvsrow">8.1</a> illustrates the basic concept of row-based vs. column-based data storage.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:columnvsrow"></span>
<img src="img/column_v_rowbased.png" alt="Schematic illustration of columnar vs. row-based data storage." width="99%" />
<p class="caption">
Figure 8.1: Schematic illustration of columnar vs. row-based data storage.
</p>
</div>

<div class="infobox">
<div class="center">
<p><strong>Aside: Row-based vs column-based databases</strong></p>
</div>
<p>Conceptually, in a <em>row-based database</em> individual values (cells) are contained in rows, which means changing one value requires updating a row. Row-based databases (e.g., SQLite) are thus designed for efficient data reading and writing when users often access many columns but rather few observations. For example, for an operational database in the back-end of a web application such as an online shop, a row-based approach makes sense because hundreds or thousands of users (customers in that case) constantly add or query small amounts of data. In contrast, changing a value in <em>column-based</em> databases means changing a column. Accessing all values in a particular column is much faster in comparison to row-based databases.</p>
<p>This means that column-based databases are useful when users tend to query rather few columns but massive numbers of observations, which is typically rather the case in an analytics context. Some well-known data warehouse and data lake systems are therefore based on this principle (e.g., Google BigQuery). However, if analytics tasks involve a lot of (out-of-memory) table joins, column-based solutions are likely to be slower than row-based solutions.</p>
</div>
<p>In the following, we have a close look at using both column-based and row-based tools. Thereby we will particularly highlight the practical differences between using column-based and row-based data storage solutions.</p>
<div id="rdbms-basics" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> RDBMS basics<a href="data-collection-and-data-storage.html#rdbms-basics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>RDBMSs have two key features that tackle the two efficiency concerns mentioned above:</p>
<ul>
<li><p>The <em>relational data model</em>: The overall dataset is split by columns (covariates) into tables in order to reduce the storage of redundant variable-value repetitions. The resulting database tables are then linked via key-variables (unique identifiers). Thus (simply put), each type of entity on which observations exist resides in its own database table. Within this table, each observation has it’s unique ID. Keeping the data in such a structure is very efficient in terms of storage space used.</p></li>
<li><p><em>Indexing</em>: The key-columns of the database tables are indexed, meaning (in simple terms) ordered on disk. Indexing a table takes time, but it has to be performed only once (unless the content of the table changes). The resulting index is then stored on disk as part of the database. These indices substantially reduce the number of disk accesses required to query/find specific observations. Thus, they make the loading of specific parts of the data for analysis much more efficient.</p></li>
</ul>
<p>The loading/querying of data from an RDBMS typically involves the selection of specific observations (rows) and covariates (columns) from different tables. Due to the indexing, observations are selected efficiently, and the defined relations between tables (via keys) facilitate the joining of columns to a new table (the queried data).</p>
</div>
<div id="efficient-data-access-indices-and-joins-in-sqlite" class="section level3 hasAnchor" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Efficient data access: Indices and joins in SQLite<a href="data-collection-and-data-storage.html#efficient-data-access-indices-and-joins-in-sqlite" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far we have only had a look at the very basics of writing SQL code. Let us now further explore SQLite as an easy-to-use and easy-to-set-up relational database solution. In a second step we then look at how to connect to a local SQLite database from within R. First, we switch to the Terminal tab in RStudio, set up a new database called <code>air.sqlite</code>, and import the csv-file <code>flights.csv</code> (used in previous chapters) as a first table.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb215-1"><a href="data-collection-and-data-storage.html#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="co"># switch to data directory</span></span>
<span id="cb215-2"><a href="data-collection-and-data-storage.html#cb215-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> data</span>
<span id="cb215-3"><a href="data-collection-and-data-storage.html#cb215-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create database and run sqlite</span></span>
<span id="cb215-4"><a href="data-collection-and-data-storage.html#cb215-4" aria-hidden="true" tabindex="-1"></a><span class="ex">sqlite3</span> air.sqlite</span></code></pre></div>
<div class="sourceCode" id="cb216"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb216-1"><a href="data-collection-and-data-storage.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="co">-- import csvs</span></span>
<span id="cb216-2"><a href="data-collection-and-data-storage.html#cb216-2" aria-hidden="true" tabindex="-1"></a>.<span class="kw">mode</span> csv</span>
<span id="cb216-3"><a href="data-collection-and-data-storage.html#cb216-3" aria-hidden="true" tabindex="-1"></a>.import flights.csv flights</span></code></pre></div>
<p>We check if everything worked out well via the <code>.tables</code> and <code>.schema</code> commands.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb217-1"><a href="data-collection-and-data-storage.html#cb217-1" aria-hidden="true" tabindex="-1"></a>.<span class="kw">tables</span></span>
<span id="cb217-2"><a href="data-collection-and-data-storage.html#cb217-2" aria-hidden="true" tabindex="-1"></a>.<span class="kw">schema</span> flights</span></code></pre></div>
<p>In <code>flights</code>, each row describes a flight (the day it took place, its origin, its destination, etc.). It contains a covariate <code>carrier</code> containing the unique ID of the respective airline/carrier carrying out the flight as well as the covariates <code>origin</code> and <code>dest</code>. The latter two variables contain the unique IATA-codes of the airports from which the flights departed and where they arrived, respectively. In <code>flights</code> we thus have observations at the level of individual flights.</p>
<p>Now we extend our database in a meaningful way, following the relational data model idea. First we download two additional CSV files containing data that relate to the flights table:</p>
<ul>
<li><a href="http://stat-computing.org/dataexpo/2009/airports.csv"><code>airports.csv</code></a>: Describes the locations of US Airports (relates to <code>origin</code> and <code>dest</code>).</li>
<li><a href="http://stat-computing.org/dataexpo/2009/carriers.csv"><code>carriers.csv</code></a>: A listing of carrier codes with full names (relates to the <code>carrier</code>-column in <code>flights</code>).</li>
</ul>
<p>In this code example, the two CSVs have already been downloaded to the <code>materials/data</code>-folder.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb218-1"><a href="data-collection-and-data-storage.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="co">-- import airport data</span></span>
<span id="cb218-2"><a href="data-collection-and-data-storage.html#cb218-2" aria-hidden="true" tabindex="-1"></a>.<span class="kw">mode</span> csv</span>
<span id="cb218-3"><a href="data-collection-and-data-storage.html#cb218-3" aria-hidden="true" tabindex="-1"></a>.import airports.csv airports</span>
<span id="cb218-4"><a href="data-collection-and-data-storage.html#cb218-4" aria-hidden="true" tabindex="-1"></a>.import carriers.csv carriers</span>
<span id="cb218-5"><a href="data-collection-and-data-storage.html#cb218-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-6"><a href="data-collection-and-data-storage.html#cb218-6" aria-hidden="true" tabindex="-1"></a><span class="co">-- inspect the result</span></span>
<span id="cb218-7"><a href="data-collection-and-data-storage.html#cb218-7" aria-hidden="true" tabindex="-1"></a>.<span class="kw">tables</span></span>
<span id="cb218-8"><a href="data-collection-and-data-storage.html#cb218-8" aria-hidden="true" tabindex="-1"></a>.<span class="kw">schema</span> airports</span>
<span id="cb218-9"><a href="data-collection-and-data-storage.html#cb218-9" aria-hidden="true" tabindex="-1"></a>.<span class="kw">schema</span> carriers</span></code></pre></div>
<p>Now we can run our first query involving the relation between tables. The aim of the exercise is to query flights data (information on departure delays per flight number and date; from the <code>flights</code> table) for all <code>United Air Lines Inc.</code> flights (information from the <code>carriers</code> table) departing from <code>Newark Intl</code> airport (information from the <code>airports</code> table). In addition, we want the resulting table ordered by flight number. For the sake of the exercise, we only show the first 10 results of this query (<code>LIMIT 10</code>).</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb219-1"><a href="data-collection-and-data-storage.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> </span>
<span id="cb219-2"><a href="data-collection-and-data-storage.html#cb219-2" aria-hidden="true" tabindex="-1"></a><span class="dt">year</span>,</span>
<span id="cb219-3"><a href="data-collection-and-data-storage.html#cb219-3" aria-hidden="true" tabindex="-1"></a><span class="dt">month</span>, </span>
<span id="cb219-4"><a href="data-collection-and-data-storage.html#cb219-4" aria-hidden="true" tabindex="-1"></a><span class="dt">day</span>,</span>
<span id="cb219-5"><a href="data-collection-and-data-storage.html#cb219-5" aria-hidden="true" tabindex="-1"></a>dep_delay,</span>
<span id="cb219-6"><a href="data-collection-and-data-storage.html#cb219-6" aria-hidden="true" tabindex="-1"></a>flight</span>
<span id="cb219-7"><a href="data-collection-and-data-storage.html#cb219-7" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> (flights <span class="kw">INNER</span> <span class="kw">JOIN</span> airports <span class="kw">ON</span> flights.origin<span class="op">=</span>airports.iata) </span>
<span id="cb219-8"><a href="data-collection-and-data-storage.html#cb219-8" aria-hidden="true" tabindex="-1"></a><span class="kw">INNER</span> <span class="kw">JOIN</span> carriers <span class="kw">ON</span> flights.carrier <span class="op">=</span> carriers.Code</span>
<span id="cb219-9"><a href="data-collection-and-data-storage.html#cb219-9" aria-hidden="true" tabindex="-1"></a><span class="kw">WHERE</span> carriers.Description <span class="op">=</span> <span class="st">&#39;United Air Lines Inc.&#39;</span></span>
<span id="cb219-10"><a href="data-collection-and-data-storage.html#cb219-10" aria-hidden="true" tabindex="-1"></a><span class="kw">AND</span> airports.airport <span class="op">=</span> <span class="st">&#39;Newark Intl&#39;</span></span>
<span id="cb219-11"><a href="data-collection-and-data-storage.html#cb219-11" aria-hidden="true" tabindex="-1"></a><span class="kw">ORDER</span> <span class="kw">BY</span> flight</span>
<span id="cb219-12"><a href="data-collection-and-data-storage.html#cb219-12" aria-hidden="true" tabindex="-1"></a><span class="kw">LIMIT</span> <span class="dv">10</span>;</span></code></pre></div>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="data-collection-and-data-storage.html#cb220-1" aria-hidden="true" tabindex="-1"></a>flights_join</span></code></pre></div>
<pre><code>##    year month day dep_delay flight
## 1  2013     1   4         0      1
## 2  2013     1   5        -2      1
## 3  2013     3   6         1      1
## 4  2013     2  13        -2      3
## 5  2013     2  16        -9      3
## 6  2013     2  20         3      3
## 7  2013     2  23        -5      3
## 8  2013     2  26        24      3
## 9  2013     2  27        10      3
## 10 2013     1   5         3     10</code></pre>
<p>Note that this query has been executed without indexing any of the tables first. Thus SQLite could not take any ‘shortcuts’ when matching the ID columns in order to join the tables for the query output. That is, SQLite had to scan the entire columns to find the matches. Now we index the respective ID columns and re-run the query.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb222-1"><a href="data-collection-and-data-storage.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> iata_airports <span class="kw">ON</span> airports (iata);</span>
<span id="cb222-2"><a href="data-collection-and-data-storage.html#cb222-2" aria-hidden="true" tabindex="-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> origin_flights <span class="kw">ON</span> flights (origin);</span>
<span id="cb222-3"><a href="data-collection-and-data-storage.html#cb222-3" aria-hidden="true" tabindex="-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> carrier_flights <span class="kw">ON</span> flights (carrier);</span>
<span id="cb222-4"><a href="data-collection-and-data-storage.html#cb222-4" aria-hidden="true" tabindex="-1"></a><span class="kw">CREATE</span> <span class="kw">INDEX</span> code_carriers <span class="kw">ON</span> carriers (code);</span></code></pre></div>
<p>Note that SQLite optimizes the efficiency of the query without our explicit instructions. If there are indices it can use to speed up the query, it will do so.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb223-1"><a href="data-collection-and-data-storage.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="kw">SELECT</span> </span>
<span id="cb223-2"><a href="data-collection-and-data-storage.html#cb223-2" aria-hidden="true" tabindex="-1"></a><span class="dt">year</span>,</span>
<span id="cb223-3"><a href="data-collection-and-data-storage.html#cb223-3" aria-hidden="true" tabindex="-1"></a><span class="dt">month</span>, </span>
<span id="cb223-4"><a href="data-collection-and-data-storage.html#cb223-4" aria-hidden="true" tabindex="-1"></a><span class="dt">day</span>,</span>
<span id="cb223-5"><a href="data-collection-and-data-storage.html#cb223-5" aria-hidden="true" tabindex="-1"></a>dep_delay,</span>
<span id="cb223-6"><a href="data-collection-and-data-storage.html#cb223-6" aria-hidden="true" tabindex="-1"></a>flight</span>
<span id="cb223-7"><a href="data-collection-and-data-storage.html#cb223-7" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> (flights <span class="kw">INNER</span> <span class="kw">JOIN</span> airports <span class="kw">ON</span> flights.origin<span class="op">=</span>airports.iata) </span>
<span id="cb223-8"><a href="data-collection-and-data-storage.html#cb223-8" aria-hidden="true" tabindex="-1"></a><span class="kw">INNER</span> <span class="kw">JOIN</span> carriers <span class="kw">ON</span> flights.carrier <span class="op">=</span> carriers.Code</span>
<span id="cb223-9"><a href="data-collection-and-data-storage.html#cb223-9" aria-hidden="true" tabindex="-1"></a><span class="kw">WHERE</span> carriers.Description <span class="op">=</span> <span class="st">&#39;United Air Lines Inc.&#39;</span></span>
<span id="cb223-10"><a href="data-collection-and-data-storage.html#cb223-10" aria-hidden="true" tabindex="-1"></a><span class="kw">AND</span> airports.airport <span class="op">=</span> <span class="st">&#39;Newark Intl&#39;</span></span>
<span id="cb223-11"><a href="data-collection-and-data-storage.html#cb223-11" aria-hidden="true" tabindex="-1"></a><span class="kw">ORDER</span> <span class="kw">BY</span> flight</span>
<span id="cb223-12"><a href="data-collection-and-data-storage.html#cb223-12" aria-hidden="true" tabindex="-1"></a><span class="kw">LIMIT</span> <span class="dv">10</span>;</span></code></pre></div>
<pre><code>##    year month day dep_delay flight
## 1  2013     1   4         0      1
## 2  2013     1   5        -2      1
## 3  2013     3   6         1      1
## 4  2013     2  13        -2      3
## 5  2013     2  16        -9      3
## 6  2013     2  20         3      3
## 7  2013     2  23        -5      3
## 8  2013     2  26        24      3
## 9  2013     2  27        10      3
## 10 2013     1   5         3     10</code></pre>
<p>You can find the final <code>air.sqlite</code> database, including all the indices and tables as <code>materials/data/air_final.sqlite</code> in the course’s code repository.</p>
</div>
</div>
<div id="connecting-r-to-an-rdbms" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Connecting R to an RDBMS<a href="data-collection-and-data-storage.html#connecting-r-to-an-rdbms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>The R-package <code>RSQLite</code> <span class="citation">(<a href="#ref-RSQLite" role="doc-biblioref">Müller et al. 2022</a>)</span> embeds SQLite in R. That is, it provides functions that allow us to use SQLite directly from within R. You will see that the combination of SQLite with R is a simple but very practical approach to working with very efficiently (and locally) stored datasets. In the following example, we explore how <code>RSQLite</code> can be used to set up and query the <code>air.sqlite</code> database shown in the example above.</p>
<div id="creating-a-new-database-with-rsqlite" class="section level3 hasAnchor" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Creating a new database with <code>RSQLite</code><a href="data-collection-and-data-storage.html#creating-a-new-database-with-rsqlite" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>Similarly to the raw SQLite syntax, connecting to a database that does not exist yet actually creates this (empty database). Note that for all interactions with the database from within R, we need to refer to the connection (here: <code>con_air</code>).</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="data-collection-and-data-storage.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb225-2"><a href="data-collection-and-data-storage.html#cb225-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RSQLite)</span>
<span id="cb225-3"><a href="data-collection-and-data-storage.html#cb225-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-4"><a href="data-collection-and-data-storage.html#cb225-4" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize the database</span></span>
<span id="cb225-5"><a href="data-collection-and-data-storage.html#cb225-5" aria-hidden="true" tabindex="-1"></a>con_air <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(<span class="fu">SQLite</span>(), <span class="st">&quot;data/air.sqlite&quot;</span>)</span></code></pre></div>
</div>
<div id="importing-data" class="section level3 hasAnchor" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Importing data<a href="data-collection-and-data-storage.html#importing-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With <code>RSQLite</code> we can easily add <code>data.frame</code>s as SQLite tables to the database.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="data-collection-and-data-storage.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import data into current R session</span></span>
<span id="cb226-2"><a href="data-collection-and-data-storage.html#cb226-2" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/flights.csv&quot;</span>)</span>
<span id="cb226-3"><a href="data-collection-and-data-storage.html#cb226-3" aria-hidden="true" tabindex="-1"></a>airports <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/airports.csv&quot;</span>)</span>
<span id="cb226-4"><a href="data-collection-and-data-storage.html#cb226-4" aria-hidden="true" tabindex="-1"></a>carriers <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/carriers.csv&quot;</span>)</span>
<span id="cb226-5"><a href="data-collection-and-data-storage.html#cb226-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-6"><a href="data-collection-and-data-storage.html#cb226-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add tables to database</span></span>
<span id="cb226-7"><a href="data-collection-and-data-storage.html#cb226-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_air, <span class="st">&quot;flights&quot;</span>, flights)</span>
<span id="cb226-8"><a href="data-collection-and-data-storage.html#cb226-8" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_air, <span class="st">&quot;airports&quot;</span>, airports)</span>
<span id="cb226-9"><a href="data-collection-and-data-storage.html#cb226-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_air, <span class="st">&quot;carriers&quot;</span>, carriers)</span></code></pre></div>
</div>
<div id="issue-queries" class="section level3 hasAnchor" number="8.4.3">
<h3><span class="header-section-number">8.4.3</span> Issue queries<a href="data-collection-and-data-storage.html#issue-queries" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we can query the database from within R. By default, <code>RSQLite</code> returns the query results as <code>data.frame</code>s. Queries are simply character strings written in SQLite.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="data-collection-and-data-storage.html#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define query</span></span>
<span id="cb227-2"><a href="data-collection-and-data-storage.html#cb227-2" aria-hidden="true" tabindex="-1"></a>delay_query <span class="ot">&lt;-</span></span>
<span id="cb227-3"><a href="data-collection-and-data-storage.html#cb227-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;SELECT </span></span>
<span id="cb227-4"><a href="data-collection-and-data-storage.html#cb227-4" aria-hidden="true" tabindex="-1"></a><span class="st">year,</span></span>
<span id="cb227-5"><a href="data-collection-and-data-storage.html#cb227-5" aria-hidden="true" tabindex="-1"></a><span class="st">month, </span></span>
<span id="cb227-6"><a href="data-collection-and-data-storage.html#cb227-6" aria-hidden="true" tabindex="-1"></a><span class="st">day,</span></span>
<span id="cb227-7"><a href="data-collection-and-data-storage.html#cb227-7" aria-hidden="true" tabindex="-1"></a><span class="st">dep_delay,</span></span>
<span id="cb227-8"><a href="data-collection-and-data-storage.html#cb227-8" aria-hidden="true" tabindex="-1"></a><span class="st">flight</span></span>
<span id="cb227-9"><a href="data-collection-and-data-storage.html#cb227-9" aria-hidden="true" tabindex="-1"></a><span class="st">FROM (flights INNER JOIN airports ON flights.origin=airports.iata) </span></span>
<span id="cb227-10"><a href="data-collection-and-data-storage.html#cb227-10" aria-hidden="true" tabindex="-1"></a><span class="st">INNER JOIN carriers ON flights.carrier = carriers.Code</span></span>
<span id="cb227-11"><a href="data-collection-and-data-storage.html#cb227-11" aria-hidden="true" tabindex="-1"></a><span class="st">WHERE carriers.Description = &#39;United Air Lines Inc.&#39;</span></span>
<span id="cb227-12"><a href="data-collection-and-data-storage.html#cb227-12" aria-hidden="true" tabindex="-1"></a><span class="st">AND airports.airport = &#39;Newark Intl&#39;</span></span>
<span id="cb227-13"><a href="data-collection-and-data-storage.html#cb227-13" aria-hidden="true" tabindex="-1"></a><span class="st">ORDER BY flight</span></span>
<span id="cb227-14"><a href="data-collection-and-data-storage.html#cb227-14" aria-hidden="true" tabindex="-1"></a><span class="st">LIMIT 10;</span></span>
<span id="cb227-15"><a href="data-collection-and-data-storage.html#cb227-15" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb227-16"><a href="data-collection-and-data-storage.html#cb227-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-17"><a href="data-collection-and-data-storage.html#cb227-17" aria-hidden="true" tabindex="-1"></a><span class="co"># issue query</span></span>
<span id="cb227-18"><a href="data-collection-and-data-storage.html#cb227-18" aria-hidden="true" tabindex="-1"></a>delays_df <span class="ot">&lt;-</span> <span class="fu">dbGetQuery</span>(con_air, delay_query)</span>
<span id="cb227-19"><a href="data-collection-and-data-storage.html#cb227-19" aria-hidden="true" tabindex="-1"></a>delays_df</span>
<span id="cb227-20"><a href="data-collection-and-data-storage.html#cb227-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-21"><a href="data-collection-and-data-storage.html#cb227-21" aria-hidden="true" tabindex="-1"></a><span class="co"># clean up</span></span>
<span id="cb227-22"><a href="data-collection-and-data-storage.html#cb227-22" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con_air)</span></code></pre></div>
<p>When done working with the database, we close the connection to the database with <code>dbDisconnect(con)</code>.</p>
</div>
</div>
<div id="cloud-solutions-for-big-data-storage" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Cloud solutions for (big) data storage<a href="data-collection-and-data-storage.html#cloud-solutions-for-big-data-storage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As outlined in the previous section, RDBMSs are a very practical tool for storing the structured data of an analytics project locally in a database. A local SQLite database can easily be set up and accessed via R, allowing one to write the whole data pipeline – from data gathering to filtering, aggregating, and finally analyzing – in R. In contrast to directly working with CSV files, using SQLite has the advantage of organizing the data access much more efficiently in terms of RAM. Only the final result of a query is really loaded fully into R’s memory.</p>
<p>If mass storage space is too sparse or if RAM is nevertheless not sufficient, even when organizing data access via SQLite, several cloud solutions come to the rescue. Although you could also rent a traditional web server and host a SQL database there, this is usually not worthwhile for a data analytics project. In the next section we thus look at three important cases of how to store data as part of an analytics project: <em>RDBMS in the cloud</em>, a serverless <em>data warehouse</em> solution for large datasets called <em>Google BigQuery</em>, and a simple storage service to use as a <em>data lake</em> called <em>AWS S3</em>. All of these solutions are discussed from a data analytics perspective, and for all of these solutions we will look at how to make use of them from within R.</p>
<div id="easy-to-use-rdbms-in-the-cloud-aws-rds" class="section level3 hasAnchor" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> Easy-to-use RDBMS in the cloud: AWS RDS<a href="data-collection-and-data-storage.html#easy-to-use-rdbms-in-the-cloud-aws-rds" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we have set up RStudio Server on an EC2 instance, we can run the SQLite examples shown above on it. There are no additional steps needed to install SQLite. However, when using RDBMSs in the cloud, we typically have a more sophisticated implementation than SQLite in mind. Particularly, we want to set up an actual RDBMS server running in the cloud to which several clients can connect (e.g., via RStudio Server).</p>
<p>AWS’s Relational Database Service (RDS) provides an easy way to set up and run a SQL database in the cloud. The great advantage for users new to RDBMS/SQL is that you do not have to manually set up a server (e.g., an EC2 instance) and install/configure the SQL server. Instead, you can directly set up a fully functioning relational database in the cloud.</p>
<p>As a first step, open the AWS console and search for/select “RDS” in the search bar. Then, click on “Create database” in the lower part of the landing page.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rdscreate"></span>
<img src="img/aws_rds_create.png" alt="Create a managed relational database on AWS RDS." width="90%" />
<p class="caption">
Figure 8.2: Create a managed relational database on AWS RDS.
</p>
</div>

<p>On the next page, select “Easy create”, “MySQL”, and the “Free tier” DB instance size. Further down you will have to set the database instance identifier, the user name, and a password.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rdseasy"></span>
<img src="img/aws_rds_easycreate.png" alt="Easy creation of an RDS MySQL DB." width="70%" />
<p class="caption">
Figure 8.3: Easy creation of an RDS MySQL DB.
</p>
</div>

<p>Once the database instance is ready, you will see it in the databases overview. Click on the DB identifier (the name of your database shown in the list of databases), and click on modify (button in the upper-right corner). In the “Connectivity” panel under “Additional configuration”, select <em>Publicly accessible</em> (this is necessary to interact with the DB from your local machine), and save the settings. Back on the overview page of your database, under “Connectivity &amp; security”, click on the link under the VPC security groups, scroll down and select the “Inbound rules” tab. Edit the inbound rule to allow any IP4 inbound traffic.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rdsinboundrules"></span>
<img src="img/rds_inboundrules.png" alt="Allow all IP4 inbound traffic (set Source to 0.0.0.0/0)." width="99%" />
<p class="caption">
Figure 8.4: Allow all IP4 inbound traffic (set Source to <code>0.0.0.0/0</code>).
</p>
</div>

<!-- Now we can connect to the instance via the `RMySQL`\index{RMySQL package} package [@RMySQL]. Before loading data, we first have to initialize a new database (in contrast, this is done automatically when connecting to a SQLite database). -->
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="data-collection-and-data-storage.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb228-2"><a href="data-collection-and-data-storage.html#cb228-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RMySQL)</span>
<span id="cb228-3"><a href="data-collection-and-data-storage.html#cb228-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb228-4"><a href="data-collection-and-data-storage.html#cb228-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-5"><a href="data-collection-and-data-storage.html#cb228-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb228-6"><a href="data-collection-and-data-storage.html#cb228-6" aria-hidden="true" tabindex="-1"></a><span class="co"># replace this with the Endpoint shown in the AWS RDS console</span></span>
<span id="cb228-7"><a href="data-collection-and-data-storage.html#cb228-7" aria-hidden="true" tabindex="-1"></a>RDS_ENDPOINT <span class="ot">&lt;-</span> <span class="st">&quot;MY-ENDPOINT&quot;</span> </span>
<span id="cb228-8"><a href="data-collection-and-data-storage.html#cb228-8" aria-hidden="true" tabindex="-1"></a><span class="co"># replace this with the password you have set when initiating the RDS DB on AWS</span></span>
<span id="cb228-9"><a href="data-collection-and-data-storage.html#cb228-9" aria-hidden="true" tabindex="-1"></a>PW <span class="ot">&lt;-</span> <span class="st">&quot;MY-PW&quot;</span> </span>
<span id="cb228-10"><a href="data-collection-and-data-storage.html#cb228-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-11"><a href="data-collection-and-data-storage.html#cb228-11" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to DB</span></span>
<span id="cb228-12"><a href="data-collection-and-data-storage.html#cb228-12" aria-hidden="true" tabindex="-1"></a>con_rds <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(RMySQL<span class="sc">::</span><span class="fu">MySQL</span>(),</span>
<span id="cb228-13"><a href="data-collection-and-data-storage.html#cb228-13" aria-hidden="true" tabindex="-1"></a>                 <span class="at">host=</span>RDS_ENDPOINT,</span>
<span id="cb228-14"><a href="data-collection-and-data-storage.html#cb228-14" aria-hidden="true" tabindex="-1"></a>                 <span class="at">port=</span><span class="dv">3306</span>,</span>
<span id="cb228-15"><a href="data-collection-and-data-storage.html#cb228-15" aria-hidden="true" tabindex="-1"></a>                 <span class="at">username=</span><span class="st">&quot;admin&quot;</span>,</span>
<span id="cb228-16"><a href="data-collection-and-data-storage.html#cb228-16" aria-hidden="true" tabindex="-1"></a>                 <span class="at">password=</span>PW)</span>
<span id="cb228-17"><a href="data-collection-and-data-storage.html#cb228-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-18"><a href="data-collection-and-data-storage.html#cb228-18" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new database on the MySQL RDS instance</span></span>
<span id="cb228-19"><a href="data-collection-and-data-storage.html#cb228-19" aria-hidden="true" tabindex="-1"></a><span class="fu">dbSendQuery</span>(con_rds, <span class="st">&quot;CREATE DATABASE air&quot;</span>)</span>
<span id="cb228-20"><a href="data-collection-and-data-storage.html#cb228-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-21"><a href="data-collection-and-data-storage.html#cb228-21" aria-hidden="true" tabindex="-1"></a><span class="co"># disconnect and re-connect directly to the new DB</span></span>
<span id="cb228-22"><a href="data-collection-and-data-storage.html#cb228-22" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con_rds)</span>
<span id="cb228-23"><a href="data-collection-and-data-storage.html#cb228-23" aria-hidden="true" tabindex="-1"></a>con_rds <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(RMySQL<span class="sc">::</span><span class="fu">MySQL</span>(),</span>
<span id="cb228-24"><a href="data-collection-and-data-storage.html#cb228-24" aria-hidden="true" tabindex="-1"></a>                 <span class="at">host=</span>RDS_ENDPOINT,</span>
<span id="cb228-25"><a href="data-collection-and-data-storage.html#cb228-25" aria-hidden="true" tabindex="-1"></a>                 <span class="at">port=</span><span class="dv">3306</span>,</span>
<span id="cb228-26"><a href="data-collection-and-data-storage.html#cb228-26" aria-hidden="true" tabindex="-1"></a>                 <span class="at">username=</span><span class="st">&quot;admin&quot;</span>,</span>
<span id="cb228-27"><a href="data-collection-and-data-storage.html#cb228-27" aria-hidden="true" tabindex="-1"></a>                 <span class="at">dbname=</span><span class="st">&quot;air&quot;</span>,</span>
<span id="cb228-28"><a href="data-collection-and-data-storage.html#cb228-28" aria-hidden="true" tabindex="-1"></a>                 <span class="at">password=</span>PW)</span></code></pre></div>
<p><code>RMySQL</code> and <code>RSQLite</code> both build on the <code>DBI</code> package, which generalizes how we can interact with SQL-type databases via R. This makes it straightforward to apply what we have learned so far by interacting with our local SQLite database to interactions with other databases. As soon as the connection to the new database is established, we can essentially use the same R functions as before to create new tables and import data.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="data-collection-and-data-storage.html#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import data into current R session</span></span>
<span id="cb229-2"><a href="data-collection-and-data-storage.html#cb229-2" aria-hidden="true" tabindex="-1"></a>flights <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/flights.csv&quot;</span>)</span>
<span id="cb229-3"><a href="data-collection-and-data-storage.html#cb229-3" aria-hidden="true" tabindex="-1"></a>airports <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/airports.csv&quot;</span>)</span>
<span id="cb229-4"><a href="data-collection-and-data-storage.html#cb229-4" aria-hidden="true" tabindex="-1"></a>carriers <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/carriers.csv&quot;</span>)</span>
<span id="cb229-5"><a href="data-collection-and-data-storage.html#cb229-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb229-6"><a href="data-collection-and-data-storage.html#cb229-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add tables to database</span></span>
<span id="cb229-7"><a href="data-collection-and-data-storage.html#cb229-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_rds, <span class="st">&quot;flights&quot;</span>, flights)</span>
<span id="cb229-8"><a href="data-collection-and-data-storage.html#cb229-8" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_rds, <span class="st">&quot;airports&quot;</span>, airports)</span>
<span id="cb229-9"><a href="data-collection-and-data-storage.html#cb229-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con_rds, <span class="st">&quot;carriers&quot;</span>, carriers)</span></code></pre></div>
<p>Finally, we can query our RDS MySQL database on AWS.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="data-collection-and-data-storage.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define query</span></span>
<span id="cb230-2"><a href="data-collection-and-data-storage.html#cb230-2" aria-hidden="true" tabindex="-1"></a>delay_query <span class="ot">&lt;-</span></span>
<span id="cb230-3"><a href="data-collection-and-data-storage.html#cb230-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;SELECT </span></span>
<span id="cb230-4"><a href="data-collection-and-data-storage.html#cb230-4" aria-hidden="true" tabindex="-1"></a><span class="st">year,</span></span>
<span id="cb230-5"><a href="data-collection-and-data-storage.html#cb230-5" aria-hidden="true" tabindex="-1"></a><span class="st">month, </span></span>
<span id="cb230-6"><a href="data-collection-and-data-storage.html#cb230-6" aria-hidden="true" tabindex="-1"></a><span class="st">day,</span></span>
<span id="cb230-7"><a href="data-collection-and-data-storage.html#cb230-7" aria-hidden="true" tabindex="-1"></a><span class="st">dep_delay,</span></span>
<span id="cb230-8"><a href="data-collection-and-data-storage.html#cb230-8" aria-hidden="true" tabindex="-1"></a><span class="st">flight</span></span>
<span id="cb230-9"><a href="data-collection-and-data-storage.html#cb230-9" aria-hidden="true" tabindex="-1"></a><span class="st">FROM (flights INNER JOIN airports ON flights.origin=airports.iata) </span></span>
<span id="cb230-10"><a href="data-collection-and-data-storage.html#cb230-10" aria-hidden="true" tabindex="-1"></a><span class="st">INNER JOIN carriers ON flights.carrier = carriers.Code</span></span>
<span id="cb230-11"><a href="data-collection-and-data-storage.html#cb230-11" aria-hidden="true" tabindex="-1"></a><span class="st">WHERE carriers.Description = &#39;United Air Lines Inc.&#39;</span></span>
<span id="cb230-12"><a href="data-collection-and-data-storage.html#cb230-12" aria-hidden="true" tabindex="-1"></a><span class="st">AND airports.airport = &#39;Newark Intl&#39;</span></span>
<span id="cb230-13"><a href="data-collection-and-data-storage.html#cb230-13" aria-hidden="true" tabindex="-1"></a><span class="st">ORDER BY flight</span></span>
<span id="cb230-14"><a href="data-collection-and-data-storage.html#cb230-14" aria-hidden="true" tabindex="-1"></a><span class="st">LIMIT 10;</span></span>
<span id="cb230-15"><a href="data-collection-and-data-storage.html#cb230-15" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb230-16"><a href="data-collection-and-data-storage.html#cb230-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-17"><a href="data-collection-and-data-storage.html#cb230-17" aria-hidden="true" tabindex="-1"></a><span class="co"># issue query</span></span>
<span id="cb230-18"><a href="data-collection-and-data-storage.html#cb230-18" aria-hidden="true" tabindex="-1"></a>delays_df <span class="ot">&lt;-</span> <span class="fu">dbGetQuery</span>(con_rds, delay_query)</span>
<span id="cb230-19"><a href="data-collection-and-data-storage.html#cb230-19" aria-hidden="true" tabindex="-1"></a>delays_df</span>
<span id="cb230-20"><a href="data-collection-and-data-storage.html#cb230-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-21"><a href="data-collection-and-data-storage.html#cb230-21" aria-hidden="true" tabindex="-1"></a><span class="co"># clean up</span></span>
<span id="cb230-22"><a href="data-collection-and-data-storage.html#cb230-22" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con_rds)</span></code></pre></div>
</div>
</div>
<div id="column-based-analytics-databases" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Column-based analytics databases<a href="data-collection-and-data-storage.html#column-based-analytics-databases" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As outlined in the discussion of row-based vs. column-based databases above, many data analytics tasks focus on few columns but many rows, hence making column-based databases the better option for large-scale analytics purposes. <a href="https://druid.apache.org/">Apache Druid</a> <span class="citation">(<a href="#ref-Druid" role="doc-biblioref">Yang et al. 2014</a>)</span> is one such solution that has particular advantages for the data analytics perspective taken in this book. It can easily be run on a local machine (Linux and Mac/OSX), or on a cluster in the cloud, and it easily allows for connections to external data, for example, data stored on Google Cloud Storage. Moreover, it can be interfaced by <code>RDruid</code> <span class="citation">(<a href="#ref-RDruid" role="doc-biblioref">Metamarkets Group Inc. 2023</a>)</span> to run Druid queries from within R, or, yet again, Druid can be directly queried via SQL.</p>
<p>To get started with Apache Druid, navigate to <a href="https://druid.apache.org/">https://druid.apache.org/</a>. Under <a href="https://druid.apache.org/downloads.html">downloads</a> you will find a link to download the latest stable release (at the time of writing this book: 24.0.0). On the Apache Druid landing page, you will also find a link <a href="https://druid.apache.org/docs/latest/tutorials/index.html">Quickstart</a> with all the details regarding the installation and set up. Importantly, as of the time of writing this book, only Linux and MacOSX are supported (Windows is not supported).</p>
<div id="installation-and-start-up" class="section level3 hasAnchor" number="8.6.1">
<h3><span class="header-section-number">8.6.1</span> Installation and start up<a href="data-collection-and-data-storage.html#installation-and-start-up" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On Linux, follow these steps to set up Apache Druid on your machine. First, open a terminal and download the Druid binary to the location in which you want to work with Druid. First, we download and unpack the current Apache Druid version via the terminal.</p>
<p>Using Druid in its most basic form is then straightforward. Simply navigate to the unpacked folder and run <code>./bin/start-micro-quickstart</code>.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb231-1"><a href="data-collection-and-data-storage.html#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="co"># navigate to local copy of druid</span></span>
<span id="cb231-2"><a href="data-collection-and-data-storage.html#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> apache-druid-24.0.0</span>
<span id="cb231-3"><a href="data-collection-and-data-storage.html#cb231-3" aria-hidden="true" tabindex="-1"></a><span class="co"># start up druid (basic/minimal settings)</span></span>
<span id="cb231-4"><a href="data-collection-and-data-storage.html#cb231-4" aria-hidden="true" tabindex="-1"></a><span class="ex">./bin/start-micro-quickstart</span></span></code></pre></div>
</div>
<div id="first-steps-via-druids-gui" class="section level3 hasAnchor" number="8.6.2">
<h3><span class="header-section-number">8.6.2</span> First steps via Druid’s GUI<a href="data-collection-and-data-storage.html#first-steps-via-druids-gui" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once all Druid services are running, open a new browser window and navigate to <code>http://localhost:8888</code>. This will open Druid’s graphical user interface (GUI). The GUI provides easy-to-use interfaces to all basic Druid services, ranging from the loading of data to querying via Druid’s SQL. Figure <a href="data-collection-and-data-storage.html#fig:druidstart">8.5</a> highlights the GUI buttons mentioned in the instructions below.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:druidstart"></span>
<img src="img/druidstart.png" alt="Apache Druid GUI starting page. White boxes highlight buttons to the Druid services discussed in the main text (from left to right): the query editor (run Druid SQL queries on any of the loaded datasources directly here); the data load service (use this to import data from local files); and the Datasources console (lists all currently available data sources)." width="99%" />
<p class="caption">
Figure 8.5: Apache Druid GUI starting page. White boxes highlight buttons to the Druid services discussed in the main text (from left to right): the query editor (run Druid SQL queries on any of the loaded datasources directly here); the data load service (use this to import data from local files); and the Datasources console (lists all currently available data sources).
</p>
</div>

<div id="load-data-into-druid" class="section level4 hasAnchor" number="8.6.2.1">
<h4><span class="header-section-number">8.6.2.1</span> Load data into Druid<a href="data-collection-and-data-storage.html#load-data-into-druid" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In a first step, we will import the TLC taxi trips dataset from the locally stored CSV file. To do so, click on <em>Load data/Batch - classic</em>, then click on <em>Start new batch spec</em> and then select <em>Local disk</em>. On the right side of the Druid GUI, a menu will open. In the <code>Base directory</code> field, enter the path to the local directory in which you have stored the TLC taxi trips CSV file used in the examples above (<code>../data/</code>).<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> In the <code>File filter</code> field, enter <code>tlc_trips.csv</code>.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a> Finally click on the <em>Apply</em> button.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:druidparse"></span>
<img src="img/druidparse.png" alt="Apache Druid GUI: CSV parse menu for classic batch data ingestion." width="99%" />
<p class="caption">
Figure 8.6: Apache Druid GUI: CSV parse menu for classic batch data ingestion.
</p>
</div>

<p>The first few lines of the raw data will appear in the Druid console. In the lower-right corner of the console, click on <em>Next: Parse data</em>. Druid will automatically guess the delimiter used in the CSV (following the examples above, this is <code>,</code>) and present the first few parsed rows.</p>
<p>If all looks good, click on <em>Next: Parse time</em> in the lower-right corner of the console. Druid is implemented to work particularly fast on time-series and panel data. To this end, it expects you to define a main time-variable in your dataset, which then can be used to index and partition your overall dataset to speed up queries for specific time frames. Per default, Druid will suggest using the first column that looks like a time format (in the TLC-data, this would be column 2, the pick-up time of a trip, which seems very reasonable for the sake of this example). We move on with a click on <em>Next: Transform</em> in the lower right corner. Druid allows you, right at the step of loading data, to add or transform variables/columns. As we do not need to change anything at this point, we continue with <em>Next: Filter</em> in the lower-right corner. At this stage you can filter out rows/observations that you are sure should not be included in any of the queries/analyses performed later via Druid.</p>
<p>For this example, we do not filter out any observations and continue via <em>Next: Configure schema</em> in the lower-right corner. Druid guesses the schema/data types for each column based on sampling the first few observations in the dataset. Notice, for example, how Druid considers <code>vendor_name</code> to be a <code>string</code> and <code>Trip_distance</code> to be a <code>double</code> (a 64-bit floating point number). In most applications of Druid for the data analytics perspective of this book, the guessed data types will be just fine. We will leave the data types as-is and keep the original column/variable names. You can easily change names of variables/columns by double-clicking on the corresponding column name, which will open a menu on the right-hand side of the console. With this, all the main parameters to load the data are defined. What follows has to do with optimizing Druid’s performance.</p>
<p>Once you click on <em>Next: Partition</em> in the lower-right corner, you will have to choose the primary partitioning, which is always based on time (again, this has to do with Druid being optimized to work on large time-series and panel datasets). Basically, you need to decide whether the data should be organized into chunks per year, month, week, etc. For this example, we will segment the data according to months. To this end, from the drop-down menu under <code>Segment granularity</code>, choose <code>month</code>. For the rest of the parameters, we keep the default values. Continue by clicking on <em>Next: Tune</em> (we do not change anything here) and then on <em>Next: Publish</em>. In the menu that appears, you can choose the name under which the TLC taxi trips data should be listed in the <em>Datasources</em> menu on your local Druid installation, once all the data is loaded/processed. Thinking of SQL queries when working with Druid, the <code>Datasource name</code> is what you then will use in the <code>FROM</code> statement of a Druid SQL query (in analogy to a table name in the case of RDBMSs like SQLite). We keep the suggested name <code>tlc_trips</code>. Thus, you can click on <em>Edit spec</em> in the lower-right corner. An editor window will open and display all your load configurations as a JSON file. Only change anything at this step if you really know what you are doing. Finally, click on <em>Submit</em> in the lower-right corner. This will trigger the loading of data into Druid. As in the case of the RDBMS covered above, the data ingestion or data loading process primarily involves indexing and writing data to disk. It does not mean importing data to RAM. Since the CSV file used in this example is rather large, this process can take several minutes on a modern laptop computer.</p>
<p>Once the data ingestion is finished, click on the <em>Datasources</em> tab in the top menu bar to verify the ingestion. The <code>tlc_trips</code> dataset should now appear in the list of data sources in Druid.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:druiddatasources"></span>
<img src="img/druiddatasources.png" alt="Apache Druid: Datasources console." width="99%" />
<p class="caption">
Figure 8.7: Apache Druid: Datasources console.
</p>
</div>

</div>
<div id="query-druid-via-the-gui-sql-console" class="section level4 hasAnchor" number="8.6.2.2">
<h4><span class="header-section-number">8.6.2.2</span> Query Druid via the GUI SQL console<a href="data-collection-and-data-storage.html#query-druid-via-the-gui-sql-console" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Once the data is loaded into Druid, we can directly query it via the SQL console in Druid’s GUI. To do this, navigate in Druid to <em>Query</em>. To illustrate the strengths of Druid as an analytic database, we run an extensive data aggregation query. Specifically, we count the number of cases (trips) per vendor and split the no. of trips per vendor further by payment type.</p>
<pre><code>SELECT
vendor_name,
Payment_Type,
COUNT(*) AS Count_trips
FROM tlc_trips
GROUP BY vendor_name, Payment_Type</code></pre>
<p>Note that for such simple queries, Druid SQL is essentially identical to the SQL dialects covered in previous chapters and subsections, which makes it rather simple for beginners to start productively engaging with Druid. SQL queries can directly be entered in the query tab, a click on <em>Run</em> will send the query to Druid, and the results are shown right below.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:druidquery"></span>
<img src="img/druidquery.png" alt="Apache Druid query console with Druid-SQL example: count the number of cases per vendor and payment type." width="99%" />
<p class="caption">
Figure 8.8: Apache Druid query console with Druid-SQL example: count the number of cases per vendor and payment type.
</p>
</div>

<p>Counting the number of taxi trips per vendor name and payment type implies using the entire dataset of over 27 million rows (1.5GB). Nevertheless, Druid needs less than a second and hardly any RAM to compute the results.</p>
</div>
</div>
<div id="query-druid-from-r" class="section level3 hasAnchor" number="8.6.3">
<h3><span class="header-section-number">8.6.3</span> Query Druid from R<a href="data-collection-and-data-storage.html#query-druid-from-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Apache provides high-level interfaces to Druid for several languages common in data science/data analytics. The <code>RDruid</code> package provides such a Druid connector for R. The package can be installed from GitHub via the <code>devtools</code> package.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="data-collection-and-data-storage.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install devtools if necessary</span></span>
<span id="cb233-2"><a href="data-collection-and-data-storage.html#cb233-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(<span class="st">&quot;devtools&quot;</span>)) {</span>
<span id="cb233-3"><a href="data-collection-and-data-storage.html#cb233-3" aria-hidden="true" tabindex="-1"></a>     <span class="fu">install.packages</span>(<span class="st">&quot;devtools&quot;</span>)}</span>
<span id="cb233-4"><a href="data-collection-and-data-storage.html#cb233-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-5"><a href="data-collection-and-data-storage.html#cb233-5" aria-hidden="true" tabindex="-1"></a><span class="co"># install RDruid</span></span>
<span id="cb233-6"><a href="data-collection-and-data-storage.html#cb233-6" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;druid-io/RDruid&quot;</span>)</span></code></pre></div>
<p>The <code>RDruid</code> package provides several high-level functions to issue specific Druid queries; however, the syntax might not be straightforward for beginners, and the package has not been further developed for many years.</p>
<p>Thanks to Druid’s basic architecture as a web application, however, there is a simple alternative to the <code>RDruid</code> package. Druid accepts queries via HTTP POST calls (with SQL queries embedded in a JSON file sent in the HTTP body). The data is then returned as a compressed JSON string in the HTTP response to the POST request. We can build on this to implement our own simple <code>druid()</code> function to query Druid from R.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="data-collection-and-data-storage.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create R function to query Druid (locally)</span></span>
<span id="cb234-2"><a href="data-collection-and-data-storage.html#cb234-2" aria-hidden="true" tabindex="-1"></a>druid <span class="ot">&lt;-</span> </span>
<span id="cb234-3"><a href="data-collection-and-data-storage.html#cb234-3" aria-hidden="true" tabindex="-1"></a>     <span class="cf">function</span>(query){</span>
<span id="cb234-4"><a href="data-collection-and-data-storage.html#cb234-4" aria-hidden="true" tabindex="-1"></a>          <span class="co"># dependencies</span></span>
<span id="cb234-5"><a href="data-collection-and-data-storage.html#cb234-5" aria-hidden="true" tabindex="-1"></a>          <span class="fu">require</span>(jsonlite)</span>
<span id="cb234-6"><a href="data-collection-and-data-storage.html#cb234-6" aria-hidden="true" tabindex="-1"></a>          <span class="fu">require</span>(httr)</span>
<span id="cb234-7"><a href="data-collection-and-data-storage.html#cb234-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">require</span>(data.table)</span>
<span id="cb234-8"><a href="data-collection-and-data-storage.html#cb234-8" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb234-9"><a href="data-collection-and-data-storage.html#cb234-9" aria-hidden="true" tabindex="-1"></a>          <span class="co"># basic POST body</span></span>
<span id="cb234-10"><a href="data-collection-and-data-storage.html#cb234-10" aria-hidden="true" tabindex="-1"></a>          base_query <span class="ot">&lt;-</span>  </span>
<span id="cb234-11"><a href="data-collection-and-data-storage.html#cb234-11" aria-hidden="true" tabindex="-1"></a>          <span class="st">&#39;{</span></span>
<span id="cb234-12"><a href="data-collection-and-data-storage.html#cb234-12" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;context&quot;: {</span></span>
<span id="cb234-13"><a href="data-collection-and-data-storage.html#cb234-13" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;sqlOuterLimit&quot;: 1001,</span></span>
<span id="cb234-14"><a href="data-collection-and-data-storage.html#cb234-14" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;sqlQueryId&quot;: &quot;1&quot;},</span></span>
<span id="cb234-15"><a href="data-collection-and-data-storage.html#cb234-15" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;header&quot;: true,</span></span>
<span id="cb234-16"><a href="data-collection-and-data-storage.html#cb234-16" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;query&quot;: &quot;&quot;,</span></span>
<span id="cb234-17"><a href="data-collection-and-data-storage.html#cb234-17" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;resultFormat&quot;: &quot;csv&quot;,</span></span>
<span id="cb234-18"><a href="data-collection-and-data-storage.html#cb234-18" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;sqlTypesHeader&quot;: false,</span></span>
<span id="cb234-19"><a href="data-collection-and-data-storage.html#cb234-19" aria-hidden="true" tabindex="-1"></a><span class="st">          &quot;typesHeader&quot;: false</span></span>
<span id="cb234-20"><a href="data-collection-and-data-storage.html#cb234-20" aria-hidden="true" tabindex="-1"></a><span class="st">          }&#39;</span></span>
<span id="cb234-21"><a href="data-collection-and-data-storage.html#cb234-21" aria-hidden="true" tabindex="-1"></a>          param_list <span class="ot">&lt;-</span> <span class="fu">fromJSON</span>(base_query)</span>
<span id="cb234-22"><a href="data-collection-and-data-storage.html#cb234-22" aria-hidden="true" tabindex="-1"></a>          <span class="co"># add SQL query</span></span>
<span id="cb234-23"><a href="data-collection-and-data-storage.html#cb234-23" aria-hidden="true" tabindex="-1"></a>          param_list<span class="sc">$</span>query <span class="ot">&lt;-</span> query</span>
<span id="cb234-24"><a href="data-collection-and-data-storage.html#cb234-24" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb234-25"><a href="data-collection-and-data-storage.html#cb234-25" aria-hidden="true" tabindex="-1"></a>          <span class="co"># send query; parse result</span></span>
<span id="cb234-26"><a href="data-collection-and-data-storage.html#cb234-26" aria-hidden="true" tabindex="-1"></a>          resp <span class="ot">&lt;-</span> <span class="fu">POST</span>(<span class="st">&quot;http://localhost:8888/druid/v2/sql&quot;</span>, </span>
<span id="cb234-27"><a href="data-collection-and-data-storage.html#cb234-27" aria-hidden="true" tabindex="-1"></a>                       <span class="at">body =</span> param_list, </span>
<span id="cb234-28"><a href="data-collection-and-data-storage.html#cb234-28" aria-hidden="true" tabindex="-1"></a>                       <span class="at">encode =</span> <span class="st">&quot;json&quot;</span>)</span>
<span id="cb234-29"><a href="data-collection-and-data-storage.html#cb234-29" aria-hidden="true" tabindex="-1"></a>          parsed <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="fu">content</span>(resp, <span class="at">as =</span> <span class="st">&quot;text&quot;</span>, <span class="at">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>))</span>
<span id="cb234-30"><a href="data-collection-and-data-storage.html#cb234-30" aria-hidden="true" tabindex="-1"></a>          <span class="fu">return</span>(parsed)</span>
<span id="cb234-31"><a href="data-collection-and-data-storage.html#cb234-31" aria-hidden="true" tabindex="-1"></a>     }</span></code></pre></div>
<p>Now we can send queries to our local Druid installation. Importantly, Druid needs to be started up in order to make this work. In the example below we start up Druid from within R via <code>system("apache-druid-24.0.0/bin/start-micro-quickstart")</code> (make sure that the working directory is set correctly before running this). Then, we send the same query as in the Druid GUI example from above.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="data-collection-and-data-storage.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="co"># start Druid</span></span>
<span id="cb235-2"><a href="data-collection-and-data-storage.html#cb235-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system</span>(<span class="st">&quot;apache-druid-24.0.0/bin/start-micro-quickstart&quot;</span>,</span>
<span id="cb235-3"><a href="data-collection-and-data-storage.html#cb235-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">intern =</span> <span class="cn">FALSE</span>, </span>
<span id="cb235-4"><a href="data-collection-and-data-storage.html#cb235-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">wait =</span> <span class="cn">FALSE</span>)</span>
<span id="cb235-5"><a href="data-collection-and-data-storage.html#cb235-5" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.sleep</span>(<span class="dv">30</span>) <span class="co"># wait for Druid to start up</span></span>
<span id="cb235-6"><a href="data-collection-and-data-storage.html#cb235-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-7"><a href="data-collection-and-data-storage.html#cb235-7" aria-hidden="true" tabindex="-1"></a><span class="co"># query tlc data</span></span>
<span id="cb235-8"><a href="data-collection-and-data-storage.html#cb235-8" aria-hidden="true" tabindex="-1"></a>query <span class="ot">&lt;-</span></span>
<span id="cb235-9"><a href="data-collection-and-data-storage.html#cb235-9" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb235-10"><a href="data-collection-and-data-storage.html#cb235-10" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT</span></span>
<span id="cb235-11"><a href="data-collection-and-data-storage.html#cb235-11" aria-hidden="true" tabindex="-1"></a><span class="st">vendor_name,</span></span>
<span id="cb235-12"><a href="data-collection-and-data-storage.html#cb235-12" aria-hidden="true" tabindex="-1"></a><span class="st">Payment_Type,</span></span>
<span id="cb235-13"><a href="data-collection-and-data-storage.html#cb235-13" aria-hidden="true" tabindex="-1"></a><span class="st">COUNT(*) AS Count_trips</span></span>
<span id="cb235-14"><a href="data-collection-and-data-storage.html#cb235-14" aria-hidden="true" tabindex="-1"></a><span class="st">FROM tlc_trips</span></span>
<span id="cb235-15"><a href="data-collection-and-data-storage.html#cb235-15" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY vendor_name, Payment_Type</span></span>
<span id="cb235-16"><a href="data-collection-and-data-storage.html#cb235-16" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span> </span>
<span id="cb235-17"><a href="data-collection-and-data-storage.html#cb235-17" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">druid</span>(query)</span>
<span id="cb235-18"><a href="data-collection-and-data-storage.html#cb235-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-19"><a href="data-collection-and-data-storage.html#cb235-19" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect result</span></span>
<span id="cb235-20"><a href="data-collection-and-data-storage.html#cb235-20" aria-hidden="true" tabindex="-1"></a>result</span></code></pre></div>
<pre><code>##    vendor_name Payment_Type Count_trips
## 1:         CMT         Cash     9618583
## 2:         CMT       Credit     2737111
## 3:         CMT      Dispute       16774
## 4:         CMT    No Charge       82142
## 5:         DDS         CASH     1332901
## 6:         DDS       CREDIT      320411
## 7:         VTS         CASH    10264988
## 8:         VTS       Credit     3099625</code></pre>
</div>
</div>
<div id="data-warehouses" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Data warehouses<a href="data-collection-and-data-storage.html#data-warehouses" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>Unlike RDBMSs, the main purpose of data warehouses is usually analytics and not the provision of data for everyday operations. Generally, data warehouses contain well-organized and well-structured data, but are not as stringent as RMDBS when it comes to organizing data in relational tables. Typically, they build on a table-based logic, but allow for nesting structures and more flexible storage approaches. They are designed to contain large amounts of data (via horizontal scaling) and are usually column-based. From the perspective of Big Data Analytics taken in this book, there are several suitable and easily accessible data warehouse solutions provided in the cloud. In the following example, we will introduce one such solution called <em>Google BigQuery</em>.</p>
<div id="data-warehouse-for-analytics-google-bigquery-example" class="section level3 hasAnchor" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> Data warehouse for analytics: Google BigQuery example<a href="data-collection-and-data-storage.html#data-warehouse-for-analytics-google-bigquery-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>
Google BigQuery is flexible regarding the upload and export of data and can be set up straightforwardly for a data analytics project with hardly any set up costs. The pricing schema is usage-based. Unless you store massive amounts of data on it, you will only be charged for the volume of data processed. Moreover, there is a straightforward R-interface to Google BigQuery called <a href="https://bigrquery.r-dbi.org/"><code>bigrquery</code></a>, which allows for the same R/SQL-syntax as R’s interfaces to traditional relational databases.</p>
<p><strong>Get started with <code>bigrquery</code></strong></p>
<p>To get started with Google BigQuery and <code>bigrquery</code> <span class="citation">(<a href="#ref-bigrquery" role="doc-biblioref">Wickham and Bryan 2022</a>)</span>, go to <a href="https://cloud.google.com/bigquery" class="uri">https://cloud.google.com/bigquery</a>. Click on “Try Big Query” (if new to this) or “Go to console” (if used previously). Create a Google Cloud project to use BigQuery with. Note that, as in general for Google Cloud services, you need to have a credit card registered with the project to do this. However, for learning and testing purposes, Google Cloud offers 1TB of free queries per month. All the examples shown below combined will not exceed this free tier. Finally, run <code>install.packages("bigrquery")</code> in R.</p>
<p>To set up an R session to interface with BigQuery, you need to indicate which Google BigQuery project you want to use for the billing (the <code>BILLING</code> variable in the example below), as well as the Google BigQuery project in which the data is stored that you want to query (the <code>PROJECT</code> variable below). This distinction is very useful because it easily allows you to query data from a large array of publicly available datasets on BigQuery. In the set up example code below, we use this option in order to access an existing and publicly available dataset (provided in the <code>bigquery-public-data</code> project) called <code>google_analytics_sample</code>. In fact, this dataset provides the raw Google Analytics data used in the Big-P example discussed in Chapter 2.</p>
<p>Finally, all that is left to do is to connect to BigQuery via the already familiar <code>dbConnect()</code> function provided in <code>DBI</code>.<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a> When first connecting to and querying BigQuery with your Google Cloud account, a browser window will open, and you will be prompted to grant <code>bigrquery</code> access to your account/project. To do so, you will have to be logged in to your Google account. See the <strong>Important details</strong> section on <a href="https://bigrquery.r-dbi.org/" class="uri">https://bigrquery.r-dbi.org/</a> for details on the authentication.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="data-collection-and-data-storage.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages, credentials</span></span>
<span id="cb237-2"><a href="data-collection-and-data-storage.html#cb237-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bigrquery)</span>
<span id="cb237-3"><a href="data-collection-and-data-storage.html#cb237-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb237-4"><a href="data-collection-and-data-storage.html#cb237-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DBI)</span>
<span id="cb237-5"><a href="data-collection-and-data-storage.html#cb237-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-6"><a href="data-collection-and-data-storage.html#cb237-6" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb237-7"><a href="data-collection-and-data-storage.html#cb237-7" aria-hidden="true" tabindex="-1"></a><span class="co"># the project ID on BigQuery (billing must be enabled)</span></span>
<span id="cb237-8"><a href="data-collection-and-data-storage.html#cb237-8" aria-hidden="true" tabindex="-1"></a>BILLING <span class="ot">&lt;-</span> <span class="st">&quot;bda-examples&quot;</span> </span>
<span id="cb237-9"><a href="data-collection-and-data-storage.html#cb237-9" aria-hidden="true" tabindex="-1"></a><span class="co"># the project name on BigQuery</span></span>
<span id="cb237-10"><a href="data-collection-and-data-storage.html#cb237-10" aria-hidden="true" tabindex="-1"></a>PROJECT <span class="ot">&lt;-</span> <span class="st">&quot;bigquery-public-data&quot;</span> </span>
<span id="cb237-11"><a href="data-collection-and-data-storage.html#cb237-11" aria-hidden="true" tabindex="-1"></a>DATASET <span class="ot">&lt;-</span> <span class="st">&quot;google_analytics_sample&quot;</span></span>
<span id="cb237-12"><a href="data-collection-and-data-storage.html#cb237-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-13"><a href="data-collection-and-data-storage.html#cb237-13" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to DB on BigQuery</span></span>
<span id="cb237-14"><a href="data-collection-and-data-storage.html#cb237-14" aria-hidden="true" tabindex="-1"></a>con <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(</span>
<span id="cb237-15"><a href="data-collection-and-data-storage.html#cb237-15" aria-hidden="true" tabindex="-1"></a>     bigrquery<span class="sc">::</span><span class="fu">bigquery</span>(),</span>
<span id="cb237-16"><a href="data-collection-and-data-storage.html#cb237-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">project =</span> PROJECT,</span>
<span id="cb237-17"><a href="data-collection-and-data-storage.html#cb237-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">dataset =</span> DATASET,</span>
<span id="cb237-18"><a href="data-collection-and-data-storage.html#cb237-18" aria-hidden="true" tabindex="-1"></a>     <span class="at">billing =</span> BILLING</span>
<span id="cb237-19"><a href="data-collection-and-data-storage.html#cb237-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><strong>Get familiar with BigQuery</strong></p>
<p>The basic query syntax is now essentially identical to what we have covered in the RDBMS examples above.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a> In this first query, we count the number of times a Google merchandise shop visit originates from a given web domain on August 1, 2017 (hence the query to table <code>ga_sessions_20170801</code>). Note the way we refer to the specific table (in the <code>FROM</code> statement of the query below): <code>bigquery-public-data</code> is the pointer to the BigQuery project, <code>google_analytics_sample</code> is the name of the data warehouse, and <code>ga_sessions_20170801</code> is the name of the specific table we want to query data from. Finally, note the argument <code>page_size=15000</code> as part of the familiar <code>dbGetQuery()</code> function. This ensures that <code>bigrquery</code> does not exceed the limit of volume per second for downloads via the Google BigQuery API (on which <code>bigrquery</code> builds).</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="data-collection-and-data-storage.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run query</span></span>
<span id="cb238-2"><a href="data-collection-and-data-storage.html#cb238-2" aria-hidden="true" tabindex="-1"></a>query <span class="ot">&lt;-</span></span>
<span id="cb238-3"><a href="data-collection-and-data-storage.html#cb238-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb238-4"><a href="data-collection-and-data-storage.html#cb238-4" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT DISTINCT trafficSource.source AS origin,</span></span>
<span id="cb238-5"><a href="data-collection-and-data-storage.html#cb238-5" aria-hidden="true" tabindex="-1"></a><span class="st">COUNT(trafficSource.source) AS no_occ</span></span>
<span id="cb238-6"><a href="data-collection-and-data-storage.html#cb238-6" aria-hidden="true" tabindex="-1"></a><span class="st">FROM `bigquery-public-data.google_analytics_sample.ga_sessions_20170801`</span></span>
<span id="cb238-7"><a href="data-collection-and-data-storage.html#cb238-7" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY trafficSource.source</span></span>
<span id="cb238-8"><a href="data-collection-and-data-storage.html#cb238-8" aria-hidden="true" tabindex="-1"></a><span class="st">ORDER BY no_occ DESC;</span></span>
<span id="cb238-9"><a href="data-collection-and-data-storage.html#cb238-9" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb238-10"><a href="data-collection-and-data-storage.html#cb238-10" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> <span class="fu">as.data.table</span>(<span class="fu">dbGetQuery</span>(con, query, <span class="at">page_size=</span><span class="dv">15000</span>))</span>
<span id="cb238-11"><a href="data-collection-and-data-storage.html#cb238-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(ga)</span></code></pre></div>
<p>Note the output displayed in the console. <code>bigrquery</code> indicates how much data volume was processed as part of the query (which indicates what will be charged to your billing project),</p>
<p><strong>Upload data to BigQuery</strong></p>
<p>Storing your entire raw dataset on BigQuery is straightforward with <code>bigrquery</code>. In the following simple example, we upload the previously gathered and locally stored TLC tax trips data. To do so, we first create and connect to a new dataset on BigQuery. To keep things simple, we initialize the new dataset in the same project used for the billing.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="data-collection-and-data-storage.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="co"># name of the dataset to be created</span></span>
<span id="cb239-2"><a href="data-collection-and-data-storage.html#cb239-2" aria-hidden="true" tabindex="-1"></a>DATASET <span class="ot">&lt;-</span> <span class="st">&quot;tlc&quot;</span></span>
<span id="cb239-3"><a href="data-collection-and-data-storage.html#cb239-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb239-4"><a href="data-collection-and-data-storage.html#cb239-4" aria-hidden="true" tabindex="-1"></a><span class="co"># connect and initialize a new dataset</span></span>
<span id="cb239-5"><a href="data-collection-and-data-storage.html#cb239-5" aria-hidden="true" tabindex="-1"></a>con <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(</span>
<span id="cb239-6"><a href="data-collection-and-data-storage.html#cb239-6" aria-hidden="true" tabindex="-1"></a>     bigrquery<span class="sc">::</span><span class="fu">bigquery</span>(),</span>
<span id="cb239-7"><a href="data-collection-and-data-storage.html#cb239-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">project =</span> BILLING,</span>
<span id="cb239-8"><a href="data-collection-and-data-storage.html#cb239-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">billing =</span> BILLING,</span>
<span id="cb239-9"><a href="data-collection-and-data-storage.html#cb239-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">dataset =</span> DATASET</span>
<span id="cb239-10"><a href="data-collection-and-data-storage.html#cb239-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>In a first step, we create the dataset to which we then can add the table.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="data-collection-and-data-storage.html#cb240-1" aria-hidden="true" tabindex="-1"></a>tlc_ds <span class="ot">&lt;-</span> <span class="fu">bq_dataset</span>(BILLING, DATASET)</span>
<span id="cb240-2"><a href="data-collection-and-data-storage.html#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bq_dataset_create</span>(tlc_ds)</span></code></pre></div>
<p>We then load the TLC dataset into R via <code>fread()</code> and upload it as a new table to your project/dataset on BigQuery via <code>bigrquery</code>. For the sake of the example, we only upload the first 10,000 rows.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="data-collection-and-data-storage.html#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read data from csv</span></span>
<span id="cb241-2"><a href="data-collection-and-data-storage.html#cb241-2" aria-hidden="true" tabindex="-1"></a>tlc <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;data/tlc_trips.csv.gz&quot;</span>, <span class="at">nrows =</span> <span class="dv">10000</span>)</span>
<span id="cb241-3"><a href="data-collection-and-data-storage.html#cb241-3" aria-hidden="true" tabindex="-1"></a><span class="co"># write data to a new table</span></span>
<span id="cb241-4"><a href="data-collection-and-data-storage.html#cb241-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dbWriteTable</span>(con, <span class="at">name =</span> <span class="st">&quot;tlc_trips&quot;</span>, <span class="at">value =</span> tlc)</span></code></pre></div>
<p>Alternatively, you can easily upload data via the Google BigQuery console in the browser. Go to <a href="https://console.cloud.google.com/bigquery">https://console.cloud.google.com/bigquery</a>, select (or create) the project you want to upload data to, then in the <em>Explorer</em> section click on <em>+ ADD DATA</em>, and select the file you want to upload. You can either upload the data from disk, from Google Cloud Storage, or from a third-party connection. Uploading the data into BigQuery via Google Cloud Storage is particularly useful for large datasets.</p>
<p>Finally, we can test the newly created dataset/table with the following query</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="data-collection-and-data-storage.html#cb242-1" aria-hidden="true" tabindex="-1"></a>test_query <span class="ot">&lt;-</span></span>
<span id="cb242-2"><a href="data-collection-and-data-storage.html#cb242-2" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb242-3"><a href="data-collection-and-data-storage.html#cb242-3" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT * </span></span>
<span id="cb242-4"><a href="data-collection-and-data-storage.html#cb242-4" aria-hidden="true" tabindex="-1"></a><span class="st">FROM tlc.tlc_trips</span></span>
<span id="cb242-5"><a href="data-collection-and-data-storage.html#cb242-5" aria-hidden="true" tabindex="-1"></a><span class="st">LIMIT 10</span></span>
<span id="cb242-6"><a href="data-collection-and-data-storage.html#cb242-6" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb242-7"><a href="data-collection-and-data-storage.html#cb242-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> <span class="fu">dbGetQuery</span>(con, test_query)</span></code></pre></div>
<p><strong>Tutorial: Retrieve and prepare Google Analytics data</strong></p>
<p>The following tutorial illustrates how the raw data for the Big-P example in Chapter 2 was collected and prepared via Google BigQuery and R. Before we get started, note an important aspect of a data warehouse solution like BigQuery in contrast to common applications of RDBS. As data warehouses are used in a more flexible way than relational databases, it is not uncommon to store data files/tables containing the same variables separately in various tables, for example to store one table per day or year of a panel dataset. On Google BigQuery, this partitioning of datasets into several components can additionally make sense for cost reasons. Suppose you want to only compute summary statistics for certain variables over a given time frame. If all observations of a large dataset are stored in one standard BigQuery table, such a query results in processing GBs or TBs of data, as the observations from the corresponding time frame need to be filtered out of the entire dataset. Partitioning the data into several subsets helps avoid this, as BigQuery has several features that allow the definition of SQL queries to be run on partitioned data. The publicly available Google Analytics dataset is organized in such a partitioned way. The data is stored in several tables (one for each day of the observation period), whereby the last few characters of the table name contain the date of the corresponding observation day (such as the one used in the example above: <code>ga_sessions_20170801</code>). If we want to combine data from several of those tables, we can use the wildcard character (<code>*</code>) to indicate that the BigQuery should consider all tables matching the table name up to the <code>*</code>: <code>FROM bigquery-public-data.google_analytics_sample.ga_sessions_*</code>.</p>
<p>We proceed by first connecting the R session with GoogleBigQuery.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="data-collection-and-data-storage.html#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix vars</span></span>
<span id="cb243-2"><a href="data-collection-and-data-storage.html#cb243-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the project ID on BigQuery (billing must be enabled)</span></span>
<span id="cb243-3"><a href="data-collection-and-data-storage.html#cb243-3" aria-hidden="true" tabindex="-1"></a>BILLING <span class="ot">&lt;-</span> <span class="st">&quot;YOUR-BILLING-PROJECT-ID&quot;</span></span>
<span id="cb243-4"><a href="data-collection-and-data-storage.html#cb243-4" aria-hidden="true" tabindex="-1"></a><span class="co"># the project name on BigQuery</span></span>
<span id="cb243-5"><a href="data-collection-and-data-storage.html#cb243-5" aria-hidden="true" tabindex="-1"></a>PROJECT <span class="ot">&lt;-</span> <span class="st">&quot;bigquery-public-data&quot;</span> </span>
<span id="cb243-6"><a href="data-collection-and-data-storage.html#cb243-6" aria-hidden="true" tabindex="-1"></a>DATASET <span class="ot">&lt;-</span> <span class="st">&quot;google_analytics_sample&quot;</span></span>
<span id="cb243-7"><a href="data-collection-and-data-storage.html#cb243-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb243-8"><a href="data-collection-and-data-storage.html#cb243-8" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to DB on BigQuery</span></span>
<span id="cb243-9"><a href="data-collection-and-data-storage.html#cb243-9" aria-hidden="true" tabindex="-1"></a>con <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(</span>
<span id="cb243-10"><a href="data-collection-and-data-storage.html#cb243-10" aria-hidden="true" tabindex="-1"></a>     bigrquery<span class="sc">::</span><span class="fu">bigquery</span>(),</span>
<span id="cb243-11"><a href="data-collection-and-data-storage.html#cb243-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">project =</span> PROJECT,</span>
<span id="cb243-12"><a href="data-collection-and-data-storage.html#cb243-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">dataset =</span> DATASET,</span>
<span id="cb243-13"><a href="data-collection-and-data-storage.html#cb243-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">billing =</span> BILLING</span>
<span id="cb243-14"><a href="data-collection-and-data-storage.html#cb243-14" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The query combines all Google Analytics data recorded from the beginning of 2016 to the end of 2017 via <code>WHERE _TABLE_SUFFIX BETWEEN '20160101' AND '20171231'</code>. This gives us all the raw data used in the Big-P analysis shown in Chapter 2.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="data-collection-and-data-storage.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run query</span></span>
<span id="cb244-2"><a href="data-collection-and-data-storage.html#cb244-2" aria-hidden="true" tabindex="-1"></a>query <span class="ot">&lt;-</span></span>
<span id="cb244-3"><a href="data-collection-and-data-storage.html#cb244-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb244-4"><a href="data-collection-and-data-storage.html#cb244-4" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT  </span></span>
<span id="cb244-5"><a href="data-collection-and-data-storage.html#cb244-5" aria-hidden="true" tabindex="-1"></a><span class="st">totals.visits, </span></span>
<span id="cb244-6"><a href="data-collection-and-data-storage.html#cb244-6" aria-hidden="true" tabindex="-1"></a><span class="st">totals.transactions, </span></span>
<span id="cb244-7"><a href="data-collection-and-data-storage.html#cb244-7" aria-hidden="true" tabindex="-1"></a><span class="st">trafficSource.source, </span></span>
<span id="cb244-8"><a href="data-collection-and-data-storage.html#cb244-8" aria-hidden="true" tabindex="-1"></a><span class="st">device.browser, </span></span>
<span id="cb244-9"><a href="data-collection-and-data-storage.html#cb244-9" aria-hidden="true" tabindex="-1"></a><span class="st">device.isMobile, </span></span>
<span id="cb244-10"><a href="data-collection-and-data-storage.html#cb244-10" aria-hidden="true" tabindex="-1"></a><span class="st">geoNetwork.city, </span></span>
<span id="cb244-11"><a href="data-collection-and-data-storage.html#cb244-11" aria-hidden="true" tabindex="-1"></a><span class="st">geoNetwork.country, </span></span>
<span id="cb244-12"><a href="data-collection-and-data-storage.html#cb244-12" aria-hidden="true" tabindex="-1"></a><span class="st">channelGrouping</span></span>
<span id="cb244-13"><a href="data-collection-and-data-storage.html#cb244-13" aria-hidden="true" tabindex="-1"></a><span class="st">FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`</span></span>
<span id="cb244-14"><a href="data-collection-and-data-storage.html#cb244-14" aria-hidden="true" tabindex="-1"></a><span class="st">WHERE _TABLE_SUFFIX BETWEEN &#39;20160101&#39; AND &#39;20171231&#39;;</span></span>
<span id="cb244-15"><a href="data-collection-and-data-storage.html#cb244-15" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb244-16"><a href="data-collection-and-data-storage.html#cb244-16" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> <span class="fu">as.data.table</span>(<span class="fu">dbGetQuery</span>(con, query, <span class="at">page_size=</span><span class="dv">15000</span>))</span></code></pre></div>
<p>Finally, we use <code>data.table</code> and basic R to prepare the final analytic dataset and write it on disk.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="data-collection-and-data-storage.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="co"># further cleaning and coding via data.table and basic R</span></span>
<span id="cb245-2"><a href="data-collection-and-data-storage.html#cb245-2" aria-hidden="true" tabindex="-1"></a>ga<span class="sc">$</span>transactions[<span class="fu">is.na</span>(ga<span class="sc">$</span>transactions)] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb245-3"><a href="data-collection-and-data-storage.html#cb245-3" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> ga[ga<span class="sc">$</span>city<span class="sc">!=</span><span class="st">&quot;not available in demo dataset&quot;</span>,]</span>
<span id="cb245-4"><a href="data-collection-and-data-storage.html#cb245-4" aria-hidden="true" tabindex="-1"></a>ga<span class="sc">$</span>purchase <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(<span class="dv">0</span><span class="sc">&lt;</span>ga<span class="sc">$</span>transactions)</span>
<span id="cb245-5"><a href="data-collection-and-data-storage.html#cb245-5" aria-hidden="true" tabindex="-1"></a>ga<span class="sc">$</span>transactions <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb245-6"><a href="data-collection-and-data-storage.html#cb245-6" aria-hidden="true" tabindex="-1"></a>ga_p <span class="ot">&lt;-</span> ga[purchase<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb245-7"><a href="data-collection-and-data-storage.html#cb245-7" aria-hidden="true" tabindex="-1"></a>ga_rest <span class="ot">&lt;-</span> ga[purchase<span class="sc">==</span><span class="dv">0</span>][<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(ga[purchase<span class="sc">==</span><span class="dv">0</span>]), <span class="dv">45000</span>)]</span>
<span id="cb245-8"><a href="data-collection-and-data-storage.html#cb245-8" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> <span class="fu">rbindlist</span>(<span class="fu">list</span>(ga_p, ga_rest))</span>
<span id="cb245-9"><a href="data-collection-and-data-storage.html#cb245-9" aria-hidden="true" tabindex="-1"></a>potential_sources <span class="ot">&lt;-</span> <span class="fu">table</span>(ga<span class="sc">$</span>source)</span>
<span id="cb245-10"><a href="data-collection-and-data-storage.html#cb245-10" aria-hidden="true" tabindex="-1"></a>potential_sources <span class="ot">&lt;-</span> <span class="fu">names</span>(potential_sources[<span class="dv">1</span><span class="sc">&lt;</span>potential_sources])</span>
<span id="cb245-11"><a href="data-collection-and-data-storage.html#cb245-11" aria-hidden="true" tabindex="-1"></a>ga <span class="ot">&lt;-</span> ga[ga<span class="sc">$</span>source <span class="sc">%in%</span> potential_sources,]</span>
<span id="cb245-12"><a href="data-collection-and-data-storage.html#cb245-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb245-13"><a href="data-collection-and-data-storage.html#cb245-13" aria-hidden="true" tabindex="-1"></a><span class="co"># store dataset on local hard disk</span></span>
<span id="cb245-14"><a href="data-collection-and-data-storage.html#cb245-14" aria-hidden="true" tabindex="-1"></a><span class="fu">fwrite</span>(ga, <span class="at">file=</span><span class="st">&quot;data/ga.csv&quot;</span>)</span>
<span id="cb245-15"><a href="data-collection-and-data-storage.html#cb245-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb245-16"><a href="data-collection-and-data-storage.html#cb245-16" aria-hidden="true" tabindex="-1"></a><span class="co"># clean up </span></span>
<span id="cb245-17"><a href="data-collection-and-data-storage.html#cb245-17" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con)</span></code></pre></div>
<p>Note how we combine BigQuery as our data warehouse with basic R for data preparation. Solutions like BigQuery are particularly useful for this kind of approach as part of an analytics project: Large operations such as the selection of columns/variables from large-scale data sources are handled within the warehouse in the cloud, and the refinement/cleaning steps can then be implemented locally on a much smaller subset.<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a></p>
<p>Note the wildcard-character (<code>*</code>) in the query is used to fetch data from several partitions of the overall dataset.</p>
</div>
</div>
<div id="data-lakes-and-simple-storage-service" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Data lakes and simple storage service<a href="data-collection-and-data-storage.html#data-lakes-and-simple-storage-service" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
</p>
<p>Broadly speaking a data lake is where all your data resides (these days, this is typically somewhere in the cloud). The data is simply stored in whatever file format and in simple terms organized in folders and sub-folders. In the same data lake you might thus store CSV files, SQL database dumps, log files, image files, raw text, etc. In addition, you typically have many options to define access rights to files, including to easily make them accessible for download to the public. For a simple data analytics project in the context of economic research or business analytics, the data lake in the cloud concept is a useful tool to store all project-related raw data files. On the one hand you avoid running into troubles with occupying gigabytes or terabytes of your local hard disk with files that are relevant but only rarely imported/worked with. On the other hand you can properly organize all the raw data for reproducibility purposes and easily share the files with colleagues (and eventually the public). For example, you can use one main folder (one “bucket”) for an entire analytics project, store all the raw data in one sub-folder (for reproduction purposes), and store all the final analytic datasets in another sub-folder for replication purposes and more frequent access as well as sharing across a team of co-workers.</p>
<p>There are several types of cloud-based data lake solutions available, many of which are primarily focused on corporate data storage and provide a variety of services (for example, AWS Lake Formation or Azure Data Lake) that might go well beyond the data analytics perspective taken in this book. However, most of these solutions build in the end on a so-called simple storage service such as AWS S3 or Google Cloud Storage, which build the core of the lake – the place where the data is actually stored and accessed. In the following, we will look at how to use such a simple storage service (AWS S3) as a data lake in simple analytics projects.<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a></p>
<p>Finally, we will look at a very interesting approach to combine the concept of a data lake with the concept of a data warehouse. That is, we briefly look at solutions of how some analytics tools (specifically, a tool called Amazon Athena) can directly be used to query/analyze the data stored in the simple storage service.</p>
<div id="aws-s3-with-r-first-steps" class="section level3 hasAnchor" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> AWS S3 with R: First steps<a href="data-collection-and-data-storage.html#aws-s3-with-r-first-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For the following first steps with AWS S3 and R, you will need an AWS account (same as above for EC2) and IAM credentials from your AWS account with the right to access S3.<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a> Finally, you will have to install the <code>aws.s3</code> package in R in order to access S3 via R: <code>install.packages("aws.s3")</code>.</p>
<p>To initiate an R session in which you connect to S3, <code>aws.s3</code> <span class="citation">(<a href="#ref-aws.s3" role="doc-biblioref">Leeper 2020</a>)</span> must be loaded and the following environment variables must be set:</p>
<ul>
<li><code>AWS_ACCESS_KEY_ID</code>: your access key ID (of the keypair with rights to use S3)</li>
<li><code>AWS_SECRET_KEY</code>: your access key (of the keypair with rights to use S3)</li>
<li><code>REGION</code>: the region in which your S3 buckets are/will be located (e.g., <code>"eu-central-1"</code>)</li>
</ul>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="data-collection-and-data-storage.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb246-2"><a href="data-collection-and-data-storage.html#cb246-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(aws.s3)</span>
<span id="cb246-3"><a href="data-collection-and-data-storage.html#cb246-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb246-4"><a href="data-collection-and-data-storage.html#cb246-4" aria-hidden="true" tabindex="-1"></a><span class="co"># set environment variables with your AWS S3 credentials</span></span>
<span id="cb246-5"><a href="data-collection-and-data-storage.html#cb246-5" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="st">&quot;AWS_ACCESS_KEY_ID&quot;</span> <span class="ot">=</span> AWS_ACCESS_KEY_ID,</span>
<span id="cb246-6"><a href="data-collection-and-data-storage.html#cb246-6" aria-hidden="true" tabindex="-1"></a>           <span class="st">&quot;AWS_SECRET_ACCESS_KEY&quot;</span> <span class="ot">=</span> AWS_SECRET_KEY,</span>
<span id="cb246-7"><a href="data-collection-and-data-storage.html#cb246-7" aria-hidden="true" tabindex="-1"></a>           <span class="st">&quot;AWS_DEFAULT_REGION&quot;</span> <span class="ot">=</span> REGION)</span></code></pre></div>
<p>In a first step, we create a project bucket (the main repository for our project) to store all the data of our analytics project. All the raw data can directly be placed in this main folder. Then, we add one sub-folder to this bucket: <code>analytic_data</code> (for the cleaned/prepared datasets underlying the analyses in the project).<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a></p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="data-collection-and-data-storage.html#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix variable for bucket name</span></span>
<span id="cb247-2"><a href="data-collection-and-data-storage.html#cb247-2" aria-hidden="true" tabindex="-1"></a>BUCKET <span class="ot">&lt;-</span> <span class="st">&quot;tlc-trips&quot;</span></span>
<span id="cb247-3"><a href="data-collection-and-data-storage.html#cb247-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create project bucket</span></span>
<span id="cb247-4"><a href="data-collection-and-data-storage.html#cb247-4" aria-hidden="true" tabindex="-1"></a><span class="fu">put_bucket</span>(BUCKET)</span>
<span id="cb247-5"><a href="data-collection-and-data-storage.html#cb247-5" aria-hidden="true" tabindex="-1"></a><span class="co"># create folders</span></span>
<span id="cb247-6"><a href="data-collection-and-data-storage.html#cb247-6" aria-hidden="true" tabindex="-1"></a><span class="fu">put_folder</span>(<span class="st">&quot;raw_data&quot;</span>, BUCKET)</span>
<span id="cb247-7"><a href="data-collection-and-data-storage.html#cb247-7" aria-hidden="true" tabindex="-1"></a><span class="fu">put_folder</span>(<span class="st">&quot;analytic_data&quot;</span>, BUCKET)</span></code></pre></div>
</div>
<div id="uploading-data-to-s3" class="section level3 hasAnchor" number="8.8.2">
<h3><span class="header-section-number">8.8.2</span> Uploading data to S3<a href="data-collection-and-data-storage.html#uploading-data-to-s3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we can start uploading the data to the bucket (and the sub-folder). For example, to remain within the context of the TLC taxi trips data, we upload the original Parquet files directly to the bucket, and the prepared CSV file to <code>analytic_data</code>. For large files (larger than 100MB) it is recommended to use the multipart option (upload of file in several parts; <code>multipart=TRUE</code>).</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="data-collection-and-data-storage.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="co"># upload to bucket</span></span>
<span id="cb248-2"><a href="data-collection-and-data-storage.html#cb248-2" aria-hidden="true" tabindex="-1"></a><span class="co"># final analytic dataset</span></span>
<span id="cb248-3"><a href="data-collection-and-data-storage.html#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="fu">put_object</span>(</span>
<span id="cb248-4"><a href="data-collection-and-data-storage.html#cb248-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> <span class="st">&quot;data/tlc_trips.csv&quot;</span>, <span class="co"># the file you want to upload</span></span>
<span id="cb248-5"><a href="data-collection-and-data-storage.html#cb248-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> <span class="st">&quot;analytic_data/tlc_trips.csv&quot;</span>, <span class="co"># name of the file in the bucket</span></span>
<span id="cb248-6"><a href="data-collection-and-data-storage.html#cb248-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">bucket =</span> BUCKET,</span>
<span id="cb248-7"><a href="data-collection-and-data-storage.html#cb248-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">multipart =</span> <span class="cn">TRUE</span></span>
<span id="cb248-8"><a href="data-collection-and-data-storage.html#cb248-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb248-9"><a href="data-collection-and-data-storage.html#cb248-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-10"><a href="data-collection-and-data-storage.html#cb248-10" aria-hidden="true" tabindex="-1"></a><span class="co"># upload raw data</span></span>
<span id="cb248-11"><a href="data-collection-and-data-storage.html#cb248-11" aria-hidden="true" tabindex="-1"></a>file_paths <span class="ot">&lt;-</span> <span class="fu">list.files</span>(<span class="st">&quot;data/tlc_trips/raw_data&quot;</span>, <span class="at">full.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb248-12"><a href="data-collection-and-data-storage.html#cb248-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(file_paths, </span>
<span id="cb248-13"><a href="data-collection-and-data-storage.html#cb248-13" aria-hidden="true" tabindex="-1"></a>       put_object, </span>
<span id="cb248-14"><a href="data-collection-and-data-storage.html#cb248-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">bucket=</span>BUCKET,</span>
<span id="cb248-15"><a href="data-collection-and-data-storage.html#cb248-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">multipart=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<!-- The code in the following section does not work properly yet, no high priority-->
</div>
<div id="more-than-just-simple-storage-s3-amazon-athena" class="section level3 hasAnchor" number="8.8.3">
<h3><span class="header-section-number">8.8.3</span> More than just simple storage: S3 + Amazon Athena<a href="data-collection-and-data-storage.html#more-than-just-simple-storage-s3-amazon-athena" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p></p>
<p>There are several implementations of interfaces with Amazon Athena in R. Here, we will rely on <code>AWR.Athena</code> <span class="citation">(<a href="#ref-AWR.Athena" role="doc-biblioref">Fultz and Daróczi 2019</a>)</span> (run <code>install.packages("AWR.Athena")</code>), which allows interacting with Amazon Athena via the familiar <code>DBI</code> package <span class="citation">(<a href="#ref-DBI" role="doc-biblioref">R Special Interest Group on Databases (R-SIG-DB), Wickham, and Müller 2022</a>)</span>.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="data-collection-and-data-storage.html#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SET UP -------------------------</span></span>
<span id="cb249-2"><a href="data-collection-and-data-storage.html#cb249-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb249-3"><a href="data-collection-and-data-storage.html#cb249-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb249-4"><a href="data-collection-and-data-storage.html#cb249-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DBI)</span>
<span id="cb249-5"><a href="data-collection-and-data-storage.html#cb249-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(aws.s3)</span>
<span id="cb249-6"><a href="data-collection-and-data-storage.html#cb249-6" aria-hidden="true" tabindex="-1"></a><span class="co"># aws credentials with Athena and S3 rights and region</span></span>
<span id="cb249-7"><a href="data-collection-and-data-storage.html#cb249-7" aria-hidden="true" tabindex="-1"></a>AWS_ACCESS_KEY_ID <span class="ot">&lt;-</span> <span class="st">&quot;YOUR_KEY_ID&quot;</span></span>
<span id="cb249-8"><a href="data-collection-and-data-storage.html#cb249-8" aria-hidden="true" tabindex="-1"></a>AWS_ACCESS_KEY <span class="ot">&lt;-</span> <span class="st">&quot;YOUR_KEY&quot;</span></span>
<span id="cb249-9"><a href="data-collection-and-data-storage.html#cb249-9" aria-hidden="true" tabindex="-1"></a>REGION <span class="ot">&lt;-</span> <span class="st">&quot;eu-central-1&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="data-collection-and-data-storage.html#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="co"># establish AWS connection</span></span>
<span id="cb250-2"><a href="data-collection-and-data-storage.html#cb250-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="st">&quot;AWS_ACCESS_KEY_ID&quot;</span> <span class="ot">=</span> AWS_ACCESS_KEY_ID,</span>
<span id="cb250-3"><a href="data-collection-and-data-storage.html#cb250-3" aria-hidden="true" tabindex="-1"></a>           <span class="st">&quot;AWS_SECRET_ACCESS_KEY&quot;</span> <span class="ot">=</span> AWS_ACCESS_KEY,</span>
<span id="cb250-4"><a href="data-collection-and-data-storage.html#cb250-4" aria-hidden="true" tabindex="-1"></a>           <span class="st">&quot;AWS_DEFAULT_REGION&quot;</span> <span class="ot">=</span> REGION)</span></code></pre></div>
<p>Create a bucket for the output.</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="data-collection-and-data-storage.html#cb251-1" aria-hidden="true" tabindex="-1"></a>OUTPUT_BUCKET <span class="ot">&lt;-</span> <span class="st">&quot;bda-athena&quot;</span></span>
<span id="cb251-2"><a href="data-collection-and-data-storage.html#cb251-2" aria-hidden="true" tabindex="-1"></a><span class="fu">put_bucket</span>(OUTPUT_BUCKET, <span class="at">region=</span><span class="st">&quot;us-east-1&quot;</span>)</span></code></pre></div>
<p>Now we can connect to Amazon Athena to query data from files in S3 via the <code>RJDBC</code> package <span class="citation">(<a href="#ref-RJDBC" role="doc-biblioref">Urbanek 2022</a>)</span>.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="data-collection-and-data-storage.html#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb252-2"><a href="data-collection-and-data-storage.html#cb252-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RJDBC)</span>
<span id="cb252-3"><a href="data-collection-and-data-storage.html#cb252-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DBI)</span>
<span id="cb252-4"><a href="data-collection-and-data-storage.html#cb252-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb252-5"><a href="data-collection-and-data-storage.html#cb252-5" aria-hidden="true" tabindex="-1"></a><span class="co"># download Athena JDBC driver</span></span>
<span id="cb252-6"><a href="data-collection-and-data-storage.html#cb252-6" aria-hidden="true" tabindex="-1"></a>URL <span class="ot">&lt;-</span> <span class="st">&quot;https://s3.amazonaws.com/athena-downloads/drivers/JDBC/&quot;</span></span>
<span id="cb252-7"><a href="data-collection-and-data-storage.html#cb252-7" aria-hidden="true" tabindex="-1"></a>VERSION <span class="ot">&lt;-</span> <span class="st">&quot;AthenaJDBC_1.1.0/AthenaJDBC41-1.1.0.jar&quot;</span></span>
<span id="cb252-8"><a href="data-collection-and-data-storage.html#cb252-8" aria-hidden="true" tabindex="-1"></a>DRV_FILE <span class="ot">&lt;-</span> <span class="st">&quot;AthenaJDBC41-1.1.0.jar&quot;</span></span>
<span id="cb252-9"><a href="data-collection-and-data-storage.html#cb252-9" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(<span class="fu">paste0</span>(URL, VERSION), <span class="at">destfile =</span> DRV_FILE)</span>
<span id="cb252-10"><a href="data-collection-and-data-storage.html#cb252-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb252-11"><a href="data-collection-and-data-storage.html#cb252-11" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to JDBC</span></span>
<span id="cb252-12"><a href="data-collection-and-data-storage.html#cb252-12" aria-hidden="true" tabindex="-1"></a>athena <span class="ot">&lt;-</span> <span class="fu">JDBC</span>(<span class="at">driverClass =</span> <span class="st">&quot;com.amazonaws.athena.jdbc.AthenaDriver&quot;</span>,</span>
<span id="cb252-13"><a href="data-collection-and-data-storage.html#cb252-13" aria-hidden="true" tabindex="-1"></a>  DRV_FILE, <span class="at">identifier.quote =</span> <span class="st">&quot;&#39;&quot;</span>)</span>
<span id="cb252-14"><a href="data-collection-and-data-storage.html#cb252-14" aria-hidden="true" tabindex="-1"></a><span class="co"># connect to Athena</span></span>
<span id="cb252-15"><a href="data-collection-and-data-storage.html#cb252-15" aria-hidden="true" tabindex="-1"></a>con <span class="ot">&lt;-</span> <span class="fu">dbConnect</span>(athena, <span class="st">&quot;jdbc:awsathena://athena.us-east-1.amazonaws.com:443/&quot;</span>,</span>
<span id="cb252-16"><a href="data-collection-and-data-storage.html#cb252-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">s3_staging_dir =</span> <span class="st">&quot;s3://bda-athena&quot;</span>, <span class="at">user =</span> AWS_ACCESS_KEY_ID,</span>
<span id="cb252-17"><a href="data-collection-and-data-storage.html#cb252-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">password =</span> AWS_ACCESS_KEY)</span></code></pre></div>
<p>In order to query data stored in S3 via Amazon Athena, we need to create an <em>external table</em> in Athena, which will be based on data stored in S3.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="data-collection-and-data-storage.html#cb253-1" aria-hidden="true" tabindex="-1"></a>query_create_table <span class="ot">&lt;-</span></span>
<span id="cb253-2"><a href="data-collection-and-data-storage.html#cb253-2" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb253-3"><a href="data-collection-and-data-storage.html#cb253-3" aria-hidden="true" tabindex="-1"></a><span class="st">CREATE EXTERNAL TABLE default.trips (</span></span>
<span id="cb253-4"><a href="data-collection-and-data-storage.html#cb253-4" aria-hidden="true" tabindex="-1"></a><span class="st">  `vendor_name` string,</span></span>
<span id="cb253-5"><a href="data-collection-and-data-storage.html#cb253-5" aria-hidden="true" tabindex="-1"></a><span class="st">  `Trip_Pickup_DateTime` string,</span></span>
<span id="cb253-6"><a href="data-collection-and-data-storage.html#cb253-6" aria-hidden="true" tabindex="-1"></a><span class="st">  `Trip_Dropoff_DateTime` string,</span></span>
<span id="cb253-7"><a href="data-collection-and-data-storage.html#cb253-7" aria-hidden="true" tabindex="-1"></a><span class="st">  `Passenger_Count` int,</span></span>
<span id="cb253-8"><a href="data-collection-and-data-storage.html#cb253-8" aria-hidden="true" tabindex="-1"></a><span class="st">  `Trip_Distance` double,</span></span>
<span id="cb253-9"><a href="data-collection-and-data-storage.html#cb253-9" aria-hidden="true" tabindex="-1"></a><span class="st">  `Start_Lon` double,</span></span>
<span id="cb253-10"><a href="data-collection-and-data-storage.html#cb253-10" aria-hidden="true" tabindex="-1"></a><span class="st">  `Start_Lat` double,</span></span>
<span id="cb253-11"><a href="data-collection-and-data-storage.html#cb253-11" aria-hidden="true" tabindex="-1"></a><span class="st">  `Rate_Code` string,</span></span>
<span id="cb253-12"><a href="data-collection-and-data-storage.html#cb253-12" aria-hidden="true" tabindex="-1"></a><span class="st">  `store_and_forward` string,</span></span>
<span id="cb253-13"><a href="data-collection-and-data-storage.html#cb253-13" aria-hidden="true" tabindex="-1"></a><span class="st">  `End_Lon` double,</span></span>
<span id="cb253-14"><a href="data-collection-and-data-storage.html#cb253-14" aria-hidden="true" tabindex="-1"></a><span class="st">  `End_Lat` double,</span></span>
<span id="cb253-15"><a href="data-collection-and-data-storage.html#cb253-15" aria-hidden="true" tabindex="-1"></a><span class="st">  `Payment_Type` string,</span></span>
<span id="cb253-16"><a href="data-collection-and-data-storage.html#cb253-16" aria-hidden="true" tabindex="-1"></a><span class="st">  `Fare_Amt` double,</span></span>
<span id="cb253-17"><a href="data-collection-and-data-storage.html#cb253-17" aria-hidden="true" tabindex="-1"></a><span class="st">  `surcharge` double,</span></span>
<span id="cb253-18"><a href="data-collection-and-data-storage.html#cb253-18" aria-hidden="true" tabindex="-1"></a><span class="st">  `mta_tax` string,</span></span>
<span id="cb253-19"><a href="data-collection-and-data-storage.html#cb253-19" aria-hidden="true" tabindex="-1"></a><span class="st">  `Tip_Amt` double,</span></span>
<span id="cb253-20"><a href="data-collection-and-data-storage.html#cb253-20" aria-hidden="true" tabindex="-1"></a><span class="st">  `Tolls_Amt` double,</span></span>
<span id="cb253-21"><a href="data-collection-and-data-storage.html#cb253-21" aria-hidden="true" tabindex="-1"></a><span class="st">  `Total_Amt` double</span></span>
<span id="cb253-22"><a href="data-collection-and-data-storage.html#cb253-22" aria-hidden="true" tabindex="-1"></a><span class="st">)</span></span>
<span id="cb253-23"><a href="data-collection-and-data-storage.html#cb253-23" aria-hidden="true" tabindex="-1"></a><span class="st">ROW FORMAT DELIMITED</span></span>
<span id="cb253-24"><a href="data-collection-and-data-storage.html#cb253-24" aria-hidden="true" tabindex="-1"></a><span class="st">FIELDS TERMINATED BY &#39;,&#39;</span></span>
<span id="cb253-25"><a href="data-collection-and-data-storage.html#cb253-25" aria-hidden="true" tabindex="-1"></a><span class="st">STORED AS TEXTFILE</span></span>
<span id="cb253-26"><a href="data-collection-and-data-storage.html#cb253-26" aria-hidden="true" tabindex="-1"></a><span class="st">LOCATION &#39;s3://tlc-trips/analytic_data/&#39;</span></span>
<span id="cb253-27"><a href="data-collection-and-data-storage.html#cb253-27" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb253-28"><a href="data-collection-and-data-storage.html#cb253-28" aria-hidden="true" tabindex="-1"></a><span class="fu">dbSendQuery</span>(con, query_create_table)</span></code></pre></div>
<p>Run a test query to verify the table.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="data-collection-and-data-storage.html#cb254-1" aria-hidden="true" tabindex="-1"></a>test_query <span class="ot">&lt;-</span></span>
<span id="cb254-2"><a href="data-collection-and-data-storage.html#cb254-2" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb254-3"><a href="data-collection-and-data-storage.html#cb254-3" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT * </span></span>
<span id="cb254-4"><a href="data-collection-and-data-storage.html#cb254-4" aria-hidden="true" tabindex="-1"></a><span class="st">FROM default.trips</span></span>
<span id="cb254-5"><a href="data-collection-and-data-storage.html#cb254-5" aria-hidden="true" tabindex="-1"></a><span class="st">LIMIT 10</span></span>
<span id="cb254-6"><a href="data-collection-and-data-storage.html#cb254-6" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb254-7"><a href="data-collection-and-data-storage.html#cb254-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> <span class="fu">dbGetQuery</span>(con, test_query)</span>
<span id="cb254-8"><a href="data-collection-and-data-storage.html#cb254-8" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code></pre></div>
<pre><code>## [1] 10 18</code></pre>
<p>Finally, close the connection.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="data-collection-and-data-storage.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dbDisconnect</span>(con)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
</div>
</div>
<div id="wrapping-up-4" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Wrapping up<a href="data-collection-and-data-storage.html#wrapping-up-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>It is good practice to set up all of the high-level <em>pipeline</em> in the same language (here: R). This substantially facilitates your workflow and makes your overall pipeline easier to maintain. Importantly, as illustrated in the sections above, this practice does not mean that all of the underlying data processing is actually done in R. We simply use R as the highest-level layer, and call a range of services under the hood to handle each of the pipeline components as efficiently as possible.</li>
<li><em>Apache Arrow</em> allows you to combine and correct raw data without exceeding RAM; in addition it facilitates working with newer (big) data formats for columnar data storage systems (like <em>Apache Parquet</em>).</li>
<li><em>RDBMSs</em> such as <em>SQLite</em> or <em>MySQL</em> and analytics databases such as <em>Druid</em> help you store and organize clean/structured data for analytics purposes locally or in the cloud.</li>
<li><em>RDBMSs</em> like SQLite are <em>row-based</em> (changing a value means changing a row), while modern analytics databases are usually <em>column</em>-based (changing a value means modifying one column).</li>
<li>Row-based databases are recommended when your analytics workflow includes a lot of tables, table joins, and frequent filtering for specific observations with variables from several tables.
Column-based databases are recommended for analytics workflows involving less frequent but large-scale data aggregation tasks.</li>
<li><em>Data warehouse</em> solutions like <em>Google BigQuery</em> are useful to store and query large (semi-)structured datasets, but are more flexible regarding hierarchical data and file formats than traditional RDBMSs.</li>
<li><em>Data lakes</em> and simple storage services are the all-purpose tools to store vast amounts of data in any format in the cloud. Typically, solutions like <em>AWS S3</em> are a great option to store all of the raw data related to a data analytics project.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-AWR.Athena" class="csl-entry">
Fultz, Neal, and Gergely Daróczi. 2019. <em>AWR.athena: ’AWS’ Athena ’DBI’ Wrapper</em>. <a href="https://CRAN.R-project.org/package=AWR.Athena">https://CRAN.R-project.org/package=AWR.Athena</a>.
</div>
<div id="ref-aws.s3" class="csl-entry">
Leeper, Thomas J. 2020. <em>Aws.s3: AWS S3 Client Package</em>.
</div>
<div id="ref-RDruid" class="csl-entry">
Metamarkets Group Inc. 2023. <em><span class="nocase">RDruid: Druid connector for R</span></em>.
</div>
<div id="ref-RSQLite" class="csl-entry">
Müller, Kirill, Hadley Wickham, David A. James, and Seth Falcon. 2022. <em>RSQLite: SQLite Interface for r</em>. <a href="https://CRAN.R-project.org/package=RSQLite">https://CRAN.R-project.org/package=RSQLite</a>.
</div>
<div id="ref-DBI" class="csl-entry">
R Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and Kirill Müller. 2022. <em>DBI: R Database Interface</em>. <a href="https://CRAN.R-project.org/package=DBI">https://CRAN.R-project.org/package=DBI</a>.
</div>
<div id="ref-richardson_etal2022" class="csl-entry">
Richardson, Neal, Ian Cook, Nic Crane, Dewey Dunnington, Romain François, Jonathan Keane, Dragoș Moldovan-Grünfeld, Jeroen Ooms, and Apache Arrow. 2022. <em>Arrow: Integration to ’Apache’ ’Arrow’</em>.
</div>
<div id="ref-RJDBC" class="csl-entry">
Urbanek, Simon. 2022. <em>RJDBC: Provides Access to Databases Through the JDBC Interface</em>. <a href="https://CRAN.R-project.org/package=RJDBC">https://CRAN.R-project.org/package=RJDBC</a>.
</div>
<div id="ref-bigrquery" class="csl-entry">
Wickham, Hadley, and Jennifer Bryan. 2022. <em>Bigrquery: An Interface to Google’s ’BigQuery’ ’API’</em>. <a href="https://CRAN.R-project.org/package=bigrquery">https://CRAN.R-project.org/package=bigrquery</a>.
</div>
<div id="ref-Druid" class="csl-entry">
Yang, Fangjin, Eric Tschetter, Xavier Léauté, Nelson Ray, Gian Merlino, and Deep Ganguli. 2014. <span>“<span>Druid: A Real-Time Analytical Data Store</span>.”</span> In <em>Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data</em>, 157–68. SIGMOD ’14. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/2588555.2595631">https://doi.org/10.1145/2588555.2595631</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="45">
<li id="fn45"><p>Note that this is not generally recommendable. Only do this to get familiar with the service and to test some code.<a href="data-collection-and-data-storage.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>Importantly, recall that with this set up, Druid is currently running from within the <code>apache-druid-24.0.0</code>-directory. Hence, unless you have copied your data into this directory, you will have to explicitly point to data files outside of this directory (via <code>../</code>).<a href="data-collection-and-data-storage.html#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>The Druid service to load data by default allows you to point to various files here via the wildcard character (<code>*</code>). As we have stored all the taxi trip example data in one CSV file, we can directly point to this one file.<a href="data-collection-and-data-storage.html#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>The <code>bigrquery</code> package provides a DBI-driver for BigQuery. For more advanced usage of <code>bigrquery</code>, the package also provides lower-level functions to directly interact with the BigQuery API.<a href="data-collection-and-data-storage.html#fnref48" class="footnote-back">↩︎</a></p></li>
<li id="fn49"><p>Minor but relevant exceptions are that <code>SQLite</code>, <code>MySQL</code>, and <code>BigQuery</code> do not provide all the same SQL commands. However, for all core operations to query and summarize data, the SQL syntax is essentially identical.<a href="data-collection-and-data-storage.html#fnref49" class="footnote-back">↩︎</a></p></li>
<li id="fn50"><p>Since in this example the queried subset is not particularly large, it is easier to perform the data preparation locally in R. However, in other situations it might make sense to use SQL in BigQuery more extensively for data preparation tasks that would require a lot of RAM.<a href="data-collection-and-data-storage.html#fnref50" class="footnote-back">↩︎</a></p></li>
<li id="fn51"><p>Essentially, all other major cloud computing providers offer very similar services with very similar features to AWS S3. Conceptually, you could thus easily use one of these other services. The examples here focus on AWS S3 primarily for simplicity (as we have already set up AWS credentials etc.), and the straightforward way to connect to AWS S3 via R.<a href="data-collection-and-data-storage.html#fnref51" class="footnote-back">↩︎</a></p></li>
<li id="fn52"><p>There are many ways to create these credentials, and which ones to use. A very simple and reasonable instruction of how to do this can be found here: <a href="https://binaryguy.tech/aws/s3/create-iam-user-to-access-s3/" class="uri">https://binaryguy.tech/aws/s3/create-iam-user-to-access-s3/</a>.<a href="data-collection-and-data-storage.html#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>Note that, technically, the explicit creation of folders is not necessary, as S3 uses slashes (<code>/</code>) in file names on S3 to make them appear to be in a particular folder. However, when using the AWS S3 console in the browser, defining folders explicitly can make more sense from the users’ perspective.<a href="data-collection-and-data-storage.html#fnref53" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="big-data-cleaning-and-transformation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
